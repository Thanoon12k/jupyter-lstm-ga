{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b169ee5-9af7-43dd-ae0f-f7c7f7e10bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense , Dropout\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.models import save_model, load_model\n",
    "\n",
    "\n",
    "from gaft import GAEngine\n",
    "from gaft.components import BinaryIndividual, Population\n",
    "from gaft.operators import RouletteWheelSelection, UniformCrossover, FlipBitMutation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping,Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89afc85-2ead-40eb-9d9c-183003063ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TaskID', 'StartTime', 'TaskFileSize', 'TaskOutputFileSize',\n",
      "       'TaskFileLength', 'DataCenterID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Tasks_DataSet.csv')\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['DataCenterID'])\n",
    "y = df['DataCenterID']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f50928-b8fe-4229-919e-609bf4d05a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e8a54f-e3f1-4480-a5d2-49b029b67855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/94\n",
      "40/40 [==============================] - 5s 33ms/step - loss: 1.1082 - accuracy: 0.3194 - val_loss: 1.0986 - val_accuracy: 0.3611\n",
      "Epoch 2/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3514 - val_loss: 1.0988 - val_accuracy: 0.3833\n",
      "Epoch 3/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0970 - accuracy: 0.3444 - val_loss: 1.1024 - val_accuracy: 0.3611\n",
      "Epoch 4/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0965 - accuracy: 0.3458 - val_loss: 1.0948 - val_accuracy: 0.3944\n",
      "Epoch 5/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0953 - accuracy: 0.3625 - val_loss: 1.0972 - val_accuracy: 0.3500\n",
      "Epoch 6/94\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 1.0912 - accuracy: 0.3681 - val_loss: 1.1022 - val_accuracy: 0.3444\n",
      "Epoch 7/94\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 1.0894 - accuracy: 0.3597 - val_loss: 1.1301 - val_accuracy: 0.3611\n",
      "Epoch 8/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0885 - accuracy: 0.3792 - val_loss: 1.0908 - val_accuracy: 0.3667\n",
      "Epoch 9/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0883 - accuracy: 0.3806 - val_loss: 1.1122 - val_accuracy: 0.3778\n",
      "Epoch 10/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0835 - accuracy: 0.3861 - val_loss: 1.0938 - val_accuracy: 0.3556\n",
      "Epoch 11/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0819 - accuracy: 0.4056 - val_loss: 1.0968 - val_accuracy: 0.3722\n",
      "Epoch 12/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0762 - accuracy: 0.3931 - val_loss: 1.0890 - val_accuracy: 0.3611\n",
      "Epoch 13/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0684 - accuracy: 0.4194 - val_loss: 1.1068 - val_accuracy: 0.3500\n",
      "Epoch 14/94\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 1.0616 - accuracy: 0.4347 - val_loss: 1.0987 - val_accuracy: 0.3722\n",
      "Epoch 15/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0570 - accuracy: 0.4319 - val_loss: 1.1021 - val_accuracy: 0.3611\n",
      "Epoch 16/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0545 - accuracy: 0.4181 - val_loss: 1.1031 - val_accuracy: 0.3611\n",
      "Epoch 17/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0433 - accuracy: 0.4583 - val_loss: 1.1212 - val_accuracy: 0.3667\n",
      "Epoch 18/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0385 - accuracy: 0.4500 - val_loss: 1.1384 - val_accuracy: 0.3278\n",
      "Epoch 19/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0341 - accuracy: 0.4528 - val_loss: 1.1185 - val_accuracy: 0.3500\n",
      "Epoch 20/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0303 - accuracy: 0.4458 - val_loss: 1.1753 - val_accuracy: 0.3444\n",
      "Epoch 21/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0078 - accuracy: 0.4750 - val_loss: 1.1534 - val_accuracy: 0.3722\n",
      "Epoch 22/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0007 - accuracy: 0.4819 - val_loss: 1.1186 - val_accuracy: 0.3667\n",
      "Epoch 23/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9890 - accuracy: 0.4847 - val_loss: 1.1276 - val_accuracy: 0.3833\n",
      "Epoch 24/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9798 - accuracy: 0.4764 - val_loss: 1.1420 - val_accuracy: 0.3611\n",
      "Epoch 25/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9766 - accuracy: 0.5028 - val_loss: 1.1841 - val_accuracy: 0.3667\n",
      "Epoch 26/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9573 - accuracy: 0.5111 - val_loss: 1.2333 - val_accuracy: 0.3833\n",
      "Epoch 27/94\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.9477 - accuracy: 0.5167 - val_loss: 1.2052 - val_accuracy: 0.3444\n",
      "Epoch 28/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.9253 - accuracy: 0.5139 - val_loss: 1.2142 - val_accuracy: 0.3889\n",
      "Epoch 29/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9101 - accuracy: 0.5319 - val_loss: 1.2713 - val_accuracy: 0.3444\n",
      "Epoch 30/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8948 - accuracy: 0.5556 - val_loss: 1.2881 - val_accuracy: 0.3556\n",
      "Epoch 31/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.8903 - accuracy: 0.5431 - val_loss: 1.2938 - val_accuracy: 0.3278\n",
      "Epoch 32/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8636 - accuracy: 0.5625 - val_loss: 1.3419 - val_accuracy: 0.3556\n",
      "Epoch 33/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8681 - accuracy: 0.5667 - val_loss: 1.3118 - val_accuracy: 0.3667\n",
      "Epoch 34/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.8301 - accuracy: 0.5792 - val_loss: 1.3038 - val_accuracy: 0.3833\n",
      "Epoch 35/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8110 - accuracy: 0.5944 - val_loss: 1.3830 - val_accuracy: 0.3722\n",
      "Epoch 36/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8153 - accuracy: 0.5806 - val_loss: 1.4350 - val_accuracy: 0.3389\n",
      "Epoch 37/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8276 - accuracy: 0.5736 - val_loss: 1.3570 - val_accuracy: 0.4056\n",
      "Epoch 38/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7700 - accuracy: 0.6153 - val_loss: 1.4100 - val_accuracy: 0.3778\n",
      "Epoch 39/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7818 - accuracy: 0.5847 - val_loss: 1.4659 - val_accuracy: 0.3778\n",
      "Epoch 40/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7594 - accuracy: 0.6139 - val_loss: 1.4590 - val_accuracy: 0.4222\n",
      "Epoch 41/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7378 - accuracy: 0.6167 - val_loss: 1.4433 - val_accuracy: 0.3944\n",
      "Epoch 42/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7186 - accuracy: 0.6292 - val_loss: 1.5136 - val_accuracy: 0.4389\n",
      "Epoch 43/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7125 - accuracy: 0.6361 - val_loss: 1.6211 - val_accuracy: 0.3667\n",
      "Epoch 44/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7196 - accuracy: 0.6292 - val_loss: 1.5632 - val_accuracy: 0.4167\n",
      "Epoch 45/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6758 - accuracy: 0.6625 - val_loss: 1.6048 - val_accuracy: 0.4167\n",
      "Epoch 46/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6470 - accuracy: 0.6833 - val_loss: 1.6238 - val_accuracy: 0.4111\n",
      "Epoch 47/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6402 - accuracy: 0.6611 - val_loss: 1.6834 - val_accuracy: 0.4389\n",
      "Epoch 48/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6861 - val_loss: 1.7437 - val_accuracy: 0.4111\n",
      "Epoch 49/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6345 - accuracy: 0.6778 - val_loss: 1.7723 - val_accuracy: 0.4167\n",
      "Epoch 50/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6244 - accuracy: 0.6903 - val_loss: 1.8769 - val_accuracy: 0.4000\n",
      "Epoch 51/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.7125 - val_loss: 1.8069 - val_accuracy: 0.3944\n",
      "Epoch 52/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5646 - accuracy: 0.7306 - val_loss: 1.8499 - val_accuracy: 0.4000\n",
      "Epoch 53/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.7222 - val_loss: 1.8852 - val_accuracy: 0.4000\n",
      "Epoch 54/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5650 - accuracy: 0.7347 - val_loss: 1.9516 - val_accuracy: 0.4278\n",
      "Epoch 55/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7611 - val_loss: 1.9540 - val_accuracy: 0.4056\n",
      "Epoch 56/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7375 - val_loss: 1.9212 - val_accuracy: 0.4056\n",
      "Epoch 57/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7444 - val_loss: 2.1253 - val_accuracy: 0.4056\n",
      "Epoch 58/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7569 - val_loss: 2.1403 - val_accuracy: 0.3889\n",
      "Epoch 59/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7583 - val_loss: 2.1286 - val_accuracy: 0.3944\n",
      "Epoch 60/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7736 - val_loss: 2.2131 - val_accuracy: 0.4167\n",
      "Epoch 61/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7528 - val_loss: 2.1869 - val_accuracy: 0.4333\n",
      "Epoch 62/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7889 - val_loss: 2.2885 - val_accuracy: 0.4111\n",
      "Epoch 63/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 2.3230 - val_accuracy: 0.4167\n",
      "Epoch 64/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7903 - val_loss: 2.3996 - val_accuracy: 0.4278\n",
      "Epoch 65/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7917 - val_loss: 2.4058 - val_accuracy: 0.4056\n",
      "Epoch 66/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7917 - val_loss: 2.3336 - val_accuracy: 0.4333\n",
      "Epoch 67/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4011 - accuracy: 0.7972 - val_loss: 2.3448 - val_accuracy: 0.4167\n",
      "Epoch 68/94\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4374 - accuracy: 0.8083 - val_loss: 2.4556 - val_accuracy: 0.4278\n",
      "Epoch 69/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.8028 - val_loss: 2.4607 - val_accuracy: 0.4333\n",
      "Epoch 70/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8042 - val_loss: 2.4768 - val_accuracy: 0.4389\n",
      "Epoch 71/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8278 - val_loss: 2.5841 - val_accuracy: 0.4167\n",
      "Epoch 72/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8264 - val_loss: 2.5204 - val_accuracy: 0.4444\n",
      "Epoch 73/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.8514 - val_loss: 2.6885 - val_accuracy: 0.4000\n",
      "Epoch 74/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8389 - val_loss: 2.6920 - val_accuracy: 0.4167\n",
      "Epoch 75/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3380 - accuracy: 0.8431 - val_loss: 2.7891 - val_accuracy: 0.4556\n",
      "Epoch 76/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8542 - val_loss: 2.7756 - val_accuracy: 0.4111\n",
      "Epoch 77/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8389 - val_loss: 2.9554 - val_accuracy: 0.3944\n",
      "Epoch 78/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 0.8528 - val_loss: 2.8694 - val_accuracy: 0.4167\n",
      "Epoch 79/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3050 - accuracy: 0.8681 - val_loss: 2.9668 - val_accuracy: 0.4278\n",
      "Epoch 80/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3351 - accuracy: 0.8444 - val_loss: 2.9939 - val_accuracy: 0.4500\n",
      "Epoch 81/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3150 - accuracy: 0.8639 - val_loss: 2.9673 - val_accuracy: 0.4278\n",
      "Epoch 82/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3153 - accuracy: 0.8556 - val_loss: 3.0281 - val_accuracy: 0.4722\n",
      "Epoch 83/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3181 - accuracy: 0.8583 - val_loss: 3.2483 - val_accuracy: 0.4111\n",
      "Epoch 84/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8486 - val_loss: 3.1618 - val_accuracy: 0.4500\n",
      "Epoch 85/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8528 - val_loss: 3.0721 - val_accuracy: 0.4222\n",
      "Epoch 86/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3129 - accuracy: 0.8639 - val_loss: 2.9532 - val_accuracy: 0.4500\n",
      "Epoch 87/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3111 - accuracy: 0.8722 - val_loss: 3.0896 - val_accuracy: 0.4000\n",
      "Epoch 88/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2873 - accuracy: 0.8833 - val_loss: 3.1734 - val_accuracy: 0.4389\n",
      "Epoch 89/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2665 - accuracy: 0.8889 - val_loss: 3.1874 - val_accuracy: 0.4556\n",
      "Epoch 90/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.8847 - val_loss: 3.2459 - val_accuracy: 0.4333\n",
      "Epoch 91/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2695 - accuracy: 0.8903 - val_loss: 3.1726 - val_accuracy: 0.4222\n",
      "Epoch 92/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2903 - accuracy: 0.8778 - val_loss: 3.2659 - val_accuracy: 0.4278\n",
      "Epoch 93/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2657 - accuracy: 0.8903 - val_loss: 3.2367 - val_accuracy: 0.4389\n",
      "Epoch 94/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2453 - accuracy: 0.8972 - val_loss: 3.3432 - val_accuracy: 0.4278\n"
     ]
    }
   ],
   "source": [
    "# Reshape data for LSTM input (assuming a time series sequence length of 1)\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val_lstm = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "#this params values from GA algorithm\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=int(54), input_shape=(1, X_train.shape[1]), return_sequences=True))\n",
    "model.add(LSTM(units=int(62)))\n",
    "model.add(Dropout(0.08203125))\n",
    "model.add(Dense(units=len(df['DataCenterID'].unique()), activation='softmax'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.014921875000000001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "history=model.fit(X_train_lstm, y_train, epochs=94, batch_size=18, validation_data=(X_val_lstm, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff9900b8-d6b4-4180-97ff-5e158f354e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 5ms/step - loss: 3.3432 - accuracy: 0.4278\n",
      "Test Loss: 3.3432\n",
      "Test Accuracy: 42.78%\n",
      "6/6 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have your X_test and y_test prepared similarly to X_train and y_train\n",
    "X_test_lstm = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test_lstm, y_val)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_lstm)\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc415ae0-bdac-4fa2-90c4-2077a5a5b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.47        66\n",
      "           1       0.50      0.38      0.43        56\n",
      "           2       0.36      0.40      0.38        58\n",
      "\n",
      "    accuracy                           0.43       180\n",
      "   macro avg       0.44      0.42      0.43       180\n",
      "weighted avg       0.43      0.43      0.43       180\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_classes))\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "\n",
    "# Create a colorful confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5acc8031-c249-4412-9b0e-94e60185eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('lstm89.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "186c0b11-06a0-4bb9-b02e-fcdfece4e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted DataCenterID: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def predict_datacenter_id(requested_array,model_name):\n",
    "    data_dict = {\n",
    "        \"TaskID\": requested_array[0],\n",
    "        \"StartTime\": requested_array[1],\n",
    "        \"TaskFileSize\": requested_array[2],\n",
    "        \"TaskOutputFileSize\": requested_array[3],\n",
    "        \"TaskFileLength\": requested_array[4],\n",
    "\n",
    "    }\n",
    "    input_data = np.array([[\n",
    "        data_dict[\"TaskID\"],\n",
    "        data_dict[\"StartTime\"],\n",
    "        data_dict[\"TaskFileSize\"],\n",
    "        data_dict[\"TaskOutputFileSize\"],\n",
    "        data_dict[\"TaskFileLength\"]]])\n",
    "    # Load the saved model\n",
    "    loaded_model = load_model(model_name)\n",
    "    # Reshape the input data to match the LSTM input shape\n",
    "    input_data_lstm = input_data.reshape(input_data.shape[0], 1, input_data.shape[1])\n",
    "    # Make predictions using the loaded model\n",
    "    predicted_probabilities = loaded_model.predict(input_data_lstm)\n",
    "    predicted_class = np.argmax(predicted_probabilities, axis=1)\n",
    "    predicted_DC=predicted_class[0]\n",
    "    return predicted_DC\n",
    "requested_array = [0.1, 55, 0, 0, 55]\n",
    "predicted_datacenter_id = predict_datacenter_id(requested_array,\"lstm89.keras\")\n",
    "print(f\"Predicted DataCenterID: {predicted_datacenter_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333079b5-a452-4b7d-96f8-4c0838e1bf14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 64.832763671875, Units2: 69.81369018554688, Dropout Rate: 0.265625, Learning Rate: 0.005640625000000001, Epochs: 52.8521728515625, Batch Size: 93.51394653320312\n",
      "\n",
      "Epoch 1/52\n",
      "8/8 [==============================] - 6s 170ms/step - loss: 1.0992 - accuracy: 0.3417 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
      "Epoch 2/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0951 - accuracy: 0.3694 - val_loss: 1.1061 - val_accuracy: 0.3500\n",
      "Epoch 3/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0931 - accuracy: 0.3583 - val_loss: 1.1099 - val_accuracy: 0.3389\n",
      "Epoch 4/52\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0927 - accuracy: 0.3667 - val_loss: 1.1125 - val_accuracy: 0.3444\n",
      "Epoch 5/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0907 - accuracy: 0.3806 - val_loss: 1.1061 - val_accuracy: 0.3778\n",
      "Epoch 6/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0890 - accuracy: 0.3750 - val_loss: 1.1042 - val_accuracy: 0.3722\n",
      "Epoch 7/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0874 - accuracy: 0.3806 - val_loss: 1.1030 - val_accuracy: 0.3833\n",
      "Epoch 8/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0873 - accuracy: 0.3833 - val_loss: 1.1052 - val_accuracy: 0.3833\n",
      "Epoch 9/52\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0873 - accuracy: 0.3819 - val_loss: 1.1042 - val_accuracy: 0.3889\n",
      "Epoch 10/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0846 - accuracy: 0.3750 - val_loss: 1.1075 - val_accuracy: 0.3778\n",
      "Epoch 11/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0841 - accuracy: 0.3736 - val_loss: 1.1053 - val_accuracy: 0.3889\n",
      "Epoch 12/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0824 - accuracy: 0.3931 - val_loss: 1.1059 - val_accuracy: 0.4056\n",
      "Epoch 13/52\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0825 - accuracy: 0.3861 - val_loss: 1.1072 - val_accuracy: 0.3944\n",
      "Epoch 14/52\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0797 - accuracy: 0.3931 - val_loss: 1.1128 - val_accuracy: 0.3944\n",
      "Epoch 15/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0754 - accuracy: 0.4083 - val_loss: 1.1069 - val_accuracy: 0.3944\n",
      "Epoch 16/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0752 - accuracy: 0.4139 - val_loss: 1.1121 - val_accuracy: 0.4111\n",
      "Epoch 17/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0693 - accuracy: 0.4222 - val_loss: 1.1197 - val_accuracy: 0.3556\n",
      "Epoch 18/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0699 - accuracy: 0.4264 - val_loss: 1.1177 - val_accuracy: 0.3667\n",
      "Epoch 19/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0620 - accuracy: 0.4306 - val_loss: 1.1180 - val_accuracy: 0.3333\n",
      "Epoch 20/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0619 - accuracy: 0.4264 - val_loss: 1.1344 - val_accuracy: 0.3500\n",
      "Epoch 21/52\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0618 - accuracy: 0.4250 - val_loss: 1.1310 - val_accuracy: 0.3389\n",
      "Epoch 22/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0574 - accuracy: 0.4333 - val_loss: 1.1243 - val_accuracy: 0.3500\n",
      "Epoch 23/52\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0630 - accuracy: 0.4278 - val_loss: 1.1468 - val_accuracy: 0.3278\n",
      "Epoch 24/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0515 - accuracy: 0.4208 - val_loss: 1.1233 - val_accuracy: 0.3444\n",
      "Epoch 25/52\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0500 - accuracy: 0.4181 - val_loss: 1.1257 - val_accuracy: 0.3333\n",
      "Epoch 26/52\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0444 - accuracy: 0.4222 - val_loss: 1.1478 - val_accuracy: 0.2944\n",
      "Epoch 27/52\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0462 - accuracy: 0.4319 - val_loss: 1.1474 - val_accuracy: 0.3111\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 51.52557373046875, Units2: 82.91900634765625, Dropout Rate: 0.802734375, Learning Rate: 0.09071875, Epochs: 89.04937744140625, Batch Size: 23.37860107421875\n",
      "\n",
      "Epoch 1/89\n",
      "32/32 [==============================] - 6s 44ms/step - loss: 1.2510 - accuracy: 0.3514 - val_loss: 1.0996 - val_accuracy: 0.3833\n",
      "Epoch 2/89\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1651 - accuracy: 0.3014 - val_loss: 1.1039 - val_accuracy: 0.3444\n",
      "Epoch 3/89\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1138 - accuracy: 0.3597 - val_loss: 1.1483 - val_accuracy: 0.3222\n",
      "Epoch 4/89\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1273 - accuracy: 0.3167 - val_loss: 1.1075 - val_accuracy: 0.3389\n",
      "Epoch 5/89\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0951 - accuracy: 0.3708 - val_loss: 1.1136 - val_accuracy: 0.3167\n",
      "Epoch 6/89\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1119 - accuracy: 0.3375 - val_loss: 1.1082 - val_accuracy: 0.3278\n",
      "Epoch 7/89\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1076 - accuracy: 0.3292 - val_loss: 1.1063 - val_accuracy: 0.3722\n",
      "Epoch 8/89\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1087 - accuracy: 0.3139 - val_loss: 1.1129 - val_accuracy: 0.3667\n",
      "Epoch 9/89\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1031 - accuracy: 0.3444 - val_loss: 1.0988 - val_accuracy: 0.3556\n",
      "Epoch 10/89\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1049 - accuracy: 0.3528 - val_loss: 1.1076 - val_accuracy: 0.3167\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 95.86090087890625, Units2: 58.857574462890625, Dropout Rate: 0.201171875, Learning Rate: 0.047406250000000004, Epochs: 53.021087646484375, Batch Size: 24.94964599609375\n",
      "\n",
      "Epoch 1/53\n",
      "30/30 [==============================] - 6s 45ms/step - loss: 1.1307 - accuracy: 0.3181 - val_loss: 1.0969 - val_accuracy: 0.3222\n",
      "Epoch 2/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1040 - accuracy: 0.3333 - val_loss: 1.0952 - val_accuracy: 0.3667\n",
      "Epoch 3/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1034 - accuracy: 0.3556 - val_loss: 1.0986 - val_accuracy: 0.3056\n",
      "Epoch 4/53\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0959 - accuracy: 0.3625 - val_loss: 1.1245 - val_accuracy: 0.3444\n",
      "Epoch 5/53\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0940 - accuracy: 0.3639 - val_loss: 1.1074 - val_accuracy: 0.3222\n",
      "Epoch 6/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0982 - accuracy: 0.3625 - val_loss: 1.1026 - val_accuracy: 0.3278\n",
      "Epoch 7/53\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0934 - accuracy: 0.3625 - val_loss: 1.1303 - val_accuracy: 0.2889\n",
      "Epoch 8/53\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0906 - accuracy: 0.3778 - val_loss: 1.1256 - val_accuracy: 0.3000\n",
      "Epoch 9/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1008 - accuracy: 0.3389 - val_loss: 1.1053 - val_accuracy: 0.3556\n",
      "Epoch 10/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0864 - accuracy: 0.3944 - val_loss: 1.1162 - val_accuracy: 0.3611\n",
      "Epoch 11/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0841 - accuracy: 0.4000 - val_loss: 1.2149 - val_accuracy: 0.3278\n",
      "Epoch 12/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0810 - accuracy: 0.3819 - val_loss: 1.1351 - val_accuracy: 0.3722\n",
      "Epoch 13/53\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0711 - accuracy: 0.4097 - val_loss: 1.1424 - val_accuracy: 0.4111\n",
      "Epoch 14/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0646 - accuracy: 0.3875 - val_loss: 1.1802 - val_accuracy: 0.3444\n",
      "Epoch 15/53\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0690 - accuracy: 0.4028 - val_loss: 1.2115 - val_accuracy: 0.3611\n",
      "Epoch 16/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0836 - accuracy: 0.3847 - val_loss: 1.1517 - val_accuracy: 0.3056\n",
      "Epoch 17/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0722 - accuracy: 0.4097 - val_loss: 1.1959 - val_accuracy: 0.3611\n",
      "Epoch 18/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0800 - accuracy: 0.4181 - val_loss: 1.1810 - val_accuracy: 0.3444\n",
      "Epoch 19/53\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0712 - accuracy: 0.3972 - val_loss: 1.1445 - val_accuracy: 0.3500\n",
      "Epoch 20/53\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0537 - accuracy: 0.4361 - val_loss: 1.2272 - val_accuracy: 0.3444\n",
      "Epoch 21/53\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0376 - accuracy: 0.4639 - val_loss: 1.1328 - val_accuracy: 0.3500\n",
      "Epoch 22/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0478 - accuracy: 0.4417 - val_loss: 1.1658 - val_accuracy: 0.3444\n",
      "Epoch 23/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0247 - accuracy: 0.4167 - val_loss: 1.2930 - val_accuracy: 0.3222\n",
      "Epoch 24/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0428 - accuracy: 0.4528 - val_loss: 1.2031 - val_accuracy: 0.3667\n",
      "Epoch 25/53\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0493 - accuracy: 0.4333 - val_loss: 1.1985 - val_accuracy: 0.3167\n",
      "Epoch 26/53\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0269 - accuracy: 0.4556 - val_loss: 1.1776 - val_accuracy: 0.3611\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 51.573638916015625, Units2: 10.295257568359375, Dropout Rate: 0.990234375, Learning Rate: 0.07834375, Epochs: 85.61614990234375, Batch Size: 68.47335815429688\n",
      "\n",
      "Epoch 1/85\n",
      "11/11 [==============================] - 6s 126ms/step - loss: 1.2556 - accuracy: 0.3194 - val_loss: 1.0917 - val_accuracy: 0.3611\n",
      "Epoch 2/85\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.3557 - accuracy: 0.3417 - val_loss: 1.1007 - val_accuracy: 0.3444\n",
      "Epoch 3/85\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1205 - accuracy: 0.3458 - val_loss: 1.0979 - val_accuracy: 0.3500\n",
      "Epoch 4/85\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1268 - accuracy: 0.3375 - val_loss: 1.0967 - val_accuracy: 0.3667\n",
      "Epoch 5/85\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1016 - accuracy: 0.3250 - val_loss: 1.0979 - val_accuracy: 0.3222\n",
      "Epoch 6/85\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1027 - accuracy: 0.3153 - val_loss: 1.0990 - val_accuracy: 0.2778\n",
      "Epoch 7/85\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1018 - accuracy: 0.3347 - val_loss: 1.0973 - val_accuracy: 0.3611\n",
      "Epoch 8/85\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1020 - accuracy: 0.3444 - val_loss: 1.0967 - val_accuracy: 0.3667\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 84.18380737304688, Units2: 66.92291259765625, Dropout Rate: 0.76953125, Learning Rate: 0.082984375, Epochs: 74.7808837890625, Batch Size: 92.2821044921875\n",
      "\n",
      "Epoch 1/74\n",
      "8/8 [==============================] - 6s 182ms/step - loss: 1.1515 - accuracy: 0.3167 - val_loss: 1.1138 - val_accuracy: 0.3278\n",
      "Epoch 2/74\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.1508 - accuracy: 0.3292 - val_loss: 1.1067 - val_accuracy: 0.2833\n",
      "Epoch 3/74\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.1201 - accuracy: 0.3514 - val_loss: 1.1180 - val_accuracy: 0.3333\n",
      "Epoch 4/74\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1154 - accuracy: 0.3819 - val_loss: 1.1059 - val_accuracy: 0.3500\n",
      "Epoch 5/74\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1172 - accuracy: 0.3278 - val_loss: 1.0976 - val_accuracy: 0.3778\n",
      "Epoch 6/74\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0965 - accuracy: 0.3472 - val_loss: 1.1022 - val_accuracy: 0.3222\n",
      "Epoch 7/74\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0980 - accuracy: 0.3597 - val_loss: 1.0995 - val_accuracy: 0.3222\n",
      "Epoch 8/74\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0991 - accuracy: 0.3500 - val_loss: 1.1043 - val_accuracy: 0.3333\n",
      "Epoch 9/74\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0982 - accuracy: 0.3792 - val_loss: 1.1055 - val_accuracy: 0.3111\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 33.91998291015625, Units2: 81.16256713867188, Dropout Rate: 0.0546875, Learning Rate: 0.048953125, Epochs: 30.337066650390625, Batch Size: 46.297454833984375\n",
      "\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 6s 87ms/step - loss: 1.1115 - accuracy: 0.3139 - val_loss: 1.1358 - val_accuracy: 0.3000\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.1042 - accuracy: 0.3292 - val_loss: 1.0965 - val_accuracy: 0.3667\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0981 - accuracy: 0.3722 - val_loss: 1.1051 - val_accuracy: 0.3111\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0973 - accuracy: 0.3556 - val_loss: 1.1018 - val_accuracy: 0.3667\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0969 - accuracy: 0.3792 - val_loss: 1.0989 - val_accuracy: 0.3778\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.1046 - accuracy: 0.3472 - val_loss: 1.0975 - val_accuracy: 0.3611\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0937 - accuracy: 0.3639 - val_loss: 1.0985 - val_accuracy: 0.3556\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0923 - accuracy: 0.3917 - val_loss: 1.1071 - val_accuracy: 0.3611\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0827 - accuracy: 0.3917 - val_loss: 1.1190 - val_accuracy: 0.3444\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0752 - accuracy: 0.4042 - val_loss: 1.1269 - val_accuracy: 0.3722\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.0595 - accuracy: 0.4042 - val_loss: 1.1465 - val_accuracy: 0.3611\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0702 - accuracy: 0.4347 - val_loss: 1.1181 - val_accuracy: 0.3444\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0447 - accuracy: 0.4403 - val_loss: 1.1610 - val_accuracy: 0.3833\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0417 - accuracy: 0.4389 - val_loss: 1.1216 - val_accuracy: 0.3722\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0243 - accuracy: 0.4722 - val_loss: 1.1580 - val_accuracy: 0.3722\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0387 - accuracy: 0.4458 - val_loss: 1.1192 - val_accuracy: 0.3500\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0263 - accuracy: 0.4583 - val_loss: 1.1220 - val_accuracy: 0.3278\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0021 - accuracy: 0.4639 - val_loss: 1.1929 - val_accuracy: 0.3278\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0056 - accuracy: 0.4750 - val_loss: 1.1411 - val_accuracy: 0.3500\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.9860 - accuracy: 0.4944 - val_loss: 1.1954 - val_accuracy: 0.3500\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.9728 - accuracy: 0.5028 - val_loss: 1.1528 - val_accuracy: 0.3389\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.9678 - accuracy: 0.4833 - val_loss: 1.2497 - val_accuracy: 0.3556\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.9652 - accuracy: 0.5028 - val_loss: 1.2430 - val_accuracy: 0.3444\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.9551 - accuracy: 0.5139 - val_loss: 1.1785 - val_accuracy: 0.3722\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9482 - accuracy: 0.5292 - val_loss: 1.2297 - val_accuracy: 0.3444\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.9404 - accuracy: 0.5389 - val_loss: 1.2440 - val_accuracy: 0.3056\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9223 - accuracy: 0.5347 - val_loss: 1.2204 - val_accuracy: 0.3444\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.9241 - accuracy: 0.5194 - val_loss: 1.2472 - val_accuracy: 0.3611\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9007 - accuracy: 0.5431 - val_loss: 1.2847 - val_accuracy: 0.3778\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.9033 - accuracy: 0.5444 - val_loss: 1.2057 - val_accuracy: 0.3333\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 90.013427734375, Units2: 53.466033935546875, Dropout Rate: 0.626953125, Learning Rate: 0.0505, Epochs: 35.451202392578125, Batch Size: 38.788299560546875\n",
      "\n",
      "Epoch 1/35\n",
      "19/19 [==============================] - 6s 78ms/step - loss: 1.1369 - accuracy: 0.3222 - val_loss: 1.1063 - val_accuracy: 0.3111\n",
      "Epoch 2/35\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.1209 - accuracy: 0.3639 - val_loss: 1.0928 - val_accuracy: 0.3500\n",
      "Epoch 3/35\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.1172 - accuracy: 0.3306 - val_loss: 1.1012 - val_accuracy: 0.3500\n",
      "Epoch 4/35\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.1036 - accuracy: 0.3625 - val_loss: 1.1007 - val_accuracy: 0.3667\n",
      "Epoch 5/35\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.1037 - accuracy: 0.3639 - val_loss: 1.1112 - val_accuracy: 0.3611\n",
      "Epoch 6/35\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0971 - accuracy: 0.3583 - val_loss: 1.1170 - val_accuracy: 0.3611\n",
      "Epoch 7/35\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.1002 - accuracy: 0.3403 - val_loss: 1.0972 - val_accuracy: 0.3722\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 90.87173461914062, Units2: 15.804901123046875, Dropout Rate: 0.548828125, Learning Rate: 0.002546875, Epochs: 60.219879150390625, Batch Size: 94.1717529296875\n",
      "\n",
      "Epoch 1/60\n",
      "8/8 [==============================] - 6s 170ms/step - loss: 1.0991 - accuracy: 0.3264 - val_loss: 1.0972 - val_accuracy: 0.3611\n",
      "Epoch 2/60\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0975 - accuracy: 0.3528 - val_loss: 1.0969 - val_accuracy: 0.3611\n",
      "Epoch 3/60\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0954 - accuracy: 0.3708 - val_loss: 1.0965 - val_accuracy: 0.3778\n",
      "Epoch 4/60\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0958 - accuracy: 0.3458 - val_loss: 1.0970 - val_accuracy: 0.3722\n",
      "Epoch 5/60\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0924 - accuracy: 0.3708 - val_loss: 1.0972 - val_accuracy: 0.3722\n",
      "Epoch 6/60\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0940 - accuracy: 0.3639 - val_loss: 1.0979 - val_accuracy: 0.3500\n",
      "Epoch 7/60\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0910 - accuracy: 0.3750 - val_loss: 1.0990 - val_accuracy: 0.3611\n",
      "Epoch 8/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0921 - accuracy: 0.3694 - val_loss: 1.0996 - val_accuracy: 0.3611\n",
      "Epoch 9/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0894 - accuracy: 0.3722 - val_loss: 1.1021 - val_accuracy: 0.3556\n",
      "Epoch 10/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0897 - accuracy: 0.3833 - val_loss: 1.1025 - val_accuracy: 0.3500\n",
      "Epoch 11/60\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0924 - accuracy: 0.3722 - val_loss: 1.1024 - val_accuracy: 0.3722\n",
      "Epoch 12/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0933 - accuracy: 0.3764 - val_loss: 1.1016 - val_accuracy: 0.3611\n",
      "Epoch 13/60\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0834 - accuracy: 0.3778 - val_loss: 1.1007 - val_accuracy: 0.3833\n",
      "Epoch 14/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0958 - accuracy: 0.3806 - val_loss: 1.1000 - val_accuracy: 0.3889\n",
      "Epoch 15/60\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0895 - accuracy: 0.3736 - val_loss: 1.0989 - val_accuracy: 0.4056\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 61.05072021484375, Units2: 15.77056884765625, Dropout Rate: 0.185546875, Learning Rate: 0.02884375, Epochs: 45.253753662109375, Batch Size: 69.75189208984375\n",
      "\n",
      "Epoch 1/45\n",
      "11/11 [==============================] - 7s 135ms/step - loss: 1.1056 - accuracy: 0.3292 - val_loss: 1.1044 - val_accuracy: 0.3278\n",
      "Epoch 2/45\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0916 - accuracy: 0.3750 - val_loss: 1.0998 - val_accuracy: 0.3611\n",
      "Epoch 3/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0900 - accuracy: 0.3597 - val_loss: 1.1101 - val_accuracy: 0.3722\n",
      "Epoch 4/45\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0935 - accuracy: 0.3347 - val_loss: 1.1035 - val_accuracy: 0.3500\n",
      "Epoch 5/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0947 - accuracy: 0.3639 - val_loss: 1.0929 - val_accuracy: 0.3833\n",
      "Epoch 6/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0857 - accuracy: 0.3750 - val_loss: 1.1076 - val_accuracy: 0.3833\n",
      "Epoch 7/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0818 - accuracy: 0.3903 - val_loss: 1.1075 - val_accuracy: 0.3778\n",
      "Epoch 8/45\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0763 - accuracy: 0.3875 - val_loss: 1.0996 - val_accuracy: 0.3889\n",
      "Epoch 9/45\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0722 - accuracy: 0.4000 - val_loss: 1.1032 - val_accuracy: 0.3500\n",
      "Epoch 10/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0566 - accuracy: 0.4347 - val_loss: 1.1158 - val_accuracy: 0.3667\n",
      "Epoch 11/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0655 - accuracy: 0.4000 - val_loss: 1.1088 - val_accuracy: 0.3667\n",
      "Epoch 12/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0542 - accuracy: 0.4403 - val_loss: 1.1381 - val_accuracy: 0.3500\n",
      "Epoch 13/45\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.0621 - accuracy: 0.4333 - val_loss: 1.1126 - val_accuracy: 0.3722\n",
      "Epoch 14/45\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0479 - accuracy: 0.4306 - val_loss: 1.1249 - val_accuracy: 0.3833\n",
      "Epoch 15/45\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0375 - accuracy: 0.4556 - val_loss: 1.1349 - val_accuracy: 0.3778\n",
      "Epoch 16/45\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0294 - accuracy: 0.4458 - val_loss: 1.1130 - val_accuracy: 0.3778\n",
      "Epoch 17/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0247 - accuracy: 0.4639 - val_loss: 1.1641 - val_accuracy: 0.3667\n",
      "Epoch 18/45\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0202 - accuracy: 0.4542 - val_loss: 1.1690 - val_accuracy: 0.3722\n",
      "Epoch 19/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0020 - accuracy: 0.4750 - val_loss: 1.1614 - val_accuracy: 0.3833\n",
      "Epoch 20/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9769 - accuracy: 0.4972 - val_loss: 1.1681 - val_accuracy: 0.3556\n",
      "Epoch 21/45\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9731 - accuracy: 0.4889 - val_loss: 1.1829 - val_accuracy: 0.3167\n",
      "Epoch 22/45\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9682 - accuracy: 0.4806 - val_loss: 1.1872 - val_accuracy: 0.3167\n",
      "Epoch 23/45\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9308 - accuracy: 0.5319 - val_loss: 1.2398 - val_accuracy: 0.3278\n",
      "Epoch 24/45\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9423 - accuracy: 0.5069 - val_loss: 1.2122 - val_accuracy: 0.3611\n",
      "Epoch 25/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9633 - accuracy: 0.5125 - val_loss: 1.2074 - val_accuracy: 0.3167\n",
      "Epoch 26/45\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9604 - accuracy: 0.5194 - val_loss: 1.2234 - val_accuracy: 0.3889\n",
      "Epoch 27/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9151 - accuracy: 0.5528 - val_loss: 1.2213 - val_accuracy: 0.3556\n",
      "Epoch 28/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9028 - accuracy: 0.5264 - val_loss: 1.2062 - val_accuracy: 0.4000\n",
      "Epoch 29/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.8632 - accuracy: 0.5778 - val_loss: 1.2498 - val_accuracy: 0.3389\n",
      "Epoch 30/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.8562 - accuracy: 0.5708 - val_loss: 1.2998 - val_accuracy: 0.3611\n",
      "Epoch 31/45\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.8530 - accuracy: 0.5458 - val_loss: 1.2961 - val_accuracy: 0.3889\n",
      "Epoch 32/45\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.8683 - accuracy: 0.5696"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_accuracy\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Run the Genetic Algorithm\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\engine.py:45\u001b[0m, in \u001b[0;36mdo_profile.<locals>._do_profile.<locals>.profiled_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m     ps\u001b[38;5;241m.\u001b[39mdump_stats(filename)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\engine.py:156\u001b[0m, in \u001b[0;36mGAEngine.run\u001b[1;34m(self, ng)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo fitness function in GA engine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_statvars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Setup analysis objects.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalysis:\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\engine.py:223\u001b[0m, in \u001b[0;36mGAEngine._update_statvars\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03mPrivate helper function to update statistic variables in GA engine, like\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mmaximum, minimum and mean values.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Wrt original fitness.\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mori_fitness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fitness)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fmean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fitness)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\components\\population.py:212\u001b[0m, in \u001b[0;36mPopulation.max\u001b[1;34m(self, fitness)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m, fitness):\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Get the maximum fitness value in population.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    :param fitness: Fitness function to calculate fitness value\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    :rtype: float\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_fits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\components\\population.py:29\u001b[0m, in \u001b[0;36mMemoized.__call__\u001b[1;34m(self, fitness)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m fitness\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Update and memoize result.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Recover flag.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\u001b[38;5;241m.\u001b[39m_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\components\\population.py:244\u001b[0m, in \u001b[0;36mPopulation.all_fits\u001b[1;34m(self, fitness)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;129m@Memoized\u001b[39m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_fits\u001b[39m(\u001b[38;5;28mself\u001b[39m, fitness):\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Get all fitness values in population.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m    :param fitness: Fitness function to calculate fitness value\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    :type fitness: function\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindividuals\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\components\\population.py:244\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;129m@Memoized\u001b[39m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_fits\u001b[39m(\u001b[38;5;28mself\u001b[39m, fitness):\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Get all fitness values in population.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m    :param fitness: Fitness function to calculate fitness value\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    :type fitness: function\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m indv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividuals]\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\engine.py:268\u001b[0m, in \u001b[0;36mGAEngine.fitness_register.<locals>._fn_with_fitness_check\u001b[1;34m(indv)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindv\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms class must be subclass of IndividualBase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# Check fitness.\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m fitness \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m is_invalid \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mtype\u001b[39m(fitness) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (math\u001b[38;5;241m.\u001b[39misnan(fitness))\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_invalid:\n",
      "Cell \u001b[1;32mIn[9], line 42\u001b[0m, in \u001b[0;36mfitness\u001b[1;34m(indv)\u001b[0m\n\u001b[0;32m     39\u001b[0m units1, units2, dropout_rate, learning_rate, epochs, batch_size \u001b[38;5;241m=\u001b[39m indv\u001b[38;5;241m.\u001b[39msolution\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Create and train LSTM model\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_and_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_accuracy\n",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m, in \u001b[0;36mcreate_and_train_model\u001b[1;34m(units1, units2, dropout_rate, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Return the validation accuracy as the fitness\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\keras\\src\\engine\\training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1855\u001b[0m     )\n\u001b[1;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1871\u001b[0m }\n\u001b[0;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\keras\\src\\engine\\training.py:2285\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautotune_steps_per_execution:\n\u001b[0;32m   2284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_tuner\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m-> 2285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m   2286\u001b[0m     _,\n\u001b[0;32m   2287\u001b[0m     dataset_or_iterator,\n\u001b[0;32m   2288\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1341\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:500\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    499\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:706\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    702\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 706\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:745\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    742\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    743\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    744\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 745\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3421\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3420\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3421\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3422\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3424\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "def create_and_train_model(units1, units2, dropout_rate, learning_rate, epochs, batch_size):\n",
    "    print(\"\\n\\nNew generation training start. Parameters:\")\n",
    "    print(f\"Units1: {units1}, Units2: {units2}, Dropout Rate: {dropout_rate}, Learning Rate: {learning_rate}, Epochs: {epochs}, Batch Size: {batch_size}\\n\")\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(units1), input_shape=(1, X_train.shape[1]), return_sequences=True))\n",
    "    model.add(LSTM(units=int(units2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=len(df['DataCenterID'].unique()), activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train_lstm, y_train, epochs=int(epochs), batch_size=int(batch_size), validation_data=(X_val_lstm, y_val), callbacks=[early_stopping])\n",
    "\n",
    "    # Return the validation accuracy as the fitness\n",
    "    return history.history['accuracy'][-1]\n",
    "\n",
    "# Define individual\n",
    "indv_template = BinaryIndividual(ranges=[(10, 100), (10, 100), (0.0, 1.0), (0.001, 0.1), (10, 100), (10, 100)])\n",
    "\n",
    "# Create population\n",
    "population = Population(indv_template=indv_template, size=50).init()\n",
    "\n",
    "# Define Genetic Algorithm operators\n",
    "selection = RouletteWheelSelection()\n",
    "crossover = UniformCrossover(pc=0.8, pe=0.5)\n",
    "mutation = FlipBitMutation(pm=0.1)\n",
    "\n",
    "# Create Genetic Algorithm engine\n",
    "engine = GAEngine(population=population, selection=selection, crossover=crossover, mutation=mutation)\n",
    "\n",
    "# Define and register fitness function\n",
    "@engine.fitness_register\n",
    "def fitness(indv):\n",
    "    # Decode GA individual to LSTM parameters\n",
    "    units1, units2, dropout_rate, learning_rate, epochs, batch_size = indv.solution\n",
    "\n",
    "    # Create and train LSTM model\n",
    "    val_accuracy = create_and_train_model(units1, units2, dropout_rate, learning_rate, epochs, batch_size)\n",
    "    \n",
    "    return val_accuracy\n",
    "\n",
    "# Run the Genetic Algorithm\n",
    "engine.run(ng=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3068fff7-be5b-41a2-b8a8-59e581f2a530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"D:\\python\\python3115\\Scripts\\jupyter-nbconvert.EXE\\__main__.py\", line 4, in <module>\n",
      "  File \"D:\\python\\python3115\\Lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 186, in <module>\n",
      "    class NbConvertApp(JupyterApp):\n",
      "  File \"D:\\python\\python3115\\Lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 245, in NbConvertApp\n",
      "    Options include {get_export_names()}.\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\python\\python3115\\Lib\\site-packages\\nbconvert\\exporters\\base.py\", line 151, in get_export_names\n",
      "    e = get_exporter(exporter_name)(config=config)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\python\\python3115\\Lib\\site-packages\\nbconvert\\exporters\\base.py\", line 110, in get_exporter\n",
      "    exporter = items[0].load()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"D:\\python\\python3115\\Lib\\importlib\\metadata\\__init__.py\", line 202, in load\n",
      "    module = import_module(match.group('module'))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\python\\python3115\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\python\\python3115\\Lib\\site-packages\\jupyter_contrib_nbextensions\\__init__.py\", line 5, in <module>\n",
      "    import jupyter_nbextensions_configurator\n",
      "  File \"D:\\python\\python3115\\Lib\\site-packages\\jupyter_nbextensions_configurator\\__init__.py\", line 18, in <module>\n",
      "    from notebook.base.handlers import APIHandler, IPythonHandler\n",
      "ModuleNotFoundError: No module named 'notebook.base'\n"
     ]
    }
   ],
   "source": [
    "! jupyter nbconvert --to script ga_lstm_v3.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d9814-938b-43a4-9854-9e9d91f610a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": ".venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
