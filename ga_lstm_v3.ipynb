{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b169ee5-9af7-43dd-ae0f-f7c7f7e10bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense , Dropout\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.models import save_model, load_model\n",
    "\n",
    "\n",
    "from gaft import GAEngine\n",
    "from gaft.components import BinaryIndividual, Population\n",
    "from gaft.operators import RouletteWheelSelection, UniformCrossover, FlipBitMutation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping,Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89afc85-2ead-40eb-9d9c-183003063ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TaskID', 'TaskFileSize', 'TaskOutputFileSize', 'TaskFileLength',\n",
      "       'DataCenterID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset\\Task_DataSet.csv')\n",
    "\n",
    "\n",
    "X = df.drop(columns=['DataCenterID'])\n",
    "y = df['DataCenterID']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f50928-b8fe-4229-919e-609bf4d05a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e8a54f-e3f1-4480-a5d2-49b029b67855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/250\n",
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "40/40 [==============================] - 6s 34ms/step - loss: 1.1067 - accuracy: 0.2944 - val_loss: 1.0972 - val_accuracy: 0.3333\n",
      "Epoch 2/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.1005 - accuracy: 0.3347 - val_loss: 1.1032 - val_accuracy: 0.3500\n",
      "Epoch 3/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.1012 - accuracy: 0.3319 - val_loss: 1.0988 - val_accuracy: 0.3222\n",
      "Epoch 4/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.1006 - accuracy: 0.3319 - val_loss: 1.0991 - val_accuracy: 0.3389\n",
      "Epoch 5/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3458 - val_loss: 1.0975 - val_accuracy: 0.3444\n",
      "Epoch 6/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3583 - val_loss: 1.0999 - val_accuracy: 0.3556\n",
      "Epoch 7/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0975 - accuracy: 0.3486 - val_loss: 1.1050 - val_accuracy: 0.3389\n",
      "Epoch 8/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0973 - accuracy: 0.3542 - val_loss: 1.1011 - val_accuracy: 0.3611\n",
      "Epoch 9/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3472 - val_loss: 1.1007 - val_accuracy: 0.3333\n",
      "Epoch 10/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0978 - accuracy: 0.3403 - val_loss: 1.1010 - val_accuracy: 0.3611\n",
      "Epoch 11/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0965 - accuracy: 0.3486 - val_loss: 1.1047 - val_accuracy: 0.3944\n",
      "Epoch 12/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0987 - accuracy: 0.3458 - val_loss: 1.1033 - val_accuracy: 0.3556\n",
      "Epoch 13/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0949 - accuracy: 0.3681 - val_loss: 1.1133 - val_accuracy: 0.3500\n",
      "Epoch 14/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0951 - accuracy: 0.3500 - val_loss: 1.1041 - val_accuracy: 0.3667\n",
      "Epoch 15/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0936 - accuracy: 0.3625 - val_loss: 1.1101 - val_accuracy: 0.3611\n",
      "Epoch 16/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0895 - accuracy: 0.3806 - val_loss: 1.1106 - val_accuracy: 0.3667\n",
      "Epoch 17/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0875 - accuracy: 0.3653 - val_loss: 1.1075 - val_accuracy: 0.3444\n",
      "Epoch 18/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0916 - accuracy: 0.3736 - val_loss: 1.1130 - val_accuracy: 0.3222\n",
      "Epoch 19/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0860 - accuracy: 0.3958 - val_loss: 1.1206 - val_accuracy: 0.3389\n",
      "Epoch 20/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0834 - accuracy: 0.3889 - val_loss: 1.1167 - val_accuracy: 0.3611\n",
      "Epoch 21/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0827 - accuracy: 0.3514 - val_loss: 1.1133 - val_accuracy: 0.3389\n",
      "Epoch 22/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0792 - accuracy: 0.3833 - val_loss: 1.1282 - val_accuracy: 0.3667\n",
      "Epoch 23/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0806 - accuracy: 0.3903 - val_loss: 1.1319 - val_accuracy: 0.3500\n",
      "Epoch 24/250\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 1.0768 - accuracy: 0.3986 - val_loss: 1.1255 - val_accuracy: 0.3278\n",
      "Epoch 25/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.0775 - accuracy: 0.3944 - val_loss: 1.1368 - val_accuracy: 0.3444\n",
      "Epoch 26/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0707 - accuracy: 0.4056 - val_loss: 1.1392 - val_accuracy: 0.3000\n",
      "Epoch 27/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0693 - accuracy: 0.4111 - val_loss: 1.1427 - val_accuracy: 0.3278\n",
      "Epoch 28/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0707 - accuracy: 0.4097 - val_loss: 1.1273 - val_accuracy: 0.3556\n",
      "Epoch 29/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0621 - accuracy: 0.4000 - val_loss: 1.1478 - val_accuracy: 0.3278\n",
      "Epoch 30/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0633 - accuracy: 0.4389 - val_loss: 1.1558 - val_accuracy: 0.3333\n",
      "Epoch 31/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0584 - accuracy: 0.4361 - val_loss: 1.1393 - val_accuracy: 0.3278\n",
      "Epoch 32/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0522 - accuracy: 0.4417 - val_loss: 1.1579 - val_accuracy: 0.3500\n",
      "Epoch 33/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0569 - accuracy: 0.4278 - val_loss: 1.1571 - val_accuracy: 0.3222\n",
      "Epoch 34/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0499 - accuracy: 0.4431 - val_loss: 1.1549 - val_accuracy: 0.3278\n",
      "Epoch 35/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0496 - accuracy: 0.4472 - val_loss: 1.1748 - val_accuracy: 0.3500\n",
      "Epoch 36/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0430 - accuracy: 0.4500 - val_loss: 1.1734 - val_accuracy: 0.3500\n",
      "Epoch 37/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0471 - accuracy: 0.4389 - val_loss: 1.1539 - val_accuracy: 0.3444\n",
      "Epoch 38/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0371 - accuracy: 0.4514 - val_loss: 1.1731 - val_accuracy: 0.3167\n",
      "Epoch 39/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0344 - accuracy: 0.4347 - val_loss: 1.1720 - val_accuracy: 0.3333\n",
      "Epoch 40/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0276 - accuracy: 0.4389 - val_loss: 1.1841 - val_accuracy: 0.3167\n",
      "Epoch 41/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0309 - accuracy: 0.4556 - val_loss: 1.1663 - val_accuracy: 0.3444\n",
      "Epoch 42/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0200 - accuracy: 0.4722 - val_loss: 1.2026 - val_accuracy: 0.3389\n",
      "Epoch 43/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0281 - accuracy: 0.4514 - val_loss: 1.1875 - val_accuracy: 0.3389\n",
      "Epoch 44/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0170 - accuracy: 0.4639 - val_loss: 1.2099 - val_accuracy: 0.3222\n",
      "Epoch 45/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0025 - accuracy: 0.4778 - val_loss: 1.2045 - val_accuracy: 0.3056\n",
      "Epoch 46/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0104 - accuracy: 0.4653 - val_loss: 1.2107 - val_accuracy: 0.3111\n",
      "Epoch 47/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4597 - val_loss: 1.2283 - val_accuracy: 0.3389\n",
      "Epoch 48/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0068 - accuracy: 0.4736 - val_loss: 1.2211 - val_accuracy: 0.3222\n",
      "Epoch 49/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0048 - accuracy: 0.4722 - val_loss: 1.2084 - val_accuracy: 0.3500\n",
      "Epoch 50/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9996 - accuracy: 0.4889 - val_loss: 1.2165 - val_accuracy: 0.3444\n",
      "Epoch 51/250\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 1.0045 - accuracy: 0.4806 - val_loss: 1.2040 - val_accuracy: 0.3167\n",
      "Epoch 52/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0032 - accuracy: 0.4750 - val_loss: 1.1993 - val_accuracy: 0.3444\n",
      "Epoch 53/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9809 - accuracy: 0.5000 - val_loss: 1.2439 - val_accuracy: 0.3444\n",
      "Epoch 54/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9831 - accuracy: 0.5014 - val_loss: 1.2174 - val_accuracy: 0.3167\n",
      "Epoch 55/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9806 - accuracy: 0.4764 - val_loss: 1.2260 - val_accuracy: 0.3389\n",
      "Epoch 56/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9762 - accuracy: 0.5111 - val_loss: 1.2174 - val_accuracy: 0.3667\n",
      "Epoch 57/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9726 - accuracy: 0.4986 - val_loss: 1.2286 - val_accuracy: 0.3389\n",
      "Epoch 58/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9715 - accuracy: 0.5069 - val_loss: 1.2522 - val_accuracy: 0.3333\n",
      "Epoch 59/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9682 - accuracy: 0.4847 - val_loss: 1.2730 - val_accuracy: 0.3333\n",
      "Epoch 60/250\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.9599 - accuracy: 0.5014 - val_loss: 1.2558 - val_accuracy: 0.3500\n",
      "Epoch 61/250\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.9571 - accuracy: 0.5167 - val_loss: 1.2332 - val_accuracy: 0.3611\n",
      "Epoch 62/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9523 - accuracy: 0.4958 - val_loss: 1.2751 - val_accuracy: 0.3111\n",
      "Epoch 63/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9501 - accuracy: 0.5264 - val_loss: 1.2760 - val_accuracy: 0.3278\n",
      "Epoch 64/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9365 - accuracy: 0.5181 - val_loss: 1.2720 - val_accuracy: 0.3444\n",
      "Epoch 65/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9491 - accuracy: 0.5083 - val_loss: 1.2947 - val_accuracy: 0.3278\n",
      "Epoch 66/250\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.9199 - accuracy: 0.5292 - val_loss: 1.3368 - val_accuracy: 0.3611\n",
      "Epoch 67/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9363 - accuracy: 0.5208 - val_loss: 1.2957 - val_accuracy: 0.3444\n",
      "Epoch 68/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9255 - accuracy: 0.5236 - val_loss: 1.3335 - val_accuracy: 0.3444\n",
      "Epoch 69/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9116 - accuracy: 0.5472 - val_loss: 1.3016 - val_accuracy: 0.3611\n",
      "Epoch 70/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.9117 - accuracy: 0.5347 - val_loss: 1.3190 - val_accuracy: 0.3556\n",
      "Epoch 71/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9118 - accuracy: 0.5250 - val_loss: 1.2988 - val_accuracy: 0.3278\n",
      "Epoch 72/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9188 - accuracy: 0.5264 - val_loss: 1.3252 - val_accuracy: 0.3333\n",
      "Epoch 73/250\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.8920 - accuracy: 0.5444 - val_loss: 1.3638 - val_accuracy: 0.3778\n",
      "Epoch 74/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9028 - accuracy: 0.5403 - val_loss: 1.3360 - val_accuracy: 0.3778\n",
      "Epoch 75/250\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.8803 - accuracy: 0.5639 - val_loss: 1.3920 - val_accuracy: 0.3667\n",
      "Epoch 76/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8965 - accuracy: 0.5278 - val_loss: 1.3863 - val_accuracy: 0.3444\n",
      "Epoch 77/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8738 - accuracy: 0.5542 - val_loss: 1.4082 - val_accuracy: 0.3389\n",
      "Epoch 78/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8695 - accuracy: 0.5514 - val_loss: 1.4463 - val_accuracy: 0.3444\n",
      "Epoch 79/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8717 - accuracy: 0.5694 - val_loss: 1.4097 - val_accuracy: 0.3833\n",
      "Epoch 80/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8454 - accuracy: 0.5917 - val_loss: 1.4073 - val_accuracy: 0.3556\n",
      "Epoch 81/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8590 - accuracy: 0.5903 - val_loss: 1.4224 - val_accuracy: 0.3389\n",
      "Epoch 82/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8594 - accuracy: 0.5639 - val_loss: 1.4718 - val_accuracy: 0.3389\n",
      "Epoch 83/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8069 - accuracy: 0.6056 - val_loss: 1.4748 - val_accuracy: 0.3389\n",
      "Epoch 84/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.8279 - accuracy: 0.5903 - val_loss: 1.5190 - val_accuracy: 0.3500\n",
      "Epoch 85/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8157 - accuracy: 0.5958 - val_loss: 1.5482 - val_accuracy: 0.3722\n",
      "Epoch 86/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8317 - accuracy: 0.5833 - val_loss: 1.5207 - val_accuracy: 0.3389\n",
      "Epoch 87/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8274 - accuracy: 0.5958 - val_loss: 1.5794 - val_accuracy: 0.3611\n",
      "Epoch 88/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7971 - accuracy: 0.6056 - val_loss: 1.5482 - val_accuracy: 0.3500\n",
      "Epoch 89/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8045 - accuracy: 0.5861 - val_loss: 1.6062 - val_accuracy: 0.3611\n",
      "Epoch 90/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.6153 - val_loss: 1.6752 - val_accuracy: 0.3611\n",
      "Epoch 91/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7992 - accuracy: 0.6125 - val_loss: 1.6398 - val_accuracy: 0.3611\n",
      "Epoch 92/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7568 - accuracy: 0.6194 - val_loss: 1.6110 - val_accuracy: 0.4167\n",
      "Epoch 93/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7673 - accuracy: 0.6222 - val_loss: 1.5838 - val_accuracy: 0.3556\n",
      "Epoch 94/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7506 - accuracy: 0.6264 - val_loss: 1.6784 - val_accuracy: 0.3500\n",
      "Epoch 95/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7403 - accuracy: 0.6472 - val_loss: 1.6743 - val_accuracy: 0.3556\n",
      "Epoch 96/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.7365 - accuracy: 0.6389 - val_loss: 1.7166 - val_accuracy: 0.3722\n",
      "Epoch 97/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.7441 - accuracy: 0.6611 - val_loss: 1.7162 - val_accuracy: 0.3889\n",
      "Epoch 98/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7014 - accuracy: 0.6528 - val_loss: 1.8454 - val_accuracy: 0.3333\n",
      "Epoch 99/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7392 - accuracy: 0.6333 - val_loss: 1.9091 - val_accuracy: 0.3278\n",
      "Epoch 100/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.7518 - accuracy: 0.6375 - val_loss: 1.8596 - val_accuracy: 0.3278\n",
      "Epoch 101/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.6667 - val_loss: 1.8196 - val_accuracy: 0.3444\n",
      "Epoch 102/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7309 - accuracy: 0.6361 - val_loss: 1.8502 - val_accuracy: 0.3889\n",
      "Epoch 103/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7190 - accuracy: 0.6486 - val_loss: 1.8862 - val_accuracy: 0.3444\n",
      "Epoch 104/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6551 - accuracy: 0.6736 - val_loss: 1.9881 - val_accuracy: 0.3611\n",
      "Epoch 105/250\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7057 - accuracy: 0.6528 - val_loss: 1.8101 - val_accuracy: 0.3500\n",
      "Epoch 106/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6683 - accuracy: 0.6819 - val_loss: 1.9896 - val_accuracy: 0.3667\n",
      "Epoch 107/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6641 - accuracy: 0.6903 - val_loss: 1.9304 - val_accuracy: 0.3611\n",
      "Epoch 108/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6875 - accuracy: 0.6625 - val_loss: 1.9201 - val_accuracy: 0.3722\n",
      "Epoch 109/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6662 - accuracy: 0.6806 - val_loss: 2.0210 - val_accuracy: 0.3611\n",
      "Epoch 110/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6702 - accuracy: 0.6819 - val_loss: 2.1025 - val_accuracy: 0.3222\n",
      "Epoch 111/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.7042 - val_loss: 2.0134 - val_accuracy: 0.3722\n",
      "Epoch 112/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6257 - accuracy: 0.7028 - val_loss: 2.2205 - val_accuracy: 0.3778\n",
      "Epoch 113/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5960 - accuracy: 0.7292 - val_loss: 2.2352 - val_accuracy: 0.3667\n",
      "Epoch 114/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6002 - accuracy: 0.7236 - val_loss: 2.2049 - val_accuracy: 0.3389\n",
      "Epoch 115/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6209 - accuracy: 0.7097 - val_loss: 2.2225 - val_accuracy: 0.3667\n",
      "Epoch 116/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5991 - accuracy: 0.7083 - val_loss: 2.2239 - val_accuracy: 0.3500\n",
      "Epoch 117/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6111 - accuracy: 0.7111 - val_loss: 2.3540 - val_accuracy: 0.3833\n",
      "Epoch 118/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5628 - accuracy: 0.7569 - val_loss: 2.3742 - val_accuracy: 0.3333\n",
      "Epoch 119/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5816 - accuracy: 0.7222 - val_loss: 2.4188 - val_accuracy: 0.3278\n",
      "Epoch 120/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5861 - accuracy: 0.7236 - val_loss: 2.2469 - val_accuracy: 0.3444\n",
      "Epoch 121/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7500 - val_loss: 2.5123 - val_accuracy: 0.3167\n",
      "Epoch 122/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5455 - accuracy: 0.7542 - val_loss: 2.4906 - val_accuracy: 0.3778\n",
      "Epoch 123/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7667 - val_loss: 2.4837 - val_accuracy: 0.3278\n",
      "Epoch 124/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7667 - val_loss: 2.5772 - val_accuracy: 0.3389\n",
      "Epoch 125/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7444 - val_loss: 2.4818 - val_accuracy: 0.3500\n",
      "Epoch 126/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7736 - val_loss: 2.5456 - val_accuracy: 0.3556\n",
      "Epoch 127/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.7708 - val_loss: 2.5895 - val_accuracy: 0.3500\n",
      "Epoch 128/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.5233 - accuracy: 0.7625 - val_loss: 2.6558 - val_accuracy: 0.3444\n",
      "Epoch 129/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5315 - accuracy: 0.7556 - val_loss: 2.6522 - val_accuracy: 0.3500\n",
      "Epoch 130/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5092 - accuracy: 0.7764 - val_loss: 2.6695 - val_accuracy: 0.3556\n",
      "Epoch 131/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4900 - accuracy: 0.7792 - val_loss: 2.7827 - val_accuracy: 0.3389\n",
      "Epoch 132/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.7750 - val_loss: 2.7515 - val_accuracy: 0.3611\n",
      "Epoch 133/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4975 - accuracy: 0.7694 - val_loss: 2.7139 - val_accuracy: 0.3722\n",
      "Epoch 134/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4873 - accuracy: 0.7833 - val_loss: 2.7404 - val_accuracy: 0.3611\n",
      "Epoch 135/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4989 - accuracy: 0.7806 - val_loss: 2.7623 - val_accuracy: 0.3500\n",
      "Epoch 136/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4882 - accuracy: 0.7764 - val_loss: 2.7373 - val_accuracy: 0.3667\n",
      "Epoch 137/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4650 - accuracy: 0.7986 - val_loss: 2.7978 - val_accuracy: 0.3722\n",
      "Epoch 138/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.8167 - val_loss: 2.8957 - val_accuracy: 0.3722\n",
      "Epoch 139/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.8139 - val_loss: 2.9576 - val_accuracy: 0.3611\n",
      "Epoch 140/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.8319 - val_loss: 2.9626 - val_accuracy: 0.3667\n",
      "Epoch 141/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7958 - val_loss: 3.1734 - val_accuracy: 0.3389\n",
      "Epoch 142/250\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 3.0934 - val_accuracy: 0.3556\n",
      "Epoch 143/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 3.0899 - val_accuracy: 0.3722\n",
      "Epoch 144/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8181 - val_loss: 3.0239 - val_accuracy: 0.3556\n",
      "Epoch 145/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4617 - accuracy: 0.8139 - val_loss: 2.9570 - val_accuracy: 0.3722\n",
      "Epoch 146/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8292 - val_loss: 3.0412 - val_accuracy: 0.3611\n",
      "Epoch 147/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.8014 - val_loss: 3.0157 - val_accuracy: 0.3833\n",
      "Epoch 148/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8222 - val_loss: 3.1153 - val_accuracy: 0.3833\n",
      "Epoch 149/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3854 - accuracy: 0.8389 - val_loss: 3.1045 - val_accuracy: 0.3833\n",
      "Epoch 150/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8222 - val_loss: 3.1449 - val_accuracy: 0.3833\n",
      "Epoch 151/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.8097 - val_loss: 3.1052 - val_accuracy: 0.3722\n",
      "Epoch 152/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.8097 - val_loss: 3.1500 - val_accuracy: 0.3889\n",
      "Epoch 153/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8319 - val_loss: 3.1216 - val_accuracy: 0.3667\n",
      "Epoch 154/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3675 - accuracy: 0.8347 - val_loss: 3.2749 - val_accuracy: 0.3778\n",
      "Epoch 155/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3855 - accuracy: 0.8278 - val_loss: 3.4479 - val_accuracy: 0.3667\n",
      "Epoch 156/250\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3447 - accuracy: 0.8417 - val_loss: 3.4563 - val_accuracy: 0.3667\n",
      "Epoch 157/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3786 - accuracy: 0.8514 - val_loss: 3.3474 - val_accuracy: 0.3556\n",
      "Epoch 158/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8472 - val_loss: 3.3798 - val_accuracy: 0.3444\n",
      "Epoch 159/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3543 - accuracy: 0.8389 - val_loss: 3.3209 - val_accuracy: 0.4000\n",
      "Epoch 160/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3364 - accuracy: 0.8625 - val_loss: 3.3810 - val_accuracy: 0.3667\n",
      "Epoch 161/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3465 - accuracy: 0.8528 - val_loss: 3.3922 - val_accuracy: 0.3611\n",
      "Epoch 162/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.8750 - val_loss: 3.3880 - val_accuracy: 0.3778\n",
      "Epoch 163/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3302 - accuracy: 0.8681 - val_loss: 3.6707 - val_accuracy: 0.3778\n",
      "Epoch 164/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.8694 - val_loss: 3.6457 - val_accuracy: 0.3611\n",
      "Epoch 165/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3206 - accuracy: 0.8667 - val_loss: 3.6540 - val_accuracy: 0.3833\n",
      "Epoch 166/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2979 - accuracy: 0.8694 - val_loss: 3.7629 - val_accuracy: 0.3778\n",
      "Epoch 167/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3228 - accuracy: 0.8569 - val_loss: 3.5970 - val_accuracy: 0.3611\n",
      "Epoch 168/250\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3036 - accuracy: 0.8778 - val_loss: 3.8864 - val_accuracy: 0.3889\n",
      "Epoch 169/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3152 - accuracy: 0.8764 - val_loss: 3.9840 - val_accuracy: 0.3722\n",
      "Epoch 170/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.8667 - val_loss: 3.8192 - val_accuracy: 0.3944\n",
      "Epoch 171/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2855 - accuracy: 0.8764 - val_loss: 3.8823 - val_accuracy: 0.3611\n",
      "Epoch 172/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3242 - accuracy: 0.8722 - val_loss: 3.8943 - val_accuracy: 0.3778\n",
      "Epoch 173/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8389 - val_loss: 3.9347 - val_accuracy: 0.3722\n",
      "Epoch 174/250\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3208 - accuracy: 0.8764 - val_loss: 3.7483 - val_accuracy: 0.3889\n",
      "Epoch 175/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3033 - accuracy: 0.8681 - val_loss: 3.8192 - val_accuracy: 0.4000\n",
      "Epoch 176/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3106 - accuracy: 0.8736 - val_loss: 3.7311 - val_accuracy: 0.3722\n",
      "Epoch 177/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3226 - accuracy: 0.8764 - val_loss: 3.9840 - val_accuracy: 0.4000\n",
      "Epoch 178/250\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3164 - accuracy: 0.8736 - val_loss: 3.8494 - val_accuracy: 0.3667\n"
     ]
    }
   ],
   "source": [
    "# Reshape data for LSTM input (assuming a time series sequence length of 1)\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val_lstm = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "#this params values from GA algorithm\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=int(54), input_shape=(1, X_train.shape[1]), return_sequences=True))\n",
    "model.add(LSTM(units=int(62)))\n",
    "model.add(Dropout(0.08203125))\n",
    "model.add(Dense(units=len(df['DataCenterID'].unique()), activation='softmax'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.014921875000000001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "history=model.fit(X_train_lstm, y_train, epochs=120, batch_size=18, validation_data=(X_val_lstm, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9900b8-d6b4-4180-97ff-5e158f354e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 5ms/step - loss: 3.8864 - accuracy: 0.3889\n",
      "Test Loss: 3.8864\n",
      "Test Accuracy: 38.89%\n",
      "6/6 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_lstm = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_lstm, y_val)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "y_pred = model.predict(X_test_lstm)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc415ae0-bdac-4fa2-90c4-2077a5a5b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.38      0.39        66\n",
      "           1       0.42      0.34      0.38        56\n",
      "           2       0.36      0.45      0.40        58\n",
      "\n",
      "    accuracy                           0.39       180\n",
      "   macro avg       0.39      0.39      0.39       180\n",
      "weighted avg       0.39      0.39      0.39       180\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_classes))\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "\n",
    "# Create a colorful confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5acc8031-c249-4412-9b0e-94e60185eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models\\lstm87.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186c0b11-06a0-4bb9-b02e-fcdfece4e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted DataCenterID: 1\n"
     ]
    }
   ],
   "source": [
    "def predict_datacenter_id(requested_array,model_name):\n",
    "    data_dict = {\n",
    "        \"TaskID\": requested_array[0],\n",
    "        \"TaskFileSize\": requested_array[1],\n",
    "        \"TaskOutputFileSize\": requested_array[2],\n",
    "        \"TaskFileLength\": requested_array[3],\n",
    "\n",
    "    }\n",
    "    input_data = np.array([[\n",
    "        data_dict[\"TaskID\"],\n",
    "        data_dict[\"TaskFileSize\"],\n",
    "        data_dict[\"TaskOutputFileSize\"],\n",
    "        data_dict[\"TaskFileLength\"]]])\n",
    "    # Load the saved model\n",
    "    loaded_model = load_model(model_name)\n",
    "    # Reshape the input data to match the LSTM input shape\n",
    "    input_data_lstm = input_data.reshape(input_data.shape[0], 1, input_data.shape[1])\n",
    "    # Make predictions using the loaded model\n",
    "    predicted_probabilities = loaded_model.predict(input_data_lstm)\n",
    "    predicted_class = np.argmax(predicted_probabilities, axis=1)\n",
    "    predicted_DC=predicted_class[0]\n",
    "    return predicted_DC\n",
    "requested_array = [0.1, 0, 0, 55]\n",
    "predicted_datacenter_id = predict_datacenter_id(requested_array,\"models\\lstm87.keras\")\n",
    "print(f\"Predicted DataCenterID: {predicted_datacenter_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333079b5-a452-4b7d-96f8-4c0838e1bf14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "def create_and_train_model(units1, units2, dropout_rate, learning_rate, epochs, batch_size):\n",
    "    print(\"\\n\\nNew generation training start. Parameters:\")\n",
    "    print(f\"Units1: {units1}, Units2: {units2}, Dropout Rate: {dropout_rate}, Learning Rate: {learning_rate}, Epochs: {epochs}, Batch Size: {batch_size}\\n\")\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(units1), input_shape=(1, X_train.shape[1]), return_sequences=True))\n",
    "    model.add(LSTM(units=int(units2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=len(df['DataCenterID'].unique()), activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train_lstm, y_train, epochs=int(epochs), batch_size=int(batch_size), validation_data=(X_val_lstm, y_val), callbacks=[early_stopping])\n",
    "\n",
    "    # Return the validation accuracy as the fitness\n",
    "    return history.history['accuracy'][-1]\n",
    "\n",
    "# Define individual\n",
    "indv_template = BinaryIndividual(ranges=[(10, 100), (10, 100), (0.0, 1.0), (0.001, 0.1), (10, 100), (10, 100)])\n",
    "\n",
    "# Create population\n",
    "population = Population(indv_template=indv_template, size=50).init()\n",
    "\n",
    "# Define Genetic Algorithm operators\n",
    "selection = RouletteWheelSelection()\n",
    "crossover = UniformCrossover(pc=0.8, pe=0.5)\n",
    "mutation = FlipBitMutation(pm=0.1)\n",
    "\n",
    "# Create Genetic Algorithm engine\n",
    "engine = GAEngine(population=population, selection=selection, crossover=crossover, mutation=mutation)\n",
    "\n",
    "# Define and register fitness function\n",
    "@engine.fitness_register\n",
    "def fitness(indv):\n",
    "    # Decode GA individual to LSTM parameters\n",
    "    units1, units2, dropout_rate, learning_rate, epochs, batch_size = indv.solution\n",
    "\n",
    "    # Create and train LSTM model\n",
    "    val_accuracy = create_and_train_model(units1, units2, dropout_rate, learning_rate, epochs, batch_size)\n",
    "    \n",
    "    return val_accuracy\n",
    "\n",
    "# Run the Genetic Algorithm\n",
    "engine.run(ng=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": ".venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
