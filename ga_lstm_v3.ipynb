{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b169ee5-9af7-43dd-ae0f-f7c7f7e10bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense , Dropout\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.models import save_model, load_model\n",
    "\n",
    "\n",
    "from gaft import GAEngine\n",
    "from gaft.components import BinaryIndividual, Population\n",
    "from gaft.operators import RouletteWheelSelection, UniformCrossover, FlipBitMutation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping,Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89afc85-2ead-40eb-9d9c-183003063ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TaskID', 'StartTime', 'TaskFileSize', 'TaskOutputFileSize',\n",
      "       'TaskFileLength', 'DataCenterID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('resourcesxxx.csv')\n",
    "df = df.drop(columns= [\n",
    "'DistanceFromDataCenter',\n",
    "'DataCenterCpuCost',\n",
    "'DataCenterRamCost',\n",
    "'DataCenterStorageCost',\n",
    "'DataCenterBwCost',\n",
    "'DataCenterTotalLoad',\n",
    "'NetworkDelay',\n",
    "'CET',\n",
    "'ObjectiveFunction'\n",
    "])\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['DataCenterID'])\n",
    "y = df['DataCenterID']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f50928-b8fe-4229-919e-609bf4d05a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e8a54f-e3f1-4480-a5d2-49b029b67855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\python\\python3115\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "23/23 [==============================] - 7s 64ms/step - loss: 2.0966 - accuracy: 0.3486 - val_loss: 1.1888 - val_accuracy: 0.3222\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1342 - accuracy: 0.3431 - val_loss: 1.1396 - val_accuracy: 0.3222\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1102 - accuracy: 0.3708 - val_loss: 1.1234 - val_accuracy: 0.3333\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1049 - accuracy: 0.3861 - val_loss: 1.1212 - val_accuracy: 0.3278\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1014 - accuracy: 0.3764 - val_loss: 1.1181 - val_accuracy: 0.3222\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0989 - accuracy: 0.3764 - val_loss: 1.1154 - val_accuracy: 0.3444\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.0976 - accuracy: 0.3778 - val_loss: 1.1139 - val_accuracy: 0.3444\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0977 - accuracy: 0.3750 - val_loss: 1.1116 - val_accuracy: 0.3444\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0968 - accuracy: 0.3625 - val_loss: 1.1140 - val_accuracy: 0.3389\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0960 - accuracy: 0.3681 - val_loss: 1.1125 - val_accuracy: 0.3167\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.0947 - accuracy: 0.3944 - val_loss: 1.1144 - val_accuracy: 0.3389\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0965 - accuracy: 0.3542 - val_loss: 1.1119 - val_accuracy: 0.3389\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0954 - accuracy: 0.3583 - val_loss: 1.1093 - val_accuracy: 0.3444\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0955 - accuracy: 0.3569 - val_loss: 1.1107 - val_accuracy: 0.3167\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0922 - accuracy: 0.3681 - val_loss: 1.1095 - val_accuracy: 0.3222\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0930 - accuracy: 0.3667 - val_loss: 1.1101 - val_accuracy: 0.3222\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0929 - accuracy: 0.3736 - val_loss: 1.1082 - val_accuracy: 0.3278\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0934 - accuracy: 0.3764 - val_loss: 1.1120 - val_accuracy: 0.3167\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0915 - accuracy: 0.3722 - val_loss: 1.1085 - val_accuracy: 0.3389\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0931 - accuracy: 0.3694 - val_loss: 1.1098 - val_accuracy: 0.3167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cbe02ec50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape data for LSTM input (assuming a time series sequence length of 1)\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val_lstm = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model.add(LSTM(units=50, input_shape=(1, X_train.shape[1]), return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=len(df['DataCenterID'].unique()), activation='relu'))\n",
    "num_classes = len(df['DataCenterID'].unique())\n",
    "model.add(Dense(units=num_classes, activation='relu'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_lstm, y_train, epochs=20, batch_size=32, validation_data=(X_val_lstm, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9900b8-d6b4-4180-97ff-5e158f354e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1098 - accuracy: 0.3167\n",
      "Test Loss: 1.1098\n",
      "Test Accuracy: 31.67%\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "(180, 1, 5)\n",
      "[[ 1.57004819  0.61002266  1.01023359  1.30823833 -1.17251774]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have your X_test and y_test prepared similarly to X_train and y_train\n",
    "X_test_lstm = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test_lstm, y_val)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_lstm)\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(X_test_lstm.shape)\n",
    "print(X_test_lstm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc415ae0-bdac-4fa2-90c4-2077a5a5b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.62      0.45        66\n",
      "           1       0.27      0.27      0.27        56\n",
      "           2       0.14      0.02      0.03        58\n",
      "\n",
      "    accuracy                           0.32       180\n",
      "   macro avg       0.25      0.30      0.25       180\n",
      "weighted avg       0.26      0.32      0.26       180\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_classes))\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "\n",
    "# Create a colorful confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acc8031-c249-4412-9b0e-94e60185eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm33.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186c0b11-06a0-4bb9-b02e-fcdfece4e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted DataCenterID: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def predict_datacenter_id(requested_array,model_name):\n",
    "    data_dict = {\n",
    "        \"TaskID\": requested_array[0],\n",
    "        \"StartTime\": requested_array[1],\n",
    "        \"TaskFileSize\": requested_array[2],\n",
    "        \"TaskOutputFileSize\": requested_array[3],\n",
    "        \"TaskFileLength\": requested_array[4],\n",
    "\n",
    "    }\n",
    "    input_data = np.array([[\n",
    "        data_dict[\"TaskID\"],\n",
    "        data_dict[\"StartTime\"],\n",
    "        data_dict[\"TaskFileSize\"],\n",
    "        data_dict[\"TaskOutputFileSize\"],\n",
    "        data_dict[\"TaskFileLength\"]]])\n",
    "    # Load the saved model\n",
    "    loaded_model = load_model(model_name)\n",
    "    # Reshape the input data to match the LSTM input shape\n",
    "    input_data_lstm = input_data.reshape(input_data.shape[0], 1, input_data.shape[1])\n",
    "    # Make predictions using the loaded model\n",
    "    predicted_probabilities = loaded_model.predict(input_data_lstm)\n",
    "    predicted_class = np.argmax(predicted_probabilities, axis=1)\n",
    "    predicted_DC=predicted_class[0]\n",
    "    return predicted_DC\n",
    "requested_array = [0.1, 55, 0, 0, 55]\n",
    "predicted_datacenter_id = predict_datacenter_id(requested_array,\"lstm33.keras\")\n",
    "print(f\"Predicted DataCenterID: {predicted_datacenter_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "333079b5-a452-4b7d-96f8-4c0838e1bf14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 24.025421142578125, Units2: 60.255584716796875, Dropout Rate: 0.193359375, Learning Rate: 0.019562500000000003, Epochs: 80.69976806640625, Batch Size: 54.11285400390625\n",
      "\n",
      "Epoch 1/80\n",
      "14/14 [==============================] - 6s 99ms/step - loss: 1.1031 - accuracy: 0.3111 - val_loss: 1.1004 - val_accuracy: 0.3389\n",
      "Epoch 2/80\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0968 - accuracy: 0.3556 - val_loss: 1.1051 - val_accuracy: 0.3500\n",
      "Epoch 3/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0946 - accuracy: 0.3625 - val_loss: 1.1013 - val_accuracy: 0.3722\n",
      "Epoch 4/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0906 - accuracy: 0.3681 - val_loss: 1.1032 - val_accuracy: 0.3389\n",
      "Epoch 5/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0913 - accuracy: 0.3750 - val_loss: 1.0996 - val_accuracy: 0.4000\n",
      "Epoch 6/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0891 - accuracy: 0.3819 - val_loss: 1.1059 - val_accuracy: 0.3611\n",
      "Epoch 7/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0805 - accuracy: 0.4069 - val_loss: 1.1100 - val_accuracy: 0.3778\n",
      "Epoch 8/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0830 - accuracy: 0.3875 - val_loss: 1.1195 - val_accuracy: 0.3556\n",
      "Epoch 9/80\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0768 - accuracy: 0.3847 - val_loss: 1.1062 - val_accuracy: 0.3667\n",
      "Epoch 10/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0723 - accuracy: 0.4111 - val_loss: 1.1115 - val_accuracy: 0.3722\n",
      "Epoch 11/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0649 - accuracy: 0.4139 - val_loss: 1.1149 - val_accuracy: 0.3611\n",
      "Epoch 12/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0708 - accuracy: 0.4097 - val_loss: 1.1126 - val_accuracy: 0.3278\n",
      "Epoch 13/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0667 - accuracy: 0.4194 - val_loss: 1.1397 - val_accuracy: 0.3167\n",
      "Epoch 14/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0655 - accuracy: 0.4028 - val_loss: 1.1069 - val_accuracy: 0.3444\n",
      "Epoch 15/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0663 - accuracy: 0.4153 - val_loss: 1.1192 - val_accuracy: 0.3333\n",
      "Epoch 16/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0511 - accuracy: 0.4319 - val_loss: 1.1355 - val_accuracy: 0.3444\n",
      "Epoch 17/80\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0472 - accuracy: 0.4417 - val_loss: 1.1337 - val_accuracy: 0.3556\n",
      "Epoch 18/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0402 - accuracy: 0.4278 - val_loss: 1.1283 - val_accuracy: 0.3667\n",
      "Epoch 19/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0384 - accuracy: 0.4583 - val_loss: 1.1415 - val_accuracy: 0.3333\n",
      "Epoch 20/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0316 - accuracy: 0.4528 - val_loss: 1.1565 - val_accuracy: 0.3444\n",
      "Epoch 21/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0235 - accuracy: 0.4347 - val_loss: 1.1445 - val_accuracy: 0.3333\n",
      "Epoch 22/80\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.0170 - accuracy: 0.4542 - val_loss: 1.1719 - val_accuracy: 0.3333\n",
      "Epoch 23/80\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.9962 - accuracy: 0.4708 - val_loss: 1.1413 - val_accuracy: 0.3444\n",
      "Epoch 24/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9977 - accuracy: 0.4764 - val_loss: 1.1628 - val_accuracy: 0.3444\n",
      "Epoch 25/80\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.9917 - accuracy: 0.4861 - val_loss: 1.1696 - val_accuracy: 0.3556\n",
      "Epoch 26/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9812 - accuracy: 0.4875 - val_loss: 1.2296 - val_accuracy: 0.3389\n",
      "Epoch 27/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9742 - accuracy: 0.4736 - val_loss: 1.1857 - val_accuracy: 0.3333\n",
      "Epoch 28/80\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.9762 - accuracy: 0.5028 - val_loss: 1.1909 - val_accuracy: 0.3500\n",
      "Epoch 29/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9678 - accuracy: 0.4833 - val_loss: 1.2008 - val_accuracy: 0.3167\n",
      "Epoch 30/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9387 - accuracy: 0.5167 - val_loss: 1.2498 - val_accuracy: 0.3389\n",
      "Epoch 31/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9386 - accuracy: 0.5069 - val_loss: 1.2398 - val_accuracy: 0.3389\n",
      "Epoch 32/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9402 - accuracy: 0.5222 - val_loss: 1.2351 - val_accuracy: 0.3389\n",
      "Epoch 33/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9251 - accuracy: 0.5139 - val_loss: 1.2364 - val_accuracy: 0.3389\n",
      "Epoch 34/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9103 - accuracy: 0.5167 - val_loss: 1.2498 - val_accuracy: 0.3944\n",
      "Epoch 35/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.8877 - accuracy: 0.5417 - val_loss: 1.3102 - val_accuracy: 0.3611\n",
      "Epoch 36/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9061 - accuracy: 0.5389 - val_loss: 1.2707 - val_accuracy: 0.3667\n",
      "Epoch 37/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8866 - accuracy: 0.5083 - val_loss: 1.2996 - val_accuracy: 0.3556\n",
      "Epoch 38/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.8740 - accuracy: 0.5417 - val_loss: 1.3238 - val_accuracy: 0.3833\n",
      "Epoch 39/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8805 - accuracy: 0.5431 - val_loss: 1.3443 - val_accuracy: 0.3889\n",
      "Epoch 40/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8898 - accuracy: 0.5333 - val_loss: 1.3408 - val_accuracy: 0.3333\n",
      "Epoch 41/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8635 - accuracy: 0.5639 - val_loss: 1.3379 - val_accuracy: 0.3722\n",
      "Epoch 42/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.8587 - accuracy: 0.5597 - val_loss: 1.3621 - val_accuracy: 0.3667\n",
      "Epoch 43/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8411 - accuracy: 0.5569 - val_loss: 1.3283 - val_accuracy: 0.3889\n",
      "Epoch 44/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8466 - accuracy: 0.5667 - val_loss: 1.4196 - val_accuracy: 0.4111\n",
      "Epoch 45/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8266 - accuracy: 0.5556 - val_loss: 1.4085 - val_accuracy: 0.3278\n",
      "Epoch 46/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8136 - accuracy: 0.6028 - val_loss: 1.3994 - val_accuracy: 0.4056\n",
      "Epoch 47/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.7966 - accuracy: 0.5986 - val_loss: 1.4595 - val_accuracy: 0.3778\n",
      "Epoch 48/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7931 - accuracy: 0.6042 - val_loss: 1.4362 - val_accuracy: 0.3833\n",
      "Epoch 49/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7765 - accuracy: 0.5931 - val_loss: 1.4760 - val_accuracy: 0.4111\n",
      "Epoch 50/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7761 - accuracy: 0.6222 - val_loss: 1.5615 - val_accuracy: 0.3500\n",
      "Epoch 51/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.8010 - accuracy: 0.5944 - val_loss: 1.5389 - val_accuracy: 0.4000\n",
      "Epoch 52/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7604 - accuracy: 0.6236 - val_loss: 1.5243 - val_accuracy: 0.3722\n",
      "Epoch 53/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7158 - accuracy: 0.6542 - val_loss: 1.6589 - val_accuracy: 0.3944\n",
      "Epoch 54/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.7295 - accuracy: 0.6167 - val_loss: 1.6000 - val_accuracy: 0.4111\n",
      "Epoch 55/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7298 - accuracy: 0.6306 - val_loss: 1.7290 - val_accuracy: 0.3833\n",
      "Epoch 56/80\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.7219 - accuracy: 0.6375 - val_loss: 1.6428 - val_accuracy: 0.3667\n",
      "Epoch 57/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7224 - accuracy: 0.6569 - val_loss: 1.6544 - val_accuracy: 0.3778\n",
      "Epoch 58/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6826 - accuracy: 0.6653 - val_loss: 1.6949 - val_accuracy: 0.3778\n",
      "Epoch 59/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7030 - accuracy: 0.6514 - val_loss: 1.7275 - val_accuracy: 0.4000\n",
      "Epoch 60/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6888 - accuracy: 0.6639 - val_loss: 1.6553 - val_accuracy: 0.3944\n",
      "Epoch 61/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6747 - accuracy: 0.6736 - val_loss: 1.7801 - val_accuracy: 0.4167\n",
      "Epoch 62/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6697 - accuracy: 0.6681 - val_loss: 1.7494 - val_accuracy: 0.4000\n",
      "Epoch 63/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6612 - accuracy: 0.6736 - val_loss: 1.7504 - val_accuracy: 0.3778\n",
      "Epoch 64/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6791 - accuracy: 0.6736 - val_loss: 1.7134 - val_accuracy: 0.3778\n",
      "Epoch 65/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6841 - accuracy: 0.6903 - val_loss: 1.8462 - val_accuracy: 0.4056\n",
      "Epoch 66/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6477 - accuracy: 0.6944 - val_loss: 1.8021 - val_accuracy: 0.3833\n",
      "Epoch 67/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6481 - accuracy: 0.6931 - val_loss: 1.8091 - val_accuracy: 0.4111\n",
      "Epoch 68/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6211 - accuracy: 0.7000 - val_loss: 1.9163 - val_accuracy: 0.4000\n",
      "Epoch 69/80\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6164 - accuracy: 0.7111 - val_loss: 1.9047 - val_accuracy: 0.4056\n",
      "Epoch 70/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.5844 - accuracy: 0.7208 - val_loss: 1.9407 - val_accuracy: 0.3944\n",
      "Epoch 71/80\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.5977 - accuracy: 0.7236 - val_loss: 1.8981 - val_accuracy: 0.4000\n",
      "Epoch 72/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.5961 - accuracy: 0.7194 - val_loss: 1.8697 - val_accuracy: 0.4111\n",
      "Epoch 73/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.5772 - accuracy: 0.7319 - val_loss: 1.9661 - val_accuracy: 0.4056\n",
      "Epoch 74/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.5715 - accuracy: 0.7139 - val_loss: 1.9963 - val_accuracy: 0.3944\n",
      "Epoch 75/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5718 - accuracy: 0.7389 - val_loss: 1.9535 - val_accuracy: 0.4000\n",
      "Epoch 76/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6009 - accuracy: 0.7222 - val_loss: 1.9950 - val_accuracy: 0.4167\n",
      "Epoch 77/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.5850 - accuracy: 0.7153 - val_loss: 2.0316 - val_accuracy: 0.4222\n",
      "Epoch 78/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5816 - accuracy: 0.7222 - val_loss: 2.0237 - val_accuracy: 0.4056\n",
      "Epoch 79/80\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5453 - accuracy: 0.7556 - val_loss: 1.9824 - val_accuracy: 0.3833\n",
      "Epoch 80/80\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.5448 - accuracy: 0.7403 - val_loss: 1.9839 - val_accuracy: 0.4000\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 51.187744140625, Units2: 80.53359985351562, Dropout Rate: 0.328125, Learning Rate: 0.098453125, Epochs: 87.3382568359375, Batch Size: 62.8607177734375\n",
      "\n",
      "Epoch 1/87\n",
      "12/12 [==============================] - 7s 185ms/step - loss: 1.1453 - accuracy: 0.3486 - val_loss: 1.1325 - val_accuracy: 0.3167\n",
      "Epoch 2/87\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.1224 - accuracy: 0.3278 - val_loss: 1.1153 - val_accuracy: 0.2944\n",
      "Epoch 3/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1000 - accuracy: 0.3444 - val_loss: 1.1078 - val_accuracy: 0.3444\n",
      "Epoch 4/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0998 - accuracy: 0.3264 - val_loss: 1.0971 - val_accuracy: 0.3778\n",
      "Epoch 5/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0862 - accuracy: 0.4014 - val_loss: 1.1528 - val_accuracy: 0.3556\n",
      "Epoch 6/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1041 - accuracy: 0.3306 - val_loss: 1.1072 - val_accuracy: 0.3333\n",
      "Epoch 7/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1005 - accuracy: 0.3472 - val_loss: 1.1112 - val_accuracy: 0.3500\n",
      "Epoch 8/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0893 - accuracy: 0.3528 - val_loss: 1.1235 - val_accuracy: 0.3833\n",
      "Epoch 9/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.1044 - accuracy: 0.3819 - val_loss: 1.1060 - val_accuracy: 0.3333\n",
      "Epoch 10/87\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.0748 - accuracy: 0.4042 - val_loss: 1.1131 - val_accuracy: 0.3333\n",
      "Epoch 11/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0826 - accuracy: 0.3875 - val_loss: 1.1335 - val_accuracy: 0.3389\n",
      "Epoch 12/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0837 - accuracy: 0.3958 - val_loss: 1.1182 - val_accuracy: 0.3611\n",
      "Epoch 13/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0810 - accuracy: 0.4153 - val_loss: 1.1469 - val_accuracy: 0.3556\n",
      "Epoch 14/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0690 - accuracy: 0.4208 - val_loss: 1.1757 - val_accuracy: 0.3167\n",
      "Epoch 15/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0665 - accuracy: 0.4125 - val_loss: 1.1524 - val_accuracy: 0.3111\n",
      "Epoch 16/87\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 1.0693 - accuracy: 0.3806 - val_loss: 1.2015 - val_accuracy: 0.3556\n",
      "Epoch 17/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0685 - accuracy: 0.4194 - val_loss: 1.1628 - val_accuracy: 0.3667\n",
      "Epoch 18/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0561 - accuracy: 0.4250 - val_loss: 1.2815 - val_accuracy: 0.3278\n",
      "Epoch 19/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0637 - accuracy: 0.4069 - val_loss: 1.1398 - val_accuracy: 0.3389\n",
      "Epoch 20/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0492 - accuracy: 0.4236 - val_loss: 1.1761 - val_accuracy: 0.3611\n",
      "Epoch 21/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0382 - accuracy: 0.4486 - val_loss: 1.1920 - val_accuracy: 0.3222\n",
      "Epoch 22/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0655 - accuracy: 0.4292 - val_loss: 1.1373 - val_accuracy: 0.3000\n",
      "Epoch 23/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0602 - accuracy: 0.4083 - val_loss: 1.1754 - val_accuracy: 0.2944\n",
      "Epoch 24/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0402 - accuracy: 0.4139 - val_loss: 1.1779 - val_accuracy: 0.3722\n",
      "Epoch 25/87\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0469 - accuracy: 0.4319 - val_loss: 1.1858 - val_accuracy: 0.3444\n",
      "Epoch 26/87\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0521 - accuracy: 0.4403 - val_loss: 1.1873 - val_accuracy: 0.3389\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 33.17840576171875, Units2: 69.14215087890625, Dropout Rate: 0.46484375, Learning Rate: 0.045859375, Epochs: 48.395843505859375, Batch Size: 23.3209228515625\n",
      "\n",
      "Epoch 1/48\n",
      "32/32 [==============================] - 6s 45ms/step - loss: 1.1195 - accuracy: 0.3222 - val_loss: 1.1067 - val_accuracy: 0.3444\n",
      "Epoch 2/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1149 - accuracy: 0.3361 - val_loss: 1.1086 - val_accuracy: 0.3167\n",
      "Epoch 3/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1075 - accuracy: 0.3375 - val_loss: 1.1046 - val_accuracy: 0.3278\n",
      "Epoch 4/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1020 - accuracy: 0.3389 - val_loss: 1.1016 - val_accuracy: 0.3333\n",
      "Epoch 5/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1027 - accuracy: 0.3611 - val_loss: 1.1099 - val_accuracy: 0.3167\n",
      "Epoch 6/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1031 - accuracy: 0.3153 - val_loss: 1.1113 - val_accuracy: 0.3333\n",
      "Epoch 7/48\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0931 - accuracy: 0.3722 - val_loss: 1.1576 - val_accuracy: 0.3333\n",
      "Epoch 8/48\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0961 - accuracy: 0.3458 - val_loss: 1.1000 - val_accuracy: 0.3056\n",
      "Epoch 9/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0940 - accuracy: 0.3597 - val_loss: 1.1286 - val_accuracy: 0.3500\n",
      "Epoch 10/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1070 - accuracy: 0.3847 - val_loss: 1.1088 - val_accuracy: 0.3222\n",
      "Epoch 11/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0985 - accuracy: 0.3486 - val_loss: 1.1188 - val_accuracy: 0.3222\n",
      "Epoch 12/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0963 - accuracy: 0.3514 - val_loss: 1.1324 - val_accuracy: 0.3333\n",
      "Epoch 13/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1029 - accuracy: 0.3444 - val_loss: 1.1027 - val_accuracy: 0.3111\n",
      "Epoch 14/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0874 - accuracy: 0.3597 - val_loss: 1.1006 - val_accuracy: 0.3611\n",
      "Epoch 15/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0858 - accuracy: 0.3903 - val_loss: 1.1208 - val_accuracy: 0.3167\n",
      "Epoch 16/48\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0939 - accuracy: 0.3569 - val_loss: 1.1156 - val_accuracy: 0.3556\n",
      "Epoch 17/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0778 - accuracy: 0.4069 - val_loss: 1.1220 - val_accuracy: 0.3389\n",
      "Epoch 18/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0700 - accuracy: 0.4097 - val_loss: 1.1329 - val_accuracy: 0.3444\n",
      "Epoch 19/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0817 - accuracy: 0.4153 - val_loss: 1.1053 - val_accuracy: 0.3111\n",
      "Epoch 20/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0688 - accuracy: 0.3931 - val_loss: 1.1251 - val_accuracy: 0.3333\n",
      "Epoch 21/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0723 - accuracy: 0.3958 - val_loss: 1.1333 - val_accuracy: 0.3222\n",
      "Epoch 22/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0670 - accuracy: 0.4125 - val_loss: 1.1270 - val_accuracy: 0.3556\n",
      "Epoch 23/48\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0695 - accuracy: 0.3861 - val_loss: 1.1264 - val_accuracy: 0.3778\n",
      "Epoch 24/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0581 - accuracy: 0.4250 - val_loss: 1.1350 - val_accuracy: 0.3778\n",
      "Epoch 25/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0375 - accuracy: 0.4667 - val_loss: 1.1989 - val_accuracy: 0.3556\n",
      "Epoch 26/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0944 - accuracy: 0.3972 - val_loss: 1.1026 - val_accuracy: 0.3111\n",
      "Epoch 27/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0580 - accuracy: 0.4056 - val_loss: 1.1772 - val_accuracy: 0.3611\n",
      "Epoch 28/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0550 - accuracy: 0.4431 - val_loss: 1.1256 - val_accuracy: 0.3611\n",
      "Epoch 29/48\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0427 - accuracy: 0.4347 - val_loss: 1.1779 - val_accuracy: 0.3222\n",
      "Epoch 30/48\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0442 - accuracy: 0.4292 - val_loss: 1.2111 - val_accuracy: 0.3278\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 37.491912841796875, Units2: 54.638824462890625, Dropout Rate: 0.69921875, Learning Rate: 0.06751562500000001, Epochs: 21.513671875, Batch Size: 91.67510986328125\n",
      "\n",
      "Epoch 1/21\n",
      "8/8 [==============================] - 6s 187ms/step - loss: 1.1160 - accuracy: 0.3333 - val_loss: 1.1046 - val_accuracy: 0.3167\n",
      "Epoch 2/21\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1152 - accuracy: 0.3625 - val_loss: 1.0984 - val_accuracy: 0.3389\n",
      "Epoch 3/21\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1180 - accuracy: 0.3306 - val_loss: 1.1039 - val_accuracy: 0.3778\n",
      "Epoch 4/21\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1064 - accuracy: 0.3486 - val_loss: 1.1000 - val_accuracy: 0.3667\n",
      "Epoch 5/21\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.1120 - accuracy: 0.3403 - val_loss: 1.1039 - val_accuracy: 0.3500\n",
      "Epoch 6/21\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0959 - accuracy: 0.3569 - val_loss: 1.1069 - val_accuracy: 0.3278\n",
      "Epoch 7/21\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0848 - accuracy: 0.3917 - val_loss: 1.1181 - val_accuracy: 0.3667\n",
      "Epoch 8/21\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0741 - accuracy: 0.4056 - val_loss: 1.1162 - val_accuracy: 0.3444\n",
      "Epoch 9/21\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0786 - accuracy: 0.3944 - val_loss: 1.1262 - val_accuracy: 0.3722\n",
      "Epoch 10/21\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0949 - accuracy: 0.3681 - val_loss: 1.1103 - val_accuracy: 0.3389\n",
      "Epoch 11/21\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0854 - accuracy: 0.3778 - val_loss: 1.1151 - val_accuracy: 0.3556\n",
      "Epoch 12/21\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0711 - accuracy: 0.4153 - val_loss: 1.1095 - val_accuracy: 0.3500\n",
      "Epoch 13/21\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0871 - accuracy: 0.3931 - val_loss: 1.1177 - val_accuracy: 0.3500\n",
      "Epoch 14/21\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0612 - accuracy: 0.4361 - val_loss: 1.1346 - val_accuracy: 0.3500\n",
      "Epoch 15/21\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0654 - accuracy: 0.4056 - val_loss: 1.1053 - val_accuracy: 0.3778\n",
      "Epoch 16/21\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0538 - accuracy: 0.4306 - val_loss: 1.1187 - val_accuracy: 0.3500\n",
      "Epoch 17/21\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0564 - accuracy: 0.4361 - val_loss: 1.1635 - val_accuracy: 0.3333\n",
      "Epoch 18/21\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0460 - accuracy: 0.4236 - val_loss: 1.1125 - val_accuracy: 0.3500\n",
      "Epoch 19/21\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0473 - accuracy: 0.4514 - val_loss: 1.1356 - val_accuracy: 0.3222\n",
      "Epoch 20/21\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0547 - accuracy: 0.4653 - val_loss: 1.1270 - val_accuracy: 0.3778\n",
      "Epoch 21/21\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0435 - accuracy: 0.4389 - val_loss: 1.1259 - val_accuracy: 0.3333\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 20.1019287109375, Units2: 38.661956787109375, Dropout Rate: 0.734375, Learning Rate: 0.014921875000000001, Epochs: 43.872222900390625, Batch Size: 41.576080322265625\n",
      "\n",
      "Epoch 1/43\n",
      "18/18 [==============================] - 11s 110ms/step - loss: 1.1005 - accuracy: 0.3347 - val_loss: 1.1011 - val_accuracy: 0.3333\n",
      "Epoch 2/43\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0994 - accuracy: 0.3403 - val_loss: 1.1063 - val_accuracy: 0.3389\n",
      "Epoch 3/43\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0995 - accuracy: 0.3819 - val_loss: 1.1037 - val_accuracy: 0.3833\n",
      "Epoch 4/43\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0977 - accuracy: 0.3500 - val_loss: 1.1033 - val_accuracy: 0.3611\n",
      "Epoch 5/43\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0968 - accuracy: 0.3222 - val_loss: 1.1089 - val_accuracy: 0.3778\n",
      "Epoch 6/43\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0928 - accuracy: 0.3639 - val_loss: 1.1045 - val_accuracy: 0.3722\n",
      "Epoch 7/43\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0928 - accuracy: 0.3500 - val_loss: 1.1057 - val_accuracy: 0.3444\n",
      "Epoch 8/43\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0928 - accuracy: 0.3667 - val_loss: 1.1049 - val_accuracy: 0.3389\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 32.298126220703125, Units2: 85.0311279296875, Dropout Rate: 0.81640625, Learning Rate: 0.033484375000000004, Epochs: 82.62374877929688, Batch Size: 50.063018798828125\n",
      "\n",
      "Epoch 1/82\n",
      "15/15 [==============================] - 7s 132ms/step - loss: 1.1168 - accuracy: 0.3083 - val_loss: 1.1087 - val_accuracy: 0.3278\n",
      "Epoch 2/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1062 - accuracy: 0.3472 - val_loss: 1.1143 - val_accuracy: 0.3444\n",
      "Epoch 3/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1180 - accuracy: 0.3278 - val_loss: 1.1048 - val_accuracy: 0.3556\n",
      "Epoch 4/82\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.1030 - accuracy: 0.3625 - val_loss: 1.0945 - val_accuracy: 0.3778\n",
      "Epoch 5/82\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.1083 - accuracy: 0.3556 - val_loss: 1.0994 - val_accuracy: 0.3778\n",
      "Epoch 6/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1063 - accuracy: 0.3347 - val_loss: 1.1119 - val_accuracy: 0.3667\n",
      "Epoch 7/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1072 - accuracy: 0.3306 - val_loss: 1.0998 - val_accuracy: 0.3556\n",
      "Epoch 8/82\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0915 - accuracy: 0.3750 - val_loss: 1.1073 - val_accuracy: 0.3444\n",
      "Epoch 9/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0989 - accuracy: 0.3639 - val_loss: 1.1054 - val_accuracy: 0.3500\n",
      "Epoch 10/82\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0935 - accuracy: 0.3819 - val_loss: 1.1136 - val_accuracy: 0.3444\n",
      "Epoch 11/82\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.0810 - accuracy: 0.3917 - val_loss: 1.1182 - val_accuracy: 0.3389\n",
      "Epoch 12/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0912 - accuracy: 0.3875 - val_loss: 1.1154 - val_accuracy: 0.3111\n",
      "Epoch 13/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0859 - accuracy: 0.3889 - val_loss: 1.1103 - val_accuracy: 0.3444\n",
      "Epoch 14/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0731 - accuracy: 0.3917 - val_loss: 1.1208 - val_accuracy: 0.3222\n",
      "Epoch 15/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0817 - accuracy: 0.3972 - val_loss: 1.1185 - val_accuracy: 0.3444\n",
      "Epoch 16/82\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0754 - accuracy: 0.3931 - val_loss: 1.1181 - val_accuracy: 0.3278\n",
      "Epoch 17/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0808 - accuracy: 0.4153 - val_loss: 1.1155 - val_accuracy: 0.3222\n",
      "Epoch 18/82\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.0901 - accuracy: 0.4139 - val_loss: 1.1150 - val_accuracy: 0.3056\n",
      "Epoch 19/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0711 - accuracy: 0.3986 - val_loss: 1.1206 - val_accuracy: 0.3111\n",
      "Epoch 20/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0637 - accuracy: 0.4222 - val_loss: 1.1273 - val_accuracy: 0.3278\n",
      "Epoch 21/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0843 - accuracy: 0.3875 - val_loss: 1.1388 - val_accuracy: 0.3278\n",
      "Epoch 22/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0669 - accuracy: 0.4069 - val_loss: 1.1312 - val_accuracy: 0.3000\n",
      "Epoch 23/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0571 - accuracy: 0.4236 - val_loss: 1.1323 - val_accuracy: 0.3333\n",
      "Epoch 24/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0569 - accuracy: 0.4403 - val_loss: 1.1549 - val_accuracy: 0.3167\n",
      "Epoch 25/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0654 - accuracy: 0.4111 - val_loss: 1.1549 - val_accuracy: 0.3222\n",
      "Epoch 26/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0660 - accuracy: 0.4208 - val_loss: 1.1271 - val_accuracy: 0.3222\n",
      "Epoch 27/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0544 - accuracy: 0.4333 - val_loss: 1.1286 - val_accuracy: 0.3111\n",
      "Epoch 28/82\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0517 - accuracy: 0.4208 - val_loss: 1.1268 - val_accuracy: 0.3833\n",
      "Epoch 29/82\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0474 - accuracy: 0.4264 - val_loss: 1.1300 - val_accuracy: 0.3722\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 14.593658447265625, Units2: 28.1439208984375, Dropout Rate: 0.275390625, Learning Rate: 0.039671875, Epochs: 74.84268188476562, Batch Size: 88.77883911132812\n",
      "\n",
      "Epoch 1/74\n",
      "9/9 [==============================] - 6s 168ms/step - loss: 1.1089 - accuracy: 0.3042 - val_loss: 1.1032 - val_accuracy: 0.3222\n",
      "Epoch 2/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0995 - accuracy: 0.3319 - val_loss: 1.1048 - val_accuracy: 0.3111\n",
      "Epoch 3/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0959 - accuracy: 0.3486 - val_loss: 1.1115 - val_accuracy: 0.3444\n",
      "Epoch 4/74\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0965 - accuracy: 0.3583 - val_loss: 1.1119 - val_accuracy: 0.3389\n",
      "Epoch 5/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0937 - accuracy: 0.3653 - val_loss: 1.1037 - val_accuracy: 0.3889\n",
      "Epoch 6/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0853 - accuracy: 0.3569 - val_loss: 1.1030 - val_accuracy: 0.3667\n",
      "Epoch 7/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0852 - accuracy: 0.3944 - val_loss: 1.0955 - val_accuracy: 0.3833\n",
      "Epoch 8/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0840 - accuracy: 0.3903 - val_loss: 1.0930 - val_accuracy: 0.3500\n",
      "Epoch 9/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0832 - accuracy: 0.3861 - val_loss: 1.0994 - val_accuracy: 0.3722\n",
      "Epoch 10/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0807 - accuracy: 0.3847 - val_loss: 1.1194 - val_accuracy: 0.3222\n",
      "Epoch 11/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0791 - accuracy: 0.3931 - val_loss: 1.1135 - val_accuracy: 0.4000\n",
      "Epoch 12/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0668 - accuracy: 0.4111 - val_loss: 1.1143 - val_accuracy: 0.3500\n",
      "Epoch 13/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0646 - accuracy: 0.4278 - val_loss: 1.1193 - val_accuracy: 0.3833\n",
      "Epoch 14/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0601 - accuracy: 0.4278 - val_loss: 1.1040 - val_accuracy: 0.3889\n",
      "Epoch 15/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0579 - accuracy: 0.4181 - val_loss: 1.1018 - val_accuracy: 0.3722\n",
      "Epoch 16/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0538 - accuracy: 0.4278 - val_loss: 1.1087 - val_accuracy: 0.4056\n",
      "Epoch 17/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0340 - accuracy: 0.4403 - val_loss: 1.1186 - val_accuracy: 0.3722\n",
      "Epoch 18/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0344 - accuracy: 0.4653 - val_loss: 1.1128 - val_accuracy: 0.4222\n",
      "Epoch 19/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0239 - accuracy: 0.4569 - val_loss: 1.1248 - val_accuracy: 0.3778\n",
      "Epoch 20/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0217 - accuracy: 0.4208 - val_loss: 1.1658 - val_accuracy: 0.3944\n",
      "Epoch 21/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0196 - accuracy: 0.4667 - val_loss: 1.1417 - val_accuracy: 0.3500\n",
      "Epoch 22/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0270 - accuracy: 0.4333 - val_loss: 1.1575 - val_accuracy: 0.3889\n",
      "Epoch 23/74\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1.0111 - accuracy: 0.4458 - val_loss: 1.1304 - val_accuracy: 0.3444\n",
      "Epoch 24/74\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9936 - accuracy: 0.4639 - val_loss: 1.1705 - val_accuracy: 0.3278\n",
      "Epoch 25/74\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9874 - accuracy: 0.4639 - val_loss: 1.1834 - val_accuracy: 0.3444\n",
      "Epoch 26/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.9911 - accuracy: 0.4806 - val_loss: 1.2012 - val_accuracy: 0.3500\n",
      "Epoch 27/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9956 - accuracy: 0.4806 - val_loss: 1.1413 - val_accuracy: 0.3611\n",
      "Epoch 28/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9792 - accuracy: 0.4889 - val_loss: 1.1750 - val_accuracy: 0.3444\n",
      "Epoch 29/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9554 - accuracy: 0.4944 - val_loss: 1.1541 - val_accuracy: 0.3333\n",
      "Epoch 30/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9754 - accuracy: 0.4861 - val_loss: 1.2597 - val_accuracy: 0.3556\n",
      "Epoch 31/74\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.9719 - accuracy: 0.4847 - val_loss: 1.1904 - val_accuracy: 0.3778\n",
      "Epoch 32/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9575 - accuracy: 0.4861 - val_loss: 1.1185 - val_accuracy: 0.3778\n",
      "Epoch 33/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9495 - accuracy: 0.5111 - val_loss: 1.2189 - val_accuracy: 0.3444\n",
      "Epoch 34/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9663 - accuracy: 0.4792 - val_loss: 1.1789 - val_accuracy: 0.3444\n",
      "Epoch 35/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9404 - accuracy: 0.5083 - val_loss: 1.1817 - val_accuracy: 0.3333\n",
      "Epoch 36/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.9534 - accuracy: 0.5083 - val_loss: 1.1755 - val_accuracy: 0.3222\n",
      "Epoch 37/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9208 - accuracy: 0.5264 - val_loss: 1.1687 - val_accuracy: 0.3778\n",
      "Epoch 38/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9283 - accuracy: 0.5083 - val_loss: 1.1856 - val_accuracy: 0.4000\n",
      "Epoch 39/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9191 - accuracy: 0.5097 - val_loss: 1.2342 - val_accuracy: 0.3944\n",
      "Epoch 40/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9013 - accuracy: 0.5375 - val_loss: 1.1960 - val_accuracy: 0.3333\n",
      "Epoch 41/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9045 - accuracy: 0.5458 - val_loss: 1.2622 - val_accuracy: 0.3611\n",
      "Epoch 42/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8942 - accuracy: 0.5556 - val_loss: 1.2676 - val_accuracy: 0.3389\n",
      "Epoch 43/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9171 - accuracy: 0.5278 - val_loss: 1.3015 - val_accuracy: 0.3556\n",
      "Epoch 44/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9038 - accuracy: 0.5389 - val_loss: 1.2530 - val_accuracy: 0.3778\n",
      "Epoch 45/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8908 - accuracy: 0.5431 - val_loss: 1.2449 - val_accuracy: 0.3944\n",
      "Epoch 46/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8688 - accuracy: 0.5639 - val_loss: 1.2824 - val_accuracy: 0.3944\n",
      "Epoch 47/74\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8732 - accuracy: 0.5583 - val_loss: 1.2766 - val_accuracy: 0.4056\n",
      "Epoch 48/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.8466 - accuracy: 0.5875 - val_loss: 1.2555 - val_accuracy: 0.4056\n",
      "Epoch 49/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.2609 - val_accuracy: 0.4000\n",
      "Epoch 50/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.8382 - accuracy: 0.5681 - val_loss: 1.3592 - val_accuracy: 0.3944\n",
      "Epoch 51/74\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8424 - accuracy: 0.5833 - val_loss: 1.3476 - val_accuracy: 0.3944\n",
      "Epoch 52/74\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.8680 - accuracy: 0.5542 - val_loss: 1.2860 - val_accuracy: 0.3667\n",
      "Epoch 53/74\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.8924 - accuracy: 0.5708 - val_loss: 1.3003 - val_accuracy: 0.4222\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 57.580413818359375, Units2: 91.29608154296875, Dropout Rate: 0.505859375, Learning Rate: 0.08762500000000001, Epochs: 34.75494384765625, Batch Size: 36.8231201171875\n",
      "\n",
      "Epoch 1/34\n",
      "20/20 [==============================] - 6s 62ms/step - loss: 1.1811 - accuracy: 0.3306 - val_loss: 1.2363 - val_accuracy: 0.2778\n",
      "Epoch 2/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.1332 - accuracy: 0.3167 - val_loss: 1.0947 - val_accuracy: 0.4111\n",
      "Epoch 3/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0962 - accuracy: 0.3708 - val_loss: 1.0919 - val_accuracy: 0.3556\n",
      "Epoch 4/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.1018 - accuracy: 0.3764 - val_loss: 1.1141 - val_accuracy: 0.3222\n",
      "Epoch 5/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.1102 - accuracy: 0.3208 - val_loss: 1.1060 - val_accuracy: 0.3222\n",
      "Epoch 6/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.1001 - accuracy: 0.3486 - val_loss: 1.1064 - val_accuracy: 0.3333\n",
      "Epoch 7/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0916 - accuracy: 0.4042 - val_loss: 1.1113 - val_accuracy: 0.3500\n",
      "Epoch 8/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0885 - accuracy: 0.3667 - val_loss: 1.1302 - val_accuracy: 0.2833\n",
      "Epoch 9/34\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1004 - accuracy: 0.3639 - val_loss: 1.1256 - val_accuracy: 0.3500\n",
      "Epoch 10/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0915 - accuracy: 0.3653 - val_loss: 1.1166 - val_accuracy: 0.3333\n",
      "Epoch 11/34\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1030 - accuracy: 0.3819 - val_loss: 1.1512 - val_accuracy: 0.3167\n",
      "Epoch 12/34\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0961 - accuracy: 0.3792 - val_loss: 1.0995 - val_accuracy: 0.3389\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 37.629241943359375, Units2: 72.05902099609375, Dropout Rate: 0.140625, Learning Rate: 0.033484375000000004, Epochs: 19.503173828125, Batch Size: 76.03195190429688\n",
      "\n",
      "Epoch 1/19\n",
      "10/10 [==============================] - 6s 137ms/step - loss: 1.1098 - accuracy: 0.3375 - val_loss: 1.0979 - val_accuracy: 0.3667\n",
      "Epoch 2/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.1015 - accuracy: 0.3292 - val_loss: 1.0996 - val_accuracy: 0.3556\n",
      "Epoch 3/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0955 - accuracy: 0.3639 - val_loss: 1.1014 - val_accuracy: 0.3778\n",
      "Epoch 4/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0907 - accuracy: 0.3750 - val_loss: 1.0979 - val_accuracy: 0.3833\n",
      "Epoch 5/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0874 - accuracy: 0.3819 - val_loss: 1.1101 - val_accuracy: 0.3722\n",
      "Epoch 6/19\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0876 - accuracy: 0.4042 - val_loss: 1.1074 - val_accuracy: 0.3722\n",
      "Epoch 7/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0780 - accuracy: 0.3875 - val_loss: 1.1119 - val_accuracy: 0.3722\n",
      "Epoch 8/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0665 - accuracy: 0.4000 - val_loss: 1.1510 - val_accuracy: 0.3667\n",
      "Epoch 9/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0799 - accuracy: 0.4014 - val_loss: 1.1370 - val_accuracy: 0.3722\n",
      "Epoch 10/19\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0604 - accuracy: 0.4194 - val_loss: 1.1086 - val_accuracy: 0.3722\n",
      "Epoch 11/19\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0612 - accuracy: 0.4153 - val_loss: 1.1160 - val_accuracy: 0.3667\n",
      "Epoch 12/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0420 - accuracy: 0.4361 - val_loss: 1.1341 - val_accuracy: 0.3667\n",
      "Epoch 13/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0388 - accuracy: 0.4389 - val_loss: 1.1326 - val_accuracy: 0.3778\n",
      "Epoch 14/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0200 - accuracy: 0.4667 - val_loss: 1.1219 - val_accuracy: 0.3611\n",
      "Epoch 15/19\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0133 - accuracy: 0.4639 - val_loss: 1.1445 - val_accuracy: 0.3889\n",
      "Epoch 16/19\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0120 - accuracy: 0.4569 - val_loss: 1.1454 - val_accuracy: 0.3667\n",
      "Epoch 17/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9867 - accuracy: 0.4903 - val_loss: 1.1845 - val_accuracy: 0.4000\n",
      "Epoch 18/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9890 - accuracy: 0.4792 - val_loss: 1.1527 - val_accuracy: 0.4111\n",
      "Epoch 19/19\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9680 - accuracy: 0.4931 - val_loss: 1.1480 - val_accuracy: 0.3611\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 30.88775634765625, Units2: 83.70590209960938, Dropout Rate: 0.37109375, Learning Rate: 0.03503125, Epochs: 74.95529174804688, Batch Size: 34.85107421875\n",
      "\n",
      "Epoch 1/74\n",
      "22/22 [==============================] - 7s 68ms/step - loss: 1.1083 - accuracy: 0.3569 - val_loss: 1.1151 - val_accuracy: 0.3222\n",
      "Epoch 2/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.1164 - accuracy: 0.3375 - val_loss: 1.0945 - val_accuracy: 0.3833\n",
      "Epoch 3/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.1082 - accuracy: 0.3278 - val_loss: 1.1012 - val_accuracy: 0.3222\n",
      "Epoch 4/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0978 - accuracy: 0.3431 - val_loss: 1.1042 - val_accuracy: 0.3611\n",
      "Epoch 5/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0964 - accuracy: 0.3611 - val_loss: 1.1016 - val_accuracy: 0.3667\n",
      "Epoch 6/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0930 - accuracy: 0.3694 - val_loss: 1.1032 - val_accuracy: 0.3556\n",
      "Epoch 7/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0862 - accuracy: 0.3806 - val_loss: 1.1395 - val_accuracy: 0.4000\n",
      "Epoch 8/74\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1042 - accuracy: 0.3486 - val_loss: 1.1244 - val_accuracy: 0.3611\n",
      "Epoch 9/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0897 - accuracy: 0.3514 - val_loss: 1.1143 - val_accuracy: 0.3556\n",
      "Epoch 10/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0739 - accuracy: 0.4222 - val_loss: 1.1535 - val_accuracy: 0.3556\n",
      "Epoch 11/74\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.0883 - accuracy: 0.3889 - val_loss: 1.1170 - val_accuracy: 0.3778\n",
      "Epoch 12/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0738 - accuracy: 0.3861 - val_loss: 1.1453 - val_accuracy: 0.3556\n",
      "Epoch 13/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0666 - accuracy: 0.4153 - val_loss: 1.1481 - val_accuracy: 0.3944\n",
      "Epoch 14/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0626 - accuracy: 0.4306 - val_loss: 1.1514 - val_accuracy: 0.3611\n",
      "Epoch 15/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0592 - accuracy: 0.4389 - val_loss: 1.1747 - val_accuracy: 0.3444\n",
      "Epoch 16/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0549 - accuracy: 0.4375 - val_loss: 1.1713 - val_accuracy: 0.3667\n",
      "Epoch 17/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0485 - accuracy: 0.4306 - val_loss: 1.1542 - val_accuracy: 0.3500\n",
      "Epoch 18/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0622 - accuracy: 0.4139 - val_loss: 1.1581 - val_accuracy: 0.3833\n",
      "Epoch 19/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0516 - accuracy: 0.4458 - val_loss: 1.1413 - val_accuracy: 0.3667\n",
      "Epoch 20/74\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0371 - accuracy: 0.4431 - val_loss: 1.1517 - val_accuracy: 0.3611\n",
      "Epoch 21/74\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0421 - accuracy: 0.4361 - val_loss: 1.1588 - val_accuracy: 0.3500\n",
      "Epoch 22/74\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0275 - accuracy: 0.4444 - val_loss: 1.1763 - val_accuracy: 0.3611\n",
      "Epoch 23/74\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 1.0301 - accuracy: 0.4278 - val_loss: 1.2007 - val_accuracy: 0.3167\n",
      "Epoch 24/74\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 1.0104 - accuracy: 0.4528 - val_loss: 1.2098 - val_accuracy: 0.3556\n",
      "Epoch 25/74\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1.0284 - accuracy: 0.4472 - val_loss: 1.1872 - val_accuracy: 0.3056\n",
      "Epoch 26/74\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 1.0014 - accuracy: 0.4611 - val_loss: 1.2219 - val_accuracy: 0.4000\n",
      "Epoch 27/74\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 1.0149 - accuracy: 0.4375 - val_loss: 1.2515 - val_accuracy: 0.3333\n",
      "Epoch 28/74\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.0235 - accuracy: 0.4583 - val_loss: 1.2277 - val_accuracy: 0.3556\n",
      "Epoch 29/74\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0546 - accuracy: 0.4278 - val_loss: 1.1923 - val_accuracy: 0.3556\n",
      "Epoch 30/74\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 1.0057 - accuracy: 0.4514 - val_loss: 1.2114 - val_accuracy: 0.3667\n",
      "Epoch 31/74\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.0154 - accuracy: 0.4250 - val_loss: 1.2203 - val_accuracy: 0.3389\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 88.4149169921875, Units2: 90.7275390625, Dropout Rate: 0.27734375, Learning Rate: 0.061328125000000004, Epochs: 19.14886474609375, Batch Size: 57.56256103515625\n",
      "\n",
      "Epoch 1/19\n",
      "13/13 [==============================] - 24s 271ms/step - loss: 1.1429 - accuracy: 0.3264 - val_loss: 1.1068 - val_accuracy: 0.3222\n",
      "Epoch 2/19\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.1075 - accuracy: 0.3556 - val_loss: 1.1092 - val_accuracy: 0.3722\n",
      "Epoch 3/19\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.1012 - accuracy: 0.3597 - val_loss: 1.1098 - val_accuracy: 0.3889\n",
      "Epoch 4/19\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.0944 - accuracy: 0.3444 - val_loss: 1.1082 - val_accuracy: 0.3500\n",
      "Epoch 5/19\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.1098 - accuracy: 0.3750 - val_loss: 1.1166 - val_accuracy: 0.3167\n",
      "Epoch 6/19\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.0989 - accuracy: 0.3514 - val_loss: 1.1115 - val_accuracy: 0.3444\n",
      "Epoch 7/19\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0894 - accuracy: 0.3958 - val_loss: 1.1514 - val_accuracy: 0.3611\n",
      "Epoch 8/19\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0869 - accuracy: 0.3958 - val_loss: 1.1333 - val_accuracy: 0.3056\n",
      "Epoch 9/19\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.0890 - accuracy: 0.3722 - val_loss: 1.1130 - val_accuracy: 0.3667\n",
      "Epoch 10/19\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.0688 - accuracy: 0.3861 - val_loss: 1.1476 - val_accuracy: 0.3667\n",
      "Epoch 11/19\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.0780 - accuracy: 0.3778 - val_loss: 1.1359 - val_accuracy: 0.3500\n",
      "Epoch 12/19\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 1.0790 - accuracy: 0.4042 - val_loss: 1.1586 - val_accuracy: 0.3722\n",
      "Epoch 13/19\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0652 - accuracy: 0.4111 - val_loss: 1.1465 - val_accuracy: 0.3333\n",
      "Epoch 14/19\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0534 - accuracy: 0.4264 - val_loss: 1.1475 - val_accuracy: 0.3333\n",
      "Epoch 15/19\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.0500 - accuracy: 0.4347 - val_loss: 1.1709 - val_accuracy: 0.3611\n",
      "Epoch 16/19\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.0285 - accuracy: 0.4486 - val_loss: 1.2041 - val_accuracy: 0.3389\n",
      "Epoch 17/19\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 1.0719 - accuracy: 0.4292 - val_loss: 1.1623 - val_accuracy: 0.3556\n",
      "Epoch 18/19\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.0269 - accuracy: 0.4583 - val_loss: 1.1564 - val_accuracy: 0.3222\n",
      "Epoch 19/19\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 1.0324 - accuracy: 0.4250 - val_loss: 1.1684 - val_accuracy: 0.3778\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 31.551055908203125, Units2: 90.55587768554688, Dropout Rate: 0.2578125, Learning Rate: 0.07370312500000001, Epochs: 96.79611206054688, Batch Size: 33.361053466796875\n",
      "\n",
      "Epoch 1/96\n",
      "22/22 [==============================] - 6s 67ms/step - loss: 1.1277 - accuracy: 0.3181 - val_loss: 1.1181 - val_accuracy: 0.2667\n",
      "Epoch 2/96\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1099 - accuracy: 0.3083 - val_loss: 1.1179 - val_accuracy: 0.3556\n",
      "Epoch 3/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1041 - accuracy: 0.3194 - val_loss: 1.1063 - val_accuracy: 0.3111\n",
      "Epoch 4/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0982 - accuracy: 0.3542 - val_loss: 1.1042 - val_accuracy: 0.3611\n",
      "Epoch 5/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1057 - accuracy: 0.3458 - val_loss: 1.1034 - val_accuracy: 0.3611\n",
      "Epoch 6/96\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0984 - accuracy: 0.3639 - val_loss: 1.1016 - val_accuracy: 0.3333\n",
      "Epoch 7/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1019 - accuracy: 0.3750 - val_loss: 1.1068 - val_accuracy: 0.3667\n",
      "Epoch 8/96\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.1066 - accuracy: 0.3319 - val_loss: 1.1099 - val_accuracy: 0.2667\n",
      "Epoch 9/96\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 1.0986 - accuracy: 0.3736 - val_loss: 1.1079 - val_accuracy: 0.3611\n",
      "Epoch 10/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0937 - accuracy: 0.3861 - val_loss: 1.0962 - val_accuracy: 0.3778\n",
      "Epoch 11/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0922 - accuracy: 0.3639 - val_loss: 1.0980 - val_accuracy: 0.3611\n",
      "Epoch 12/96\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 1.0901 - accuracy: 0.3750 - val_loss: 1.1111 - val_accuracy: 0.3056\n",
      "Epoch 13/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1092 - accuracy: 0.3778 - val_loss: 1.1181 - val_accuracy: 0.3722\n",
      "Epoch 14/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0931 - accuracy: 0.3736 - val_loss: 1.1470 - val_accuracy: 0.3722\n",
      "Epoch 15/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0820 - accuracy: 0.3986 - val_loss: 1.1613 - val_accuracy: 0.3389\n",
      "Epoch 16/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1020 - accuracy: 0.3806 - val_loss: 1.1088 - val_accuracy: 0.3222\n",
      "Epoch 17/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0864 - accuracy: 0.3861 - val_loss: 1.1041 - val_accuracy: 0.3944\n",
      "Epoch 18/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0804 - accuracy: 0.3861 - val_loss: 1.1568 - val_accuracy: 0.3722\n",
      "Epoch 19/96\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 1.0716 - accuracy: 0.4042 - val_loss: 1.1185 - val_accuracy: 0.3500\n",
      "Epoch 20/96\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0692 - accuracy: 0.3986 - val_loss: 1.1285 - val_accuracy: 0.3333\n",
      "Epoch 21/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0586 - accuracy: 0.4236 - val_loss: 1.2337 - val_accuracy: 0.3444\n",
      "Epoch 22/96\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 1.0504 - accuracy: 0.4000 - val_loss: 1.2119 - val_accuracy: 0.3611\n",
      "Epoch 23/96\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 1.0401 - accuracy: 0.4097 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
      "Epoch 24/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0514 - accuracy: 0.4361 - val_loss: 1.1326 - val_accuracy: 0.3889\n",
      "Epoch 25/96\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 1.0322 - accuracy: 0.4528 - val_loss: 1.2051 - val_accuracy: 0.3667\n",
      "Epoch 26/96\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0255 - accuracy: 0.4597 - val_loss: 1.3329 - val_accuracy: 0.4000\n",
      "Epoch 27/96\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.0522 - accuracy: 0.4222 - val_loss: 1.1621 - val_accuracy: 0.3500\n",
      "Epoch 28/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0568 - accuracy: 0.3931 - val_loss: 1.1590 - val_accuracy: 0.4167\n",
      "Epoch 29/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0227 - accuracy: 0.4403 - val_loss: 1.3189 - val_accuracy: 0.3222\n",
      "Epoch 30/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0182 - accuracy: 0.4333 - val_loss: 1.2624 - val_accuracy: 0.3278\n",
      "Epoch 31/96\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9944 - accuracy: 0.4583 - val_loss: 1.2945 - val_accuracy: 0.3389\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 51.76177978515625, Units2: 95.37750244140625, Dropout Rate: 0.3515625, Learning Rate: 0.076796875, Epochs: 15.6414794921875, Batch Size: 67.91854858398438\n",
      "\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - 6s 140ms/step - loss: 1.1311 - accuracy: 0.3708 - val_loss: 1.1058 - val_accuracy: 0.3944\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.1273 - accuracy: 0.3333 - val_loss: 1.1118 - val_accuracy: 0.3500\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.1062 - accuracy: 0.3486 - val_loss: 1.1156 - val_accuracy: 0.2778\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0997 - accuracy: 0.3319 - val_loss: 1.1069 - val_accuracy: 0.3111\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0897 - accuracy: 0.3750 - val_loss: 1.1192 - val_accuracy: 0.2778\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0987 - accuracy: 0.3792 - val_loss: 1.1305 - val_accuracy: 0.3333\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0868 - accuracy: 0.3972 - val_loss: 1.1302 - val_accuracy: 0.3500\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0829 - accuracy: 0.3986 - val_loss: 1.1337 - val_accuracy: 0.3278\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0860 - accuracy: 0.3861 - val_loss: 1.1356 - val_accuracy: 0.3500\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.0638 - accuracy: 0.4097 - val_loss: 1.1495 - val_accuracy: 0.3611\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.0681 - accuracy: 0.4181 - val_loss: 1.1564 - val_accuracy: 0.3722\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0711 - accuracy: 0.4097 - val_loss: 1.1231 - val_accuracy: 0.3278\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0562 - accuracy: 0.4333 - val_loss: 1.1420 - val_accuracy: 0.3556\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0585 - accuracy: 0.4569 - val_loss: 1.1621 - val_accuracy: 0.3389\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0454 - accuracy: 0.4222 - val_loss: 1.1326 - val_accuracy: 0.3556\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 74.3853759765625, Units2: 23.7274169921875, Dropout Rate: 0.7109375, Learning Rate: 0.1, Epochs: 60.44647216796875, Batch Size: 33.811492919921875\n",
      "\n",
      "Epoch 1/60\n",
      "22/22 [==============================] - 6s 71ms/step - loss: 1.1506 - accuracy: 0.3042 - val_loss: 1.1132 - val_accuracy: 0.3222\n",
      "Epoch 2/60\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.1051 - accuracy: 0.3500 - val_loss: 1.1092 - val_accuracy: 0.3278\n",
      "Epoch 3/60\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.1130 - accuracy: 0.3097 - val_loss: 1.0993 - val_accuracy: 0.3667\n",
      "Epoch 4/60\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.1029 - accuracy: 0.3444 - val_loss: 1.1059 - val_accuracy: 0.3000\n",
      "Epoch 5/60\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.1075 - accuracy: 0.3236 - val_loss: 1.1141 - val_accuracy: 0.3667\n",
      "Epoch 6/60\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.1059 - accuracy: 0.3222 - val_loss: 1.1065 - val_accuracy: 0.3278\n",
      "Epoch 7/60\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.1048 - accuracy: 0.3347 - val_loss: 1.0975 - val_accuracy: 0.3667\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 20.711669921875, Units2: 36.019744873046875, Dropout Rate: 0.375, Learning Rate: 0.001, Epochs: 89.453125, Batch Size: 37.085418701171875\n",
      "\n",
      "Epoch 1/89\n",
      "20/20 [==============================] - 7s 74ms/step - loss: 1.0983 - accuracy: 0.3403 - val_loss: 1.0978 - val_accuracy: 0.3667\n",
      "Epoch 2/89\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0973 - accuracy: 0.3486 - val_loss: 1.0981 - val_accuracy: 0.3833\n",
      "Epoch 3/89\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0975 - accuracy: 0.3444 - val_loss: 1.0982 - val_accuracy: 0.3667\n",
      "Epoch 4/89\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0963 - accuracy: 0.3583 - val_loss: 1.0984 - val_accuracy: 0.3611\n",
      "Epoch 5/89\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0957 - accuracy: 0.3361 - val_loss: 1.0983 - val_accuracy: 0.3611\n",
      "Epoch 6/89\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0948 - accuracy: 0.3639 - val_loss: 1.0982 - val_accuracy: 0.3556\n",
      "Epoch 7/89\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0949 - accuracy: 0.3556 - val_loss: 1.0986 - val_accuracy: 0.3500\n",
      "Epoch 8/89\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0940 - accuracy: 0.3500 - val_loss: 1.0991 - val_accuracy: 0.3389\n",
      "Epoch 9/89\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 1.0929 - accuracy: 0.3500 - val_loss: 1.0995 - val_accuracy: 0.3333\n",
      "Epoch 10/89\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0923 - accuracy: 0.3569 - val_loss: 1.1002 - val_accuracy: 0.3389\n",
      "Epoch 11/89\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0919 - accuracy: 0.3569 - val_loss: 1.1009 - val_accuracy: 0.3444\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 21.37359619140625, Units2: 84.77432250976562, Dropout Rate: 0.07421875, Learning Rate: 0.07215625, Epochs: 38.565826416015625, Batch Size: 89.89532470703125\n",
      "\n",
      "Epoch 1/38\n",
      "9/9 [==============================] - 7s 172ms/step - loss: 1.1162 - accuracy: 0.3444 - val_loss: 1.1084 - val_accuracy: 0.3167\n",
      "Epoch 2/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.1053 - accuracy: 0.3472 - val_loss: 1.1544 - val_accuracy: 0.3333\n",
      "Epoch 3/38\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1051 - accuracy: 0.3708 - val_loss: 1.0986 - val_accuracy: 0.3667\n",
      "Epoch 4/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.1040 - accuracy: 0.3236 - val_loss: 1.1013 - val_accuracy: 0.3000\n",
      "Epoch 5/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.1039 - accuracy: 0.3542 - val_loss: 1.1314 - val_accuracy: 0.3333\n",
      "Epoch 6/38\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0974 - accuracy: 0.3750 - val_loss: 1.1095 - val_accuracy: 0.3111\n",
      "Epoch 7/38\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0908 - accuracy: 0.3778 - val_loss: 1.1072 - val_accuracy: 0.3444\n",
      "Epoch 8/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0879 - accuracy: 0.3722 - val_loss: 1.1100 - val_accuracy: 0.3167\n",
      "Epoch 9/38\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.0874 - accuracy: 0.3722 - val_loss: 1.1114 - val_accuracy: 0.3278\n",
      "Epoch 10/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0823 - accuracy: 0.3681 - val_loss: 1.1233 - val_accuracy: 0.3111\n",
      "Epoch 11/38\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0850 - accuracy: 0.3694 - val_loss: 1.1030 - val_accuracy: 0.3611\n",
      "Epoch 12/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0838 - accuracy: 0.3917 - val_loss: 1.1328 - val_accuracy: 0.3278\n",
      "Epoch 13/38\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0676 - accuracy: 0.4167 - val_loss: 1.1875 - val_accuracy: 0.3167\n",
      "Epoch 14/38\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0996 - accuracy: 0.3792 - val_loss: 1.1349 - val_accuracy: 0.3000\n",
      "Epoch 15/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0841 - accuracy: 0.3597 - val_loss: 1.1212 - val_accuracy: 0.3333\n",
      "Epoch 16/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0684 - accuracy: 0.4111 - val_loss: 1.1366 - val_accuracy: 0.3333\n",
      "Epoch 17/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0715 - accuracy: 0.4208 - val_loss: 1.1675 - val_accuracy: 0.3722\n",
      "Epoch 18/38\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0720 - accuracy: 0.4000 - val_loss: 1.1314 - val_accuracy: 0.2889\n",
      "Epoch 19/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0550 - accuracy: 0.4153 - val_loss: 1.1511 - val_accuracy: 0.3278\n",
      "Epoch 20/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0462 - accuracy: 0.4181 - val_loss: 1.1512 - val_accuracy: 0.3333\n",
      "Epoch 21/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0393 - accuracy: 0.4361 - val_loss: 1.1629 - val_accuracy: 0.3722\n",
      "Epoch 22/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0399 - accuracy: 0.4417 - val_loss: 1.1719 - val_accuracy: 0.3500\n",
      "Epoch 23/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0326 - accuracy: 0.4611 - val_loss: 1.1727 - val_accuracy: 0.3333\n",
      "Epoch 24/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0252 - accuracy: 0.4667 - val_loss: 1.1835 - val_accuracy: 0.3167\n",
      "Epoch 25/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0321 - accuracy: 0.4611 - val_loss: 1.1776 - val_accuracy: 0.3389\n",
      "Epoch 26/38\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0244 - accuracy: 0.4653 - val_loss: 1.1409 - val_accuracy: 0.3444\n",
      "Epoch 27/38\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0188 - accuracy: 0.4500 - val_loss: 1.2149 - val_accuracy: 0.4000\n",
      "Epoch 28/38\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0102 - accuracy: 0.4694 - val_loss: 1.2147 - val_accuracy: 0.3833\n",
      "Epoch 29/38\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0263 - accuracy: 0.4708 - val_loss: 1.2174 - val_accuracy: 0.3278\n",
      "Epoch 30/38\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0068 - accuracy: 0.4778 - val_loss: 1.2153 - val_accuracy: 0.3500\n",
      "Epoch 31/38\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9930 - accuracy: 0.4833 - val_loss: 1.2885 - val_accuracy: 0.3556\n",
      "Epoch 32/38\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9945 - accuracy: 0.4750 - val_loss: 1.2642 - val_accuracy: 0.3722\n",
      "Epoch 33/38\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9745 - accuracy: 0.4875 - val_loss: 1.2663 - val_accuracy: 0.3444\n",
      "Epoch 34/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.9600 - accuracy: 0.5028 - val_loss: 1.2823 - val_accuracy: 0.3611\n",
      "Epoch 35/38\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9581 - accuracy: 0.5028 - val_loss: 1.3222 - val_accuracy: 0.3667\n",
      "Epoch 36/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.9497 - accuracy: 0.5236 - val_loss: 1.2847 - val_accuracy: 0.3889\n",
      "Epoch 37/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.9406 - accuracy: 0.5042 - val_loss: 1.2066 - val_accuracy: 0.4056\n",
      "Epoch 38/38\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.9274 - accuracy: 0.5292 - val_loss: 1.2579 - val_accuracy: 0.4000\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 94.08798217773438, Units2: 34.69451904296875, Dropout Rate: 0.310546875, Learning Rate: 0.052046875000000006, Epochs: 28.47900390625, Batch Size: 93.463134765625\n",
      "\n",
      "Epoch 1/28\n",
      "8/8 [==============================] - 7s 203ms/step - loss: 1.1129 - accuracy: 0.3458 - val_loss: 1.1255 - val_accuracy: 0.2944\n",
      "Epoch 2/28\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1080 - accuracy: 0.3500 - val_loss: 1.0922 - val_accuracy: 0.4278\n",
      "Epoch 3/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0985 - accuracy: 0.3569 - val_loss: 1.1099 - val_accuracy: 0.3722\n",
      "Epoch 4/28\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1020 - accuracy: 0.3722 - val_loss: 1.1025 - val_accuracy: 0.3833\n",
      "Epoch 5/28\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0846 - accuracy: 0.3597 - val_loss: 1.0896 - val_accuracy: 0.3833\n",
      "Epoch 6/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0873 - accuracy: 0.3806 - val_loss: 1.1180 - val_accuracy: 0.3722\n",
      "Epoch 7/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0764 - accuracy: 0.3986 - val_loss: 1.1131 - val_accuracy: 0.3500\n",
      "Epoch 8/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0698 - accuracy: 0.4097 - val_loss: 1.1555 - val_accuracy: 0.3611\n",
      "Epoch 9/28\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0711 - accuracy: 0.4194 - val_loss: 1.1215 - val_accuracy: 0.3278\n",
      "Epoch 10/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0609 - accuracy: 0.4056 - val_loss: 1.1140 - val_accuracy: 0.3611\n",
      "Epoch 11/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0452 - accuracy: 0.4264 - val_loss: 1.1419 - val_accuracy: 0.3944\n",
      "Epoch 12/28\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0424 - accuracy: 0.4333 - val_loss: 1.1637 - val_accuracy: 0.3944\n",
      "Epoch 13/28\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0362 - accuracy: 0.4500 - val_loss: 1.1595 - val_accuracy: 0.3611\n",
      "Epoch 14/28\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0457 - accuracy: 0.4250 - val_loss: 1.1222 - val_accuracy: 0.3778\n",
      "Epoch 15/28\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0357 - accuracy: 0.4708 - val_loss: 1.1601 - val_accuracy: 0.4000\n",
      "Epoch 16/28\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0422 - accuracy: 0.4458 - val_loss: 1.1846 - val_accuracy: 0.3111\n",
      "Epoch 17/28\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0159 - accuracy: 0.4764 - val_loss: 1.1577 - val_accuracy: 0.3333\n",
      "Epoch 18/28\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0175 - accuracy: 0.4625 - val_loss: 1.1939 - val_accuracy: 0.3556\n",
      "Epoch 19/28\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0103 - accuracy: 0.4764 - val_loss: 1.2066 - val_accuracy: 0.3389\n",
      "Epoch 20/28\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9886 - accuracy: 0.4972 - val_loss: 1.2434 - val_accuracy: 0.3000\n",
      "Epoch 21/28\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9716 - accuracy: 0.4903 - val_loss: 1.2497 - val_accuracy: 0.3278\n",
      "Epoch 22/28\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9715 - accuracy: 0.5111 - val_loss: 1.2573 - val_accuracy: 0.3500\n",
      "Epoch 23/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9590 - accuracy: 0.5097 - val_loss: 1.2433 - val_accuracy: 0.3222\n",
      "Epoch 24/28\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9372 - accuracy: 0.5083 - val_loss: 1.2732 - val_accuracy: 0.3667\n",
      "Epoch 25/28\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9323 - accuracy: 0.5111 - val_loss: 1.2940 - val_accuracy: 0.3833\n",
      "Epoch 26/28\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9227 - accuracy: 0.5333 - val_loss: 1.2854 - val_accuracy: 0.3389\n",
      "Epoch 27/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9162 - accuracy: 0.5292 - val_loss: 1.3040 - val_accuracy: 0.3444\n",
      "Epoch 28/28\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8988 - accuracy: 0.5500 - val_loss: 1.3655 - val_accuracy: 0.3444\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 48.133544921875, Units2: 95.13580322265625, Dropout Rate: 0.75, Learning Rate: 0.086078125, Epochs: 92.69683837890625, Batch Size: 35.4168701171875\n",
      "\n",
      "Epoch 1/92\n",
      "21/21 [==============================] - 6s 65ms/step - loss: 1.1901 - accuracy: 0.3431 - val_loss: 1.1090 - val_accuracy: 0.3444\n",
      "Epoch 2/92\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1535 - accuracy: 0.3597 - val_loss: 1.1281 - val_accuracy: 0.3778\n",
      "Epoch 3/92\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1201 - accuracy: 0.3569 - val_loss: 1.1019 - val_accuracy: 0.3111\n",
      "Epoch 4/92\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1136 - accuracy: 0.3375 - val_loss: 1.1007 - val_accuracy: 0.3333\n",
      "Epoch 5/92\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1032 - accuracy: 0.3944 - val_loss: 1.1116 - val_accuracy: 0.3611\n",
      "Epoch 6/92\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1030 - accuracy: 0.3569 - val_loss: 1.1009 - val_accuracy: 0.3167\n",
      "Epoch 7/92\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0999 - accuracy: 0.3333 - val_loss: 1.1035 - val_accuracy: 0.3389\n",
      "Epoch 8/92\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0934 - accuracy: 0.3708 - val_loss: 1.1143 - val_accuracy: 0.3056\n",
      "Epoch 9/92\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1130 - accuracy: 0.3403 - val_loss: 1.1077 - val_accuracy: 0.3056\n",
      "Epoch 10/92\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.1058 - accuracy: 0.3306 - val_loss: 1.1134 - val_accuracy: 0.3000\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 58.6474609375, Units2: 31.397247314453125, Dropout Rate: 0.5, Learning Rate: 0.048953125, Epochs: 13.945465087890625, Batch Size: 68.09432983398438\n",
      "\n",
      "Epoch 1/13\n",
      "11/11 [==============================] - 8s 132ms/step - loss: 1.1166 - accuracy: 0.3417 - val_loss: 1.1015 - val_accuracy: 0.3444\n",
      "Epoch 2/13\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1071 - accuracy: 0.3375 - val_loss: 1.1232 - val_accuracy: 0.3056\n",
      "Epoch 3/13\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1034 - accuracy: 0.3444 - val_loss: 1.1040 - val_accuracy: 0.3333\n",
      "Epoch 4/13\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0965 - accuracy: 0.3653 - val_loss: 1.1000 - val_accuracy: 0.3278\n",
      "Epoch 5/13\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0951 - accuracy: 0.3750 - val_loss: 1.0951 - val_accuracy: 0.3722\n",
      "Epoch 6/13\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0926 - accuracy: 0.3792 - val_loss: 1.1011 - val_accuracy: 0.3833\n",
      "Epoch 7/13\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0777 - accuracy: 0.4042 - val_loss: 1.1055 - val_accuracy: 0.3778\n",
      "Epoch 8/13\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0811 - accuracy: 0.4014 - val_loss: 1.1455 - val_accuracy: 0.3667\n",
      "Epoch 9/13\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0907 - accuracy: 0.3861 - val_loss: 1.1060 - val_accuracy: 0.3556\n",
      "Epoch 10/13\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0888 - accuracy: 0.3694 - val_loss: 1.1001 - val_accuracy: 0.3611\n",
      "Epoch 11/13\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0881 - accuracy: 0.3931 - val_loss: 1.1123 - val_accuracy: 0.3500\n",
      "Epoch 12/13\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.0778 - accuracy: 0.4056 - val_loss: 1.1018 - val_accuracy: 0.3333\n",
      "Epoch 13/13\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0799 - accuracy: 0.4028 - val_loss: 1.1006 - val_accuracy: 0.3611\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 94.8748779296875, Units2: 17.62725830078125, Dropout Rate: 0.8125, Learning Rate: 0.070609375, Epochs: 95.52032470703125, Batch Size: 65.08407592773438\n",
      "\n",
      "Epoch 1/95\n",
      "12/12 [==============================] - 7s 144ms/step - loss: 1.1207 - accuracy: 0.3583 - val_loss: 1.1122 - val_accuracy: 0.3056\n",
      "Epoch 2/95\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.1164 - accuracy: 0.3556 - val_loss: 1.1068 - val_accuracy: 0.3333\n",
      "Epoch 3/95\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.1059 - accuracy: 0.3528 - val_loss: 1.1042 - val_accuracy: 0.3611\n",
      "Epoch 4/95\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.1028 - accuracy: 0.3444 - val_loss: 1.1098 - val_accuracy: 0.3667\n",
      "Epoch 5/95\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 1.1033 - accuracy: 0.3444 - val_loss: 1.0979 - val_accuracy: 0.3278\n",
      "Epoch 6/95\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1051 - accuracy: 0.3361 - val_loss: 1.1082 - val_accuracy: 0.3333\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 42.254486083984375, Units2: 68.60931396484375, Dropout Rate: 0.3671875, Learning Rate: 0.06596875, Epochs: 38.34747314453125, Batch Size: 66.85699462890625\n",
      "\n",
      "Epoch 1/38\n",
      "11/11 [==============================] - 6s 146ms/step - loss: 1.1194 - accuracy: 0.3333 - val_loss: 1.1043 - val_accuracy: 0.3389\n",
      "Epoch 2/38\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.1192 - accuracy: 0.3375 - val_loss: 1.1195 - val_accuracy: 0.3167\n",
      "Epoch 3/38\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.0966 - accuracy: 0.3653 - val_loss: 1.1058 - val_accuracy: 0.3222\n",
      "Epoch 4/38\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0935 - accuracy: 0.3708 - val_loss: 1.1224 - val_accuracy: 0.3389\n",
      "Epoch 5/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0707 - accuracy: 0.3944 - val_loss: 1.1560 - val_accuracy: 0.3389\n",
      "Epoch 6/38\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.0869 - accuracy: 0.4042 - val_loss: 1.1252 - val_accuracy: 0.3444\n",
      "Epoch 7/38\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0786 - accuracy: 0.3833 - val_loss: 1.1292 - val_accuracy: 0.3222\n",
      "Epoch 8/38\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0731 - accuracy: 0.4014 - val_loss: 1.1263 - val_accuracy: 0.3111\n",
      "Epoch 9/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0706 - accuracy: 0.4069 - val_loss: 1.1519 - val_accuracy: 0.3278\n",
      "Epoch 10/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0479 - accuracy: 0.4500 - val_loss: 1.1916 - val_accuracy: 0.3556\n",
      "Epoch 11/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0391 - accuracy: 0.4403 - val_loss: 1.1672 - val_accuracy: 0.3444\n",
      "Epoch 12/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0392 - accuracy: 0.4583 - val_loss: 1.1763 - val_accuracy: 0.3389\n",
      "Epoch 13/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0327 - accuracy: 0.4528 - val_loss: 1.2064 - val_accuracy: 0.3500\n",
      "Epoch 14/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0253 - accuracy: 0.4597 - val_loss: 1.1520 - val_accuracy: 0.3222\n",
      "Epoch 15/38\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0074 - accuracy: 0.4597 - val_loss: 1.2174 - val_accuracy: 0.3444\n",
      "Epoch 16/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9964 - accuracy: 0.4583 - val_loss: 1.1804 - val_accuracy: 0.3778\n",
      "Epoch 17/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0138 - accuracy: 0.4694 - val_loss: 1.1996 - val_accuracy: 0.3556\n",
      "Epoch 18/38\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.9884 - accuracy: 0.4639 - val_loss: 1.2528 - val_accuracy: 0.3556\n",
      "Epoch 19/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0005 - accuracy: 0.4597 - val_loss: 1.2494 - val_accuracy: 0.4000\n",
      "Epoch 20/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9871 - accuracy: 0.4750 - val_loss: 1.2981 - val_accuracy: 0.3000\n",
      "Epoch 21/38\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9679 - accuracy: 0.4778 - val_loss: 1.1796 - val_accuracy: 0.3611\n",
      "Epoch 22/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9686 - accuracy: 0.5014 - val_loss: 1.3138 - val_accuracy: 0.3278\n",
      "Epoch 23/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9396 - accuracy: 0.5306 - val_loss: 1.2633 - val_accuracy: 0.3389\n",
      "Epoch 24/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9542 - accuracy: 0.4958 - val_loss: 1.2770 - val_accuracy: 0.3444\n",
      "Epoch 25/38\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.9415 - accuracy: 0.5194 - val_loss: 1.1994 - val_accuracy: 0.3389\n",
      "Epoch 26/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9316 - accuracy: 0.5056 - val_loss: 1.3299 - val_accuracy: 0.3333\n",
      "Epoch 27/38\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.9309 - accuracy: 0.5333 - val_loss: 1.3609 - val_accuracy: 0.3111\n",
      "Epoch 28/38\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.9228 - accuracy: 0.5167 - val_loss: 1.3767 - val_accuracy: 0.3500\n",
      "Epoch 29/38\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.9147 - accuracy: 0.5306 - val_loss: 1.4544 - val_accuracy: 0.3556\n",
      "Epoch 30/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8938 - accuracy: 0.5528 - val_loss: 1.3160 - val_accuracy: 0.3111\n",
      "Epoch 31/38\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.8926 - accuracy: 0.5403 - val_loss: 1.2891 - val_accuracy: 0.3444\n",
      "Epoch 32/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9139 - accuracy: 0.5306 - val_loss: 1.3557 - val_accuracy: 0.3389\n",
      "Epoch 33/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8735 - accuracy: 0.5528 - val_loss: 1.3018 - val_accuracy: 0.3833\n",
      "Epoch 34/38\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.8794 - accuracy: 0.5528 - val_loss: 1.3686 - val_accuracy: 0.3278\n",
      "Epoch 35/38\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.8584 - accuracy: 0.5708 - val_loss: 1.3530 - val_accuracy: 0.3278\n",
      "Epoch 36/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8406 - accuracy: 0.5875 - val_loss: 1.4147 - val_accuracy: 0.3556\n",
      "Epoch 37/38\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.8737 - accuracy: 0.5806 - val_loss: 1.3212 - val_accuracy: 0.3500\n",
      "Epoch 38/38\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8268 - accuracy: 0.5681 - val_loss: 1.3854 - val_accuracy: 0.3611\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 74.56253051757812, Units2: 11.665802001953125, Dropout Rate: 0.0546875, Learning Rate: 0.06596875, Epochs: 71.73629760742188, Batch Size: 31.49200439453125\n",
      "\n",
      "Epoch 1/71\n",
      "24/24 [==============================] - 6s 58ms/step - loss: 1.1071 - accuracy: 0.3306 - val_loss: 1.1067 - val_accuracy: 0.3222\n",
      "Epoch 2/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1058 - accuracy: 0.3264 - val_loss: 1.1045 - val_accuracy: 0.3611\n",
      "Epoch 3/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0992 - accuracy: 0.3444 - val_loss: 1.1039 - val_accuracy: 0.3500\n",
      "Epoch 4/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0973 - accuracy: 0.3486 - val_loss: 1.1251 - val_accuracy: 0.3111\n",
      "Epoch 5/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1015 - accuracy: 0.3222 - val_loss: 1.1189 - val_accuracy: 0.3278\n",
      "Epoch 6/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0983 - accuracy: 0.3556 - val_loss: 1.1160 - val_accuracy: 0.3556\n",
      "Epoch 7/71\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.0890 - accuracy: 0.3847 - val_loss: 1.1415 - val_accuracy: 0.2833\n",
      "Epoch 8/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0924 - accuracy: 0.3736 - val_loss: 1.1290 - val_accuracy: 0.3611\n",
      "Epoch 9/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0884 - accuracy: 0.3611 - val_loss: 1.1438 - val_accuracy: 0.3333\n",
      "Epoch 10/71\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.0820 - accuracy: 0.3986 - val_loss: 1.1216 - val_accuracy: 0.3389\n",
      "Epoch 11/71\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0840 - accuracy: 0.3889 - val_loss: 1.1084 - val_accuracy: 0.3222\n",
      "Epoch 12/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0748 - accuracy: 0.4069 - val_loss: 1.1284 - val_accuracy: 0.3500\n",
      "Epoch 13/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0771 - accuracy: 0.3736 - val_loss: 1.1245 - val_accuracy: 0.3500\n",
      "Epoch 14/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0737 - accuracy: 0.3736 - val_loss: 1.1446 - val_accuracy: 0.3333\n",
      "Epoch 15/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0816 - accuracy: 0.3819 - val_loss: 1.1081 - val_accuracy: 0.3667\n",
      "Epoch 16/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0678 - accuracy: 0.4278 - val_loss: 1.1259 - val_accuracy: 0.3556\n",
      "Epoch 17/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0631 - accuracy: 0.4236 - val_loss: 1.1535 - val_accuracy: 0.3556\n",
      "Epoch 18/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0954 - accuracy: 0.3611 - val_loss: 1.1334 - val_accuracy: 0.3944\n",
      "Epoch 19/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0711 - accuracy: 0.3986 - val_loss: 1.1438 - val_accuracy: 0.3556\n",
      "Epoch 20/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0411 - accuracy: 0.4125 - val_loss: 1.1349 - val_accuracy: 0.3556\n",
      "Epoch 21/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0683 - accuracy: 0.4333 - val_loss: 1.1383 - val_accuracy: 0.3611\n",
      "Epoch 22/71\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0412 - accuracy: 0.4528 - val_loss: 1.1575 - val_accuracy: 0.3444\n",
      "Epoch 23/71\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0406 - accuracy: 0.4611 - val_loss: 1.1592 - val_accuracy: 0.3500\n",
      "Epoch 24/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0509 - accuracy: 0.4472 - val_loss: 1.1465 - val_accuracy: 0.3556\n",
      "Epoch 25/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0392 - accuracy: 0.4472 - val_loss: 1.1427 - val_accuracy: 0.3667\n",
      "Epoch 26/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0574 - accuracy: 0.3958 - val_loss: 1.1502 - val_accuracy: 0.3389\n",
      "Epoch 27/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0387 - accuracy: 0.4458 - val_loss: 1.1857 - val_accuracy: 0.3278\n",
      "Epoch 28/71\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0148 - accuracy: 0.4889 - val_loss: 1.2383 - val_accuracy: 0.3111\n",
      "Epoch 29/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0387 - accuracy: 0.4361 - val_loss: 1.1818 - val_accuracy: 0.3333\n",
      "Epoch 30/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4750 - val_loss: 1.1937 - val_accuracy: 0.3167\n",
      "Epoch 31/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0271 - accuracy: 0.4653 - val_loss: 1.1967 - val_accuracy: 0.3056\n",
      "Epoch 32/71\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0091 - accuracy: 0.4819 - val_loss: 1.2184 - val_accuracy: 0.3111\n",
      "Epoch 33/71\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.0112 - accuracy: 0.4722 - val_loss: 1.2316 - val_accuracy: 0.3222\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 21.17034912109375, Units2: 43.79119873046875, Dropout Rate: 0.033203125, Learning Rate: 0.044312500000000005, Epochs: 16.403656005859375, Batch Size: 30.555419921875\n",
      "\n",
      "Epoch 1/16\n",
      "24/24 [==============================] - 6s 60ms/step - loss: 1.1106 - accuracy: 0.3167 - val_loss: 1.0992 - val_accuracy: 0.3722\n",
      "Epoch 2/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.1047 - accuracy: 0.3403 - val_loss: 1.0995 - val_accuracy: 0.3444\n",
      "Epoch 3/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0983 - accuracy: 0.3486 - val_loss: 1.1045 - val_accuracy: 0.3278\n",
      "Epoch 4/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0996 - accuracy: 0.3264 - val_loss: 1.1025 - val_accuracy: 0.3000\n",
      "Epoch 5/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0994 - accuracy: 0.3458 - val_loss: 1.1004 - val_accuracy: 0.3444\n",
      "Epoch 6/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0943 - accuracy: 0.3708 - val_loss: 1.0995 - val_accuracy: 0.3667\n",
      "Epoch 7/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0834 - accuracy: 0.3819 - val_loss: 1.0926 - val_accuracy: 0.3500\n",
      "Epoch 8/16\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0790 - accuracy: 0.3903 - val_loss: 1.0940 - val_accuracy: 0.3500\n",
      "Epoch 9/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0866 - accuracy: 0.3792 - val_loss: 1.0923 - val_accuracy: 0.3833\n",
      "Epoch 10/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0786 - accuracy: 0.3958 - val_loss: 1.1103 - val_accuracy: 0.3111\n",
      "Epoch 11/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0673 - accuracy: 0.4056 - val_loss: 1.0923 - val_accuracy: 0.3778\n",
      "Epoch 12/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0654 - accuracy: 0.4083 - val_loss: 1.1376 - val_accuracy: 0.3611\n",
      "Epoch 13/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0595 - accuracy: 0.4222 - val_loss: 1.0736 - val_accuracy: 0.3833\n",
      "Epoch 14/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0537 - accuracy: 0.4208 - val_loss: 1.0951 - val_accuracy: 0.3611\n",
      "Epoch 15/16\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.0533 - accuracy: 0.4347 - val_loss: 1.0850 - val_accuracy: 0.3889\n",
      "Epoch 16/16\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0623 - accuracy: 0.3972 - val_loss: 1.1010 - val_accuracy: 0.3833\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 20.372467041015625, Units2: 29.072265625, Dropout Rate: 0.408203125, Learning Rate: 0.021109375000000003, Epochs: 24.40582275390625, Batch Size: 71.42868041992188\n",
      "\n",
      "Epoch 1/24\n",
      "11/11 [==============================] - 6s 123ms/step - loss: 1.1042 - accuracy: 0.3000 - val_loss: 1.0987 - val_accuracy: 0.3722\n",
      "Epoch 2/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1017 - accuracy: 0.3556 - val_loss: 1.1017 - val_accuracy: 0.3278\n",
      "Epoch 3/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0900 - accuracy: 0.3611 - val_loss: 1.1087 - val_accuracy: 0.3278\n",
      "Epoch 4/24\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0909 - accuracy: 0.3556 - val_loss: 1.1062 - val_accuracy: 0.3778\n",
      "Epoch 5/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0894 - accuracy: 0.3611 - val_loss: 1.1057 - val_accuracy: 0.3500\n",
      "Epoch 6/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0950 - accuracy: 0.3944 - val_loss: 1.1059 - val_accuracy: 0.3722\n",
      "Epoch 7/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0901 - accuracy: 0.3750 - val_loss: 1.1114 - val_accuracy: 0.3833\n",
      "Epoch 8/24\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0828 - accuracy: 0.4028 - val_loss: 1.1025 - val_accuracy: 0.3778\n",
      "Epoch 9/24\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0786 - accuracy: 0.4153 - val_loss: 1.1154 - val_accuracy: 0.3833\n",
      "Epoch 10/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0823 - accuracy: 0.3944 - val_loss: 1.1200 - val_accuracy: 0.3833\n",
      "Epoch 11/24\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0750 - accuracy: 0.4069 - val_loss: 1.1320 - val_accuracy: 0.3556\n",
      "Epoch 12/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0736 - accuracy: 0.3917 - val_loss: 1.1364 - val_accuracy: 0.3556\n",
      "Epoch 13/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0738 - accuracy: 0.4181 - val_loss: 1.1224 - val_accuracy: 0.3444\n",
      "Epoch 14/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0679 - accuracy: 0.4292 - val_loss: 1.1100 - val_accuracy: 0.3722\n",
      "Epoch 15/24\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0578 - accuracy: 0.4111 - val_loss: 1.1140 - val_accuracy: 0.3500\n",
      "Epoch 16/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0549 - accuracy: 0.4306 - val_loss: 1.1204 - val_accuracy: 0.3778\n",
      "Epoch 17/24\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.0628 - accuracy: 0.4181 - val_loss: 1.1047 - val_accuracy: 0.3611\n",
      "Epoch 18/24\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0544 - accuracy: 0.4194 - val_loss: 1.1229 - val_accuracy: 0.3556\n",
      "Epoch 19/24\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0565 - accuracy: 0.4319 - val_loss: 1.1248 - val_accuracy: 0.3889\n",
      "Epoch 20/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0480 - accuracy: 0.4292 - val_loss: 1.1468 - val_accuracy: 0.3944\n",
      "Epoch 21/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0417 - accuracy: 0.4500 - val_loss: 1.1381 - val_accuracy: 0.3722\n",
      "Epoch 22/24\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0363 - accuracy: 0.4458 - val_loss: 1.1438 - val_accuracy: 0.3500\n",
      "Epoch 23/24\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0309 - accuracy: 0.4375 - val_loss: 1.1416 - val_accuracy: 0.3389\n",
      "Epoch 24/24\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0282 - accuracy: 0.4458 - val_loss: 1.1545 - val_accuracy: 0.3444\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 54.806365966796875, Units2: 62.49542236328125, Dropout Rate: 0.08203125, Learning Rate: 0.014921875000000001, Epochs: 94.298095703125, Batch Size: 18.4320068359375\n",
      "\n",
      "Epoch 1/94\n",
      "40/40 [==============================] - 6s 36ms/step - loss: 1.1040 - accuracy: 0.3542 - val_loss: 1.1087 - val_accuracy: 0.3833\n",
      "Epoch 2/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0994 - accuracy: 0.3681 - val_loss: 1.1122 - val_accuracy: 0.3167\n",
      "Epoch 3/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0957 - accuracy: 0.3556 - val_loss: 1.1058 - val_accuracy: 0.3556\n",
      "Epoch 4/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0957 - accuracy: 0.3542 - val_loss: 1.1066 - val_accuracy: 0.3556\n",
      "Epoch 5/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.0915 - accuracy: 0.3778 - val_loss: 1.1218 - val_accuracy: 0.3833\n",
      "Epoch 6/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0901 - accuracy: 0.3861 - val_loss: 1.1076 - val_accuracy: 0.3556\n",
      "Epoch 7/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0894 - accuracy: 0.3736 - val_loss: 1.0916 - val_accuracy: 0.3611\n",
      "Epoch 8/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0849 - accuracy: 0.3931 - val_loss: 1.1101 - val_accuracy: 0.3611\n",
      "Epoch 9/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0825 - accuracy: 0.3708 - val_loss: 1.0990 - val_accuracy: 0.3722\n",
      "Epoch 10/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0790 - accuracy: 0.4111 - val_loss: 1.1135 - val_accuracy: 0.3833\n",
      "Epoch 11/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.0799 - accuracy: 0.3903 - val_loss: 1.1193 - val_accuracy: 0.3389\n",
      "Epoch 12/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.0735 - accuracy: 0.4125 - val_loss: 1.1392 - val_accuracy: 0.3444\n",
      "Epoch 13/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0654 - accuracy: 0.4139 - val_loss: 1.1298 - val_accuracy: 0.3556\n",
      "Epoch 14/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0509 - accuracy: 0.4347 - val_loss: 1.1484 - val_accuracy: 0.3944\n",
      "Epoch 15/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0527 - accuracy: 0.4347 - val_loss: 1.1500 - val_accuracy: 0.3333\n",
      "Epoch 16/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0458 - accuracy: 0.4292 - val_loss: 1.1656 - val_accuracy: 0.3667\n",
      "Epoch 17/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0328 - accuracy: 0.4417 - val_loss: 1.1498 - val_accuracy: 0.3500\n",
      "Epoch 18/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0234 - accuracy: 0.4472 - val_loss: 1.1688 - val_accuracy: 0.3611\n",
      "Epoch 19/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0162 - accuracy: 0.4444 - val_loss: 1.1784 - val_accuracy: 0.3333\n",
      "Epoch 20/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0142 - accuracy: 0.4694 - val_loss: 1.1518 - val_accuracy: 0.3667\n",
      "Epoch 21/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.0004 - accuracy: 0.4653 - val_loss: 1.2009 - val_accuracy: 0.3833\n",
      "Epoch 22/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.9883 - accuracy: 0.4778 - val_loss: 1.2008 - val_accuracy: 0.3667\n",
      "Epoch 23/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9758 - accuracy: 0.4722 - val_loss: 1.2177 - val_accuracy: 0.3500\n",
      "Epoch 24/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.9765 - accuracy: 0.4833 - val_loss: 1.1966 - val_accuracy: 0.3278\n",
      "Epoch 25/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9388 - accuracy: 0.5194 - val_loss: 1.2115 - val_accuracy: 0.3389\n",
      "Epoch 26/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.9367 - accuracy: 0.4972 - val_loss: 1.2724 - val_accuracy: 0.3056\n",
      "Epoch 27/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9260 - accuracy: 0.5097 - val_loss: 1.2880 - val_accuracy: 0.3056\n",
      "Epoch 28/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9169 - accuracy: 0.5181 - val_loss: 1.2945 - val_accuracy: 0.3556\n",
      "Epoch 29/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.8895 - accuracy: 0.5542 - val_loss: 1.3140 - val_accuracy: 0.3556\n",
      "Epoch 30/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8607 - accuracy: 0.5639 - val_loss: 1.3043 - val_accuracy: 0.3444\n",
      "Epoch 31/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.8756 - accuracy: 0.5403 - val_loss: 1.3465 - val_accuracy: 0.3389\n",
      "Epoch 32/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.8360 - accuracy: 0.5875 - val_loss: 1.3861 - val_accuracy: 0.3778\n",
      "Epoch 33/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8298 - accuracy: 0.5847 - val_loss: 1.4404 - val_accuracy: 0.3056\n",
      "Epoch 34/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8341 - accuracy: 0.5736 - val_loss: 1.4774 - val_accuracy: 0.3556\n",
      "Epoch 35/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.8363 - accuracy: 0.5861 - val_loss: 1.3981 - val_accuracy: 0.3556\n",
      "Epoch 36/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7848 - accuracy: 0.6000 - val_loss: 1.4742 - val_accuracy: 0.3722\n",
      "Epoch 37/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.7716 - accuracy: 0.5931 - val_loss: 1.4964 - val_accuracy: 0.3333\n",
      "Epoch 38/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7570 - accuracy: 0.6000 - val_loss: 1.5439 - val_accuracy: 0.3167\n",
      "Epoch 39/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7490 - accuracy: 0.6181 - val_loss: 1.5920 - val_accuracy: 0.3167\n",
      "Epoch 40/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.7257 - accuracy: 0.6389 - val_loss: 1.6693 - val_accuracy: 0.3833\n",
      "Epoch 41/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7148 - accuracy: 0.6556 - val_loss: 1.6763 - val_accuracy: 0.3556\n",
      "Epoch 42/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.6597 - val_loss: 1.6135 - val_accuracy: 0.3944\n",
      "Epoch 43/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.6472 - val_loss: 1.6862 - val_accuracy: 0.3444\n",
      "Epoch 44/94\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6920 - accuracy: 0.6653 - val_loss: 1.7243 - val_accuracy: 0.3389\n",
      "Epoch 45/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6845 - accuracy: 0.6611 - val_loss: 1.7189 - val_accuracy: 0.3667\n",
      "Epoch 46/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6540 - accuracy: 0.6847 - val_loss: 1.7356 - val_accuracy: 0.3889\n",
      "Epoch 47/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6204 - accuracy: 0.6931 - val_loss: 1.8822 - val_accuracy: 0.3667\n",
      "Epoch 48/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6322 - accuracy: 0.6972 - val_loss: 1.8221 - val_accuracy: 0.4056\n",
      "Epoch 49/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6045 - accuracy: 0.7236 - val_loss: 1.8732 - val_accuracy: 0.3833\n",
      "Epoch 50/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6030 - accuracy: 0.7028 - val_loss: 1.9019 - val_accuracy: 0.3278\n",
      "Epoch 51/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.7292 - val_loss: 2.0231 - val_accuracy: 0.3667\n",
      "Epoch 52/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5652 - accuracy: 0.7375 - val_loss: 1.9156 - val_accuracy: 0.3889\n",
      "Epoch 53/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7361 - val_loss: 2.0625 - val_accuracy: 0.4000\n",
      "Epoch 54/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.7417 - val_loss: 1.9635 - val_accuracy: 0.4056\n",
      "Epoch 55/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5491 - accuracy: 0.7375 - val_loss: 2.0102 - val_accuracy: 0.4167\n",
      "Epoch 56/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7528 - val_loss: 2.0843 - val_accuracy: 0.4111\n",
      "Epoch 57/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7347 - val_loss: 2.1920 - val_accuracy: 0.3778\n",
      "Epoch 58/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7625 - val_loss: 2.2880 - val_accuracy: 0.4000\n",
      "Epoch 59/94\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.5115 - accuracy: 0.7542 - val_loss: 2.2619 - val_accuracy: 0.3778\n",
      "Epoch 60/94\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.5068 - accuracy: 0.7625 - val_loss: 2.3335 - val_accuracy: 0.3833\n",
      "Epoch 61/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.7847 - val_loss: 2.2835 - val_accuracy: 0.4278\n",
      "Epoch 62/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7694 - val_loss: 2.4965 - val_accuracy: 0.3833\n",
      "Epoch 63/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7625 - val_loss: 2.3460 - val_accuracy: 0.4444\n",
      "Epoch 64/94\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.4624 - accuracy: 0.7806 - val_loss: 2.4676 - val_accuracy: 0.3944\n",
      "Epoch 65/94\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.7792 - val_loss: 2.3711 - val_accuracy: 0.4167\n",
      "Epoch 66/94\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7792 - val_loss: 2.4626 - val_accuracy: 0.4056\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 50.189361572265625, Units2: 46.473236083984375, Dropout Rate: 0.328125, Learning Rate: 0.076796875, Epochs: 86.97296142578125, Batch Size: 89.10018920898438\n",
      "\n",
      "Epoch 1/86\n",
      "9/9 [==============================] - 6s 151ms/step - loss: 1.1205 - accuracy: 0.3194 - val_loss: 1.1008 - val_accuracy: 0.3722\n",
      "Epoch 2/86\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1233 - accuracy: 0.3333 - val_loss: 1.1374 - val_accuracy: 0.3667\n",
      "Epoch 3/86\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1094 - accuracy: 0.3778 - val_loss: 1.1015 - val_accuracy: 0.3278\n",
      "Epoch 4/86\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0947 - accuracy: 0.3694 - val_loss: 1.1080 - val_accuracy: 0.3611\n",
      "Epoch 5/86\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0943 - accuracy: 0.3861 - val_loss: 1.1236 - val_accuracy: 0.3222\n",
      "Epoch 6/86\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1012 - accuracy: 0.3556 - val_loss: 1.1071 - val_accuracy: 0.3722\n",
      "Epoch 7/86\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0800 - accuracy: 0.3792 - val_loss: 1.1099 - val_accuracy: 0.3778\n",
      "Epoch 8/86\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.0751 - accuracy: 0.3875 - val_loss: 1.1085 - val_accuracy: 0.4111\n",
      "Epoch 9/86\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0658 - accuracy: 0.3944 - val_loss: 1.1181 - val_accuracy: 0.3389\n",
      "Epoch 10/86\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0535 - accuracy: 0.4208 - val_loss: 1.1134 - val_accuracy: 0.3667\n",
      "Epoch 11/86\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0721 - accuracy: 0.4194 - val_loss: 1.1051 - val_accuracy: 0.3556\n",
      "Epoch 12/86\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0530 - accuracy: 0.4514 - val_loss: 1.1185 - val_accuracy: 0.4056\n",
      "Epoch 13/86\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.0618 - accuracy: 0.4236 - val_loss: 1.1161 - val_accuracy: 0.3667\n",
      "Epoch 14/86\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0589 - accuracy: 0.4208 - val_loss: 1.1144 - val_accuracy: 0.3667\n",
      "Epoch 15/86\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0724 - accuracy: 0.4208 - val_loss: 1.1066 - val_accuracy: 0.3444\n",
      "Epoch 16/86\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0390 - accuracy: 0.4444 - val_loss: 1.1373 - val_accuracy: 0.3778\n",
      "Epoch 17/86\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.0375 - accuracy: 0.4306 - val_loss: 1.1749 - val_accuracy: 0.3611\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 29.620208740234375, Units2: 22.821044921875, Dropout Rate: 0.599609375, Learning Rate: 0.070609375, Epochs: 72.7978515625, Batch Size: 33.311614990234375\n",
      "\n",
      "Epoch 1/72\n",
      "22/22 [==============================] - 6s 68ms/step - loss: 1.1253 - accuracy: 0.3264 - val_loss: 1.1058 - val_accuracy: 0.3333\n",
      "Epoch 2/72\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.1138 - accuracy: 0.3361 - val_loss: 1.1108 - val_accuracy: 0.3167\n",
      "Epoch 3/72\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0989 - accuracy: 0.3417 - val_loss: 1.1079 - val_accuracy: 0.3167\n",
      "Epoch 4/72\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1043 - accuracy: 0.3444 - val_loss: 1.1151 - val_accuracy: 0.3222\n",
      "Epoch 5/72\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0991 - accuracy: 0.3861 - val_loss: 1.0999 - val_accuracy: 0.3500\n",
      "Epoch 6/72\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0963 - accuracy: 0.4056 - val_loss: 1.1144 - val_accuracy: 0.3556\n",
      "Epoch 7/72\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0991 - accuracy: 0.3486 - val_loss: 1.1133 - val_accuracy: 0.3333\n",
      "Epoch 8/72\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.0941 - accuracy: 0.3569 - val_loss: 1.1069 - val_accuracy: 0.3222\n",
      "Epoch 9/72\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.0884 - accuracy: 0.3903 - val_loss: 1.1184 - val_accuracy: 0.3333\n",
      "Epoch 10/72\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.1002 - accuracy: 0.3486 - val_loss: 1.1113 - val_accuracy: 0.3333\n",
      "Epoch 11/72\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0944 - accuracy: 0.3542 - val_loss: 1.1319 - val_accuracy: 0.3222\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 57.580413818359375, Units2: 22.415924072265625, Dropout Rate: 0.90234375, Learning Rate: 0.07370312500000001, Epochs: 92.95913696289062, Batch Size: 57.607879638671875\n",
      "\n",
      "Epoch 1/92\n",
      "13/13 [==============================] - 7s 114ms/step - loss: 1.1518 - accuracy: 0.3389 - val_loss: 1.0923 - val_accuracy: 0.3889\n",
      "Epoch 2/92\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.1228 - accuracy: 0.3111 - val_loss: 1.1002 - val_accuracy: 0.2944\n",
      "Epoch 3/92\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.1110 - accuracy: 0.2889 - val_loss: 1.0933 - val_accuracy: 0.3833\n",
      "Epoch 4/92\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.1033 - accuracy: 0.3472 - val_loss: 1.0991 - val_accuracy: 0.3056\n",
      "Epoch 5/92\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.1014 - accuracy: 0.3403 - val_loss: 1.0979 - val_accuracy: 0.3722\n",
      "Epoch 6/92\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.1073 - accuracy: 0.3347 - val_loss: 1.0965 - val_accuracy: 0.3778\n",
      "Epoch 7/92\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.1075 - accuracy: 0.3333 - val_loss: 1.0993 - val_accuracy: 0.3222\n",
      "Epoch 8/92\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.1039 - accuracy: 0.3208 - val_loss: 1.0990 - val_accuracy: 0.3278\n",
      "Epoch 9/92\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.1054 - accuracy: 0.2917 - val_loss: 1.0973 - val_accuracy: 0.3778\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 24.7381591796875, Units2: 51.220703125, Dropout Rate: 0.203125, Learning Rate: 0.0505, Epochs: 48.73504638671875, Batch Size: 18.48419189453125\n",
      "\n",
      "Epoch 1/48\n",
      "40/40 [==============================] - 8s 36ms/step - loss: 1.1219 - accuracy: 0.3181 - val_loss: 1.0945 - val_accuracy: 0.3722\n",
      "Epoch 2/48\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.1063 - accuracy: 0.3208 - val_loss: 1.1117 - val_accuracy: 0.3500\n",
      "Epoch 3/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.1046 - accuracy: 0.3181 - val_loss: 1.0988 - val_accuracy: 0.3611\n",
      "Epoch 4/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.1006 - accuracy: 0.3444 - val_loss: 1.1049 - val_accuracy: 0.3333\n",
      "Epoch 5/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.1027 - accuracy: 0.3569 - val_loss: 1.0971 - val_accuracy: 0.3667\n",
      "Epoch 6/48\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.1029 - accuracy: 0.3444 - val_loss: 1.1126 - val_accuracy: 0.2889\n",
      "Epoch 7/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.1067 - accuracy: 0.3194 - val_loss: 1.1071 - val_accuracy: 0.3222\n",
      "Epoch 8/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0948 - accuracy: 0.3222 - val_loss: 1.1063 - val_accuracy: 0.3278\n",
      "Epoch 9/48\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.1017 - accuracy: 0.3847 - val_loss: 1.0970 - val_accuracy: 0.3500\n",
      "Epoch 10/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0937 - accuracy: 0.3514 - val_loss: 1.1236 - val_accuracy: 0.3778\n",
      "Epoch 11/48\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.1001 - accuracy: 0.3528 - val_loss: 1.1181 - val_accuracy: 0.3278\n",
      "Epoch 12/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0954 - accuracy: 0.3583 - val_loss: 1.1035 - val_accuracy: 0.3111\n",
      "Epoch 13/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0853 - accuracy: 0.3889 - val_loss: 1.1184 - val_accuracy: 0.3667\n",
      "Epoch 14/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0870 - accuracy: 0.3847 - val_loss: 1.1872 - val_accuracy: 0.3389\n",
      "Epoch 15/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0922 - accuracy: 0.3694 - val_loss: 1.1210 - val_accuracy: 0.3111\n",
      "Epoch 16/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0830 - accuracy: 0.3917 - val_loss: 1.1210 - val_accuracy: 0.3056\n",
      "Epoch 17/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0733 - accuracy: 0.4125 - val_loss: 1.1127 - val_accuracy: 0.3278\n",
      "Epoch 18/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0634 - accuracy: 0.3972 - val_loss: 1.1869 - val_accuracy: 0.3167\n",
      "Epoch 19/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0838 - accuracy: 0.4028 - val_loss: 1.1584 - val_accuracy: 0.3278\n",
      "Epoch 20/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0610 - accuracy: 0.4333 - val_loss: 1.2254 - val_accuracy: 0.3444\n",
      "Epoch 21/48\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.0637 - accuracy: 0.4292 - val_loss: 1.1637 - val_accuracy: 0.3222\n",
      "Epoch 22/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0627 - accuracy: 0.4236 - val_loss: 1.1448 - val_accuracy: 0.3333\n",
      "Epoch 23/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0558 - accuracy: 0.4319 - val_loss: 1.1900 - val_accuracy: 0.3389\n",
      "Epoch 24/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0275 - accuracy: 0.4333 - val_loss: 1.2270 - val_accuracy: 0.3333\n",
      "Epoch 25/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0388 - accuracy: 0.4694 - val_loss: 1.1612 - val_accuracy: 0.3778\n",
      "Epoch 26/48\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.0318 - accuracy: 0.4431 - val_loss: 1.1812 - val_accuracy: 0.3778\n",
      "Epoch 27/48\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0320 - accuracy: 0.4486 - val_loss: 1.2436 - val_accuracy: 0.3000\n",
      "Epoch 28/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0076 - accuracy: 0.4806 - val_loss: 1.2466 - val_accuracy: 0.3167\n",
      "Epoch 29/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0409 - accuracy: 0.4583 - val_loss: 1.2601 - val_accuracy: 0.3667\n",
      "Epoch 30/48\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 1.0249 - accuracy: 0.4583 - val_loss: 1.2425 - val_accuracy: 0.3500\n",
      "Epoch 31/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0082 - accuracy: 0.4611 - val_loss: 1.2967 - val_accuracy: 0.3667\n",
      "Epoch 32/48\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0213 - accuracy: 0.4500 - val_loss: 1.2126 - val_accuracy: 0.3444\n",
      "Epoch 33/48\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.9911 - accuracy: 0.4958 - val_loss: 1.2927 - val_accuracy: 0.3722\n",
      "Epoch 34/48\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.0000 - accuracy: 0.4667 - val_loss: 1.2239 - val_accuracy: 0.3778\n",
      "Epoch 35/48\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.9888 - accuracy: 0.4750 - val_loss: 1.2728 - val_accuracy: 0.3500\n",
      "Epoch 36/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.0111 - accuracy: 0.4792 - val_loss: 1.2218 - val_accuracy: 0.3389\n",
      "Epoch 37/48\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.9905 - accuracy: 0.4653 - val_loss: 1.2869 - val_accuracy: 0.3444\n",
      "Epoch 38/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9977 - accuracy: 0.5000 - val_loss: 1.2597 - val_accuracy: 0.3222\n",
      "Epoch 39/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9945 - accuracy: 0.4736 - val_loss: 1.2498 - val_accuracy: 0.3778\n",
      "Epoch 40/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9800 - accuracy: 0.5000 - val_loss: 1.2706 - val_accuracy: 0.3833\n",
      "Epoch 41/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9616 - accuracy: 0.5250 - val_loss: 1.3786 - val_accuracy: 0.3667\n",
      "Epoch 42/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9798 - accuracy: 0.5000 - val_loss: 1.2440 - val_accuracy: 0.3611\n",
      "Epoch 43/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9739 - accuracy: 0.5111 - val_loss: 1.3589 - val_accuracy: 0.3556\n",
      "Epoch 44/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9316 - accuracy: 0.5306 - val_loss: 1.3652 - val_accuracy: 0.3444\n",
      "Epoch 45/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9601 - accuracy: 0.5194 - val_loss: 1.3618 - val_accuracy: 0.3556\n",
      "Epoch 46/48\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.9515 - accuracy: 0.5250 - val_loss: 1.3712 - val_accuracy: 0.3278\n",
      "Epoch 47/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9582 - accuracy: 0.5069 - val_loss: 1.4708 - val_accuracy: 0.3556\n",
      "Epoch 48/48\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.9755 - accuracy: 0.5181 - val_loss: 1.3197 - val_accuracy: 0.3500\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 48.165130615234375, Units2: 89.80056762695312, Dropout Rate: 0.8125, Learning Rate: 0.044312500000000005, Epochs: 81.19552612304688, Batch Size: 76.82296752929688\n",
      "\n",
      "Epoch 1/81\n",
      "10/10 [==============================] - 6s 148ms/step - loss: 1.1130 - accuracy: 0.3333 - val_loss: 1.1060 - val_accuracy: 0.3944\n",
      "Epoch 2/81\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.1352 - accuracy: 0.3431 - val_loss: 1.1000 - val_accuracy: 0.3667\n",
      "Epoch 3/81\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.1194 - accuracy: 0.3500 - val_loss: 1.0939 - val_accuracy: 0.3611\n",
      "Epoch 4/81\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.1130 - accuracy: 0.3389 - val_loss: 1.1100 - val_accuracy: 0.3444\n",
      "Epoch 5/81\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.1039 - accuracy: 0.3792 - val_loss: 1.1018 - val_accuracy: 0.3278\n",
      "Epoch 6/81\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1140 - accuracy: 0.3250 - val_loss: 1.1051 - val_accuracy: 0.3944\n",
      "Epoch 7/81\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0965 - accuracy: 0.3486 - val_loss: 1.1081 - val_accuracy: 0.3556\n",
      "Epoch 8/81\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.1046 - accuracy: 0.3542 - val_loss: 1.1070 - val_accuracy: 0.3278\n",
      "Epoch 9/81\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0849 - accuracy: 0.3792 - val_loss: 1.1042 - val_accuracy: 0.3667\n",
      "Epoch 10/81\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.1080 - accuracy: 0.3597 - val_loss: 1.1135 - val_accuracy: 0.3556\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 94.03579711914062, Units2: 34.3402099609375, Dropout Rate: 0.55859375, Learning Rate: 0.038125000000000006, Epochs: 85.60791015625, Batch Size: 30.381011962890625\n",
      "\n",
      "Epoch 1/85\n",
      "24/24 [==============================] - 6s 62ms/step - loss: 1.1262 - accuracy: 0.2889 - val_loss: 1.0966 - val_accuracy: 0.3389\n",
      "Epoch 2/85\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1069 - accuracy: 0.3472 - val_loss: 1.1088 - val_accuracy: 0.3056\n",
      "Epoch 3/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.1056 - accuracy: 0.3333 - val_loss: 1.0984 - val_accuracy: 0.3889\n",
      "Epoch 4/85\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1016 - accuracy: 0.3361 - val_loss: 1.1025 - val_accuracy: 0.3444\n",
      "Epoch 5/85\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0909 - accuracy: 0.3694 - val_loss: 1.1104 - val_accuracy: 0.3444\n",
      "Epoch 6/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0936 - accuracy: 0.3847 - val_loss: 1.1142 - val_accuracy: 0.3611\n",
      "Epoch 7/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.1070 - accuracy: 0.3472 - val_loss: 1.0975 - val_accuracy: 0.3389\n",
      "Epoch 8/85\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0829 - accuracy: 0.3736 - val_loss: 1.0936 - val_accuracy: 0.3333\n",
      "Epoch 9/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0929 - accuracy: 0.3833 - val_loss: 1.0953 - val_accuracy: 0.3444\n",
      "Epoch 10/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0806 - accuracy: 0.3944 - val_loss: 1.1125 - val_accuracy: 0.3111\n",
      "Epoch 11/85\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0646 - accuracy: 0.4111 - val_loss: 1.1190 - val_accuracy: 0.3389\n",
      "Epoch 12/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0596 - accuracy: 0.4153 - val_loss: 1.1151 - val_accuracy: 0.3389\n",
      "Epoch 13/85\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0571 - accuracy: 0.4194 - val_loss: 1.1161 - val_accuracy: 0.3333\n",
      "Epoch 14/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0693 - accuracy: 0.4167 - val_loss: 1.0995 - val_accuracy: 0.3444\n",
      "Epoch 15/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0643 - accuracy: 0.4389 - val_loss: 1.1214 - val_accuracy: 0.3611\n",
      "Epoch 16/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0465 - accuracy: 0.4236 - val_loss: 1.1925 - val_accuracy: 0.3222\n",
      "Epoch 17/85\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0634 - accuracy: 0.4014 - val_loss: 1.1022 - val_accuracy: 0.3500\n",
      "Epoch 18/85\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0405 - accuracy: 0.4389 - val_loss: 1.1268 - val_accuracy: 0.3611\n",
      "Epoch 19/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0330 - accuracy: 0.4417 - val_loss: 1.1499 - val_accuracy: 0.3333\n",
      "Epoch 20/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0443 - accuracy: 0.4097 - val_loss: 1.1475 - val_accuracy: 0.3833\n",
      "Epoch 21/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0234 - accuracy: 0.4417 - val_loss: 1.2049 - val_accuracy: 0.3389\n",
      "Epoch 22/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0203 - accuracy: 0.4597 - val_loss: 1.1480 - val_accuracy: 0.3444\n",
      "Epoch 23/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0387 - accuracy: 0.4361 - val_loss: 1.1577 - val_accuracy: 0.3500\n",
      "Epoch 24/85\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0032 - accuracy: 0.4625 - val_loss: 1.1800 - val_accuracy: 0.3611\n",
      "Epoch 25/85\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0150 - accuracy: 0.4417 - val_loss: 1.1311 - val_accuracy: 0.3444\n",
      "Epoch 26/85\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9983 - accuracy: 0.4681 - val_loss: 1.2143 - val_accuracy: 0.3556\n",
      "Epoch 27/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9912 - accuracy: 0.4708 - val_loss: 1.1801 - val_accuracy: 0.3444\n",
      "Epoch 28/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0055 - accuracy: 0.4903 - val_loss: 1.2328 - val_accuracy: 0.3056\n",
      "Epoch 29/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9724 - accuracy: 0.4708 - val_loss: 1.1699 - val_accuracy: 0.3444\n",
      "Epoch 30/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9834 - accuracy: 0.4597 - val_loss: 1.2580 - val_accuracy: 0.3389\n",
      "Epoch 31/85\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9602 - accuracy: 0.4736 - val_loss: 1.2273 - val_accuracy: 0.3389\n",
      "Epoch 32/85\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9771 - accuracy: 0.4639 - val_loss: 1.2339 - val_accuracy: 0.3889\n",
      "Epoch 33/85\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9811 - accuracy: 0.4778 - val_loss: 1.2118 - val_accuracy: 0.3556\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 61.032867431640625, Units2: 39.5477294921875, Dropout Rate: 0.296875, Learning Rate: 0.09690625, Epochs: 71.7156982421875, Batch Size: 42.23114013671875\n",
      "\n",
      "Epoch 1/71\n",
      "18/18 [==============================] - 7s 86ms/step - loss: 1.1322 - accuracy: 0.3556 - val_loss: 1.1584 - val_accuracy: 0.3778\n",
      "Epoch 2/71\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.1192 - accuracy: 0.3222 - val_loss: 1.1036 - val_accuracy: 0.3333\n",
      "Epoch 3/71\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1.1010 - accuracy: 0.3542 - val_loss: 1.0969 - val_accuracy: 0.3389\n",
      "Epoch 4/71\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.1004 - accuracy: 0.3514 - val_loss: 1.1155 - val_accuracy: 0.3500\n",
      "Epoch 5/71\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0959 - accuracy: 0.3569 - val_loss: 1.1151 - val_accuracy: 0.3389\n",
      "Epoch 6/71\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0855 - accuracy: 0.3764 - val_loss: 1.1126 - val_accuracy: 0.3611\n",
      "Epoch 7/71\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0967 - accuracy: 0.3611 - val_loss: 1.1767 - val_accuracy: 0.3222\n",
      "Epoch 8/71\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1001 - accuracy: 0.3708 - val_loss: 1.1271 - val_accuracy: 0.3222\n",
      "Epoch 9/71\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1.1049 - accuracy: 0.3500 - val_loss: 1.1117 - val_accuracy: 0.3278\n",
      "Epoch 10/71\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0901 - accuracy: 0.3611 - val_loss: 1.1244 - val_accuracy: 0.3111\n",
      "Epoch 11/71\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0935 - accuracy: 0.3639 - val_loss: 1.1234 - val_accuracy: 0.3111\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 91.43890380859375, Units2: 35.828857421875, Dropout Rate: 0.880859375, Learning Rate: 0.1, Epochs: 21.95587158203125, Batch Size: 33.115234375\n",
      "\n",
      "Epoch 1/21\n",
      "22/22 [==============================] - 7s 79ms/step - loss: 1.2602 - accuracy: 0.3458 - val_loss: 1.1006 - val_accuracy: 0.3167\n",
      "Epoch 2/21\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1144 - accuracy: 0.3097 - val_loss: 1.1000 - val_accuracy: 0.3222\n",
      "Epoch 3/21\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1047 - accuracy: 0.3042 - val_loss: 1.1014 - val_accuracy: 0.3278\n",
      "Epoch 4/21\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1019 - accuracy: 0.3278 - val_loss: 1.0974 - val_accuracy: 0.3833\n",
      "Epoch 5/21\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1131 - accuracy: 0.3139 - val_loss: 1.0977 - val_accuracy: 0.3667\n",
      "Epoch 6/21\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1063 - accuracy: 0.3264 - val_loss: 1.1000 - val_accuracy: 0.3667\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 76.8902587890625, Units2: 51.72332763671875, Dropout Rate: 0.25, Learning Rate: 0.030390625, Epochs: 22.094573974609375, Batch Size: 99.94781494140625\n",
      "\n",
      "Epoch 1/22\n",
      "8/8 [==============================] - 6s 205ms/step - loss: 1.1095 - accuracy: 0.3347 - val_loss: 1.0975 - val_accuracy: 0.3667\n",
      "Epoch 2/22\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0963 - accuracy: 0.3569 - val_loss: 1.1012 - val_accuracy: 0.3278\n",
      "Epoch 3/22\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0934 - accuracy: 0.3722 - val_loss: 1.0969 - val_accuracy: 0.3722\n",
      "Epoch 4/22\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0912 - accuracy: 0.3806 - val_loss: 1.1057 - val_accuracy: 0.3500\n",
      "Epoch 5/22\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0877 - accuracy: 0.3806 - val_loss: 1.1170 - val_accuracy: 0.3333\n",
      "Epoch 6/22\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0842 - accuracy: 0.3917 - val_loss: 1.1119 - val_accuracy: 0.3611\n",
      "Epoch 7/22\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0778 - accuracy: 0.3917 - val_loss: 1.1058 - val_accuracy: 0.3889\n",
      "Epoch 8/22\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0792 - accuracy: 0.4014 - val_loss: 1.1196 - val_accuracy: 0.3611\n",
      "Epoch 9/22\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0804 - accuracy: 0.3931 - val_loss: 1.1094 - val_accuracy: 0.3556\n",
      "Epoch 10/22\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0682 - accuracy: 0.4167 - val_loss: 1.1324 - val_accuracy: 0.3667\n",
      "Epoch 11/22\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0658 - accuracy: 0.4208 - val_loss: 1.1090 - val_accuracy: 0.3833\n",
      "Epoch 12/22\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0675 - accuracy: 0.4236 - val_loss: 1.1161 - val_accuracy: 0.3667\n",
      "Epoch 13/22\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0498 - accuracy: 0.4375 - val_loss: 1.1239 - val_accuracy: 0.3667\n",
      "Epoch 14/22\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0498 - accuracy: 0.4347 - val_loss: 1.1337 - val_accuracy: 0.3667\n",
      "Epoch 15/22\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0330 - accuracy: 0.4597 - val_loss: 1.1426 - val_accuracy: 0.3778\n",
      "Epoch 16/22\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0395 - accuracy: 0.4347 - val_loss: 1.1408 - val_accuracy: 0.3611\n",
      "Epoch 17/22\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0251 - accuracy: 0.4431 - val_loss: 1.1520 - val_accuracy: 0.3167\n",
      "Epoch 18/22\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0239 - accuracy: 0.4722 - val_loss: 1.1441 - val_accuracy: 0.3722\n",
      "Epoch 19/22\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0145 - accuracy: 0.4681 - val_loss: 1.1559 - val_accuracy: 0.3222\n",
      "Epoch 20/22\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9989 - accuracy: 0.4931 - val_loss: 1.1751 - val_accuracy: 0.3500\n",
      "Epoch 21/22\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9952 - accuracy: 0.4736 - val_loss: 1.1954 - val_accuracy: 0.3722\n",
      "Epoch 22/22\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0014 - accuracy: 0.4722 - val_loss: 1.1565 - val_accuracy: 0.3778\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 24.9798583984375, Units2: 10.940704345703125, Dropout Rate: 0.435546875, Learning Rate: 0.086078125, Epochs: 63.510284423828125, Batch Size: 16.65771484375\n",
      "\n",
      "Epoch 1/63\n",
      "45/45 [==============================] - 6s 37ms/step - loss: 1.1159 - accuracy: 0.3361 - val_loss: 1.1069 - val_accuracy: 0.3111\n",
      "Epoch 2/63\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 1.1130 - accuracy: 0.3000 - val_loss: 1.1012 - val_accuracy: 0.3667\n",
      "Epoch 3/63\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.1113 - accuracy: 0.3514 - val_loss: 1.0965 - val_accuracy: 0.3667\n",
      "Epoch 4/63\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.1057 - accuracy: 0.3500 - val_loss: 1.0970 - val_accuracy: 0.3667\n",
      "Epoch 5/63\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 1.1096 - accuracy: 0.3306 - val_loss: 1.1019 - val_accuracy: 0.2833\n",
      "Epoch 6/63\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.1122 - accuracy: 0.3250 - val_loss: 1.1004 - val_accuracy: 0.3722\n",
      "Epoch 7/63\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.1072 - accuracy: 0.3250 - val_loss: 1.1033 - val_accuracy: 0.3222\n",
      "Epoch 8/63\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 1.1092 - accuracy: 0.3431 - val_loss: 1.1007 - val_accuracy: 0.3667\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 89.50942993164062, Units2: 75.9014892578125, Dropout Rate: 0.64453125, Learning Rate: 0.047406250000000004, Epochs: 98.47976684570312, Batch Size: 52.3797607421875\n",
      "\n",
      "Epoch 1/98\n",
      "14/14 [==============================] - 7s 130ms/step - loss: 1.1412 - accuracy: 0.3403 - val_loss: 1.1164 - val_accuracy: 0.3778\n",
      "Epoch 2/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.1203 - accuracy: 0.3333 - val_loss: 1.1074 - val_accuracy: 0.3500\n",
      "Epoch 3/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.1102 - accuracy: 0.3389 - val_loss: 1.1071 - val_accuracy: 0.3333\n",
      "Epoch 4/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.1053 - accuracy: 0.3458 - val_loss: 1.1006 - val_accuracy: 0.3222\n",
      "Epoch 5/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0853 - accuracy: 0.3653 - val_loss: 1.1112 - val_accuracy: 0.3667\n",
      "Epoch 6/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0926 - accuracy: 0.3722 - val_loss: 1.1227 - val_accuracy: 0.3889\n",
      "Epoch 7/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0860 - accuracy: 0.3958 - val_loss: 1.1097 - val_accuracy: 0.3278\n",
      "Epoch 8/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0954 - accuracy: 0.3653 - val_loss: 1.1042 - val_accuracy: 0.3778\n",
      "Epoch 9/98\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0885 - accuracy: 0.3667 - val_loss: 1.0904 - val_accuracy: 0.3611\n",
      "Epoch 10/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0835 - accuracy: 0.3875 - val_loss: 1.1072 - val_accuracy: 0.3722\n",
      "Epoch 11/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0642 - accuracy: 0.4250 - val_loss: 1.1003 - val_accuracy: 0.3667\n",
      "Epoch 12/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0682 - accuracy: 0.4208 - val_loss: 1.1467 - val_accuracy: 0.3222\n",
      "Epoch 13/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0785 - accuracy: 0.3889 - val_loss: 1.1240 - val_accuracy: 0.3389\n",
      "Epoch 14/98\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0573 - accuracy: 0.4111 - val_loss: 1.1494 - val_accuracy: 0.3278\n",
      "Epoch 15/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0549 - accuracy: 0.4375 - val_loss: 1.1208 - val_accuracy: 0.3833\n",
      "Epoch 16/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0497 - accuracy: 0.4319 - val_loss: 1.1256 - val_accuracy: 0.3778\n",
      "Epoch 17/98\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0431 - accuracy: 0.4208 - val_loss: 1.1737 - val_accuracy: 0.3278\n",
      "Epoch 18/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0299 - accuracy: 0.4389 - val_loss: 1.1584 - val_accuracy: 0.3389\n",
      "Epoch 19/98\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0371 - accuracy: 0.4333 - val_loss: 1.2001 - val_accuracy: 0.3333\n",
      "Epoch 20/98\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0280 - accuracy: 0.4306 - val_loss: 1.1195 - val_accuracy: 0.3278\n",
      "Epoch 21/98\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0183 - accuracy: 0.4597 - val_loss: 1.1763 - val_accuracy: 0.3389\n",
      "Epoch 22/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0200 - accuracy: 0.4389 - val_loss: 1.1617 - val_accuracy: 0.3611\n",
      "Epoch 23/98\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0166 - accuracy: 0.4417 - val_loss: 1.2315 - val_accuracy: 0.3833\n",
      "Epoch 24/98\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0211 - accuracy: 0.4417 - val_loss: 1.1981 - val_accuracy: 0.3611\n",
      "Epoch 25/98\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0128 - accuracy: 0.4667 - val_loss: 1.1900 - val_accuracy: 0.3389\n",
      "Epoch 26/98\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0035 - accuracy: 0.4389 - val_loss: 1.2115 - val_accuracy: 0.2778\n",
      "Epoch 27/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0013 - accuracy: 0.4694 - val_loss: 1.1588 - val_accuracy: 0.3778\n",
      "Epoch 28/98\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.9890 - accuracy: 0.4389 - val_loss: 1.2402 - val_accuracy: 0.3611\n",
      "Epoch 29/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9730 - accuracy: 0.4736 - val_loss: 1.2896 - val_accuracy: 0.3111\n",
      "Epoch 30/98\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.9834 - accuracy: 0.4667 - val_loss: 1.2122 - val_accuracy: 0.3556\n",
      "Epoch 31/98\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.9776 - accuracy: 0.4597 - val_loss: 1.1756 - val_accuracy: 0.3444\n",
      "Epoch 32/98\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.9362 - accuracy: 0.5069 - val_loss: 1.3063 - val_accuracy: 0.3889\n",
      "Epoch 33/98\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.9521 - accuracy: 0.5125 - val_loss: 1.2459 - val_accuracy: 0.3333\n",
      "Epoch 34/98\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.9564 - accuracy: 0.4819 - val_loss: 1.2683 - val_accuracy: 0.3389\n",
      "Epoch 35/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9430 - accuracy: 0.4889 - val_loss: 1.2807 - val_accuracy: 0.3556\n",
      "Epoch 36/98\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.9498 - accuracy: 0.4931 - val_loss: 1.2281 - val_accuracy: 0.3611\n",
      "Epoch 37/98\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9508 - accuracy: 0.4639 - val_loss: 1.3306 - val_accuracy: 0.3111\n",
      "Epoch 38/98\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.9226 - accuracy: 0.4889 - val_loss: 1.2504 - val_accuracy: 0.3722\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 23.827667236328125, Units2: 65.59356689453125, Dropout Rate: 0.41015625, Learning Rate: 0.061328125000000004, Epochs: 62.381439208984375, Batch Size: 39.450225830078125\n",
      "\n",
      "Epoch 1/62\n",
      "19/19 [==============================] - 7s 75ms/step - loss: 1.1304 - accuracy: 0.3292 - val_loss: 1.1176 - val_accuracy: 0.3278\n",
      "Epoch 2/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.1162 - accuracy: 0.3500 - val_loss: 1.1122 - val_accuracy: 0.3333\n",
      "Epoch 3/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0971 - accuracy: 0.3750 - val_loss: 1.1090 - val_accuracy: 0.3667\n",
      "Epoch 4/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0939 - accuracy: 0.3681 - val_loss: 1.1109 - val_accuracy: 0.3611\n",
      "Epoch 5/62\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.1002 - accuracy: 0.3750 - val_loss: 1.1055 - val_accuracy: 0.3333\n",
      "Epoch 6/62\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0942 - accuracy: 0.3792 - val_loss: 1.1162 - val_accuracy: 0.3444\n",
      "Epoch 7/62\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0923 - accuracy: 0.3569 - val_loss: 1.1089 - val_accuracy: 0.3667\n",
      "Epoch 8/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0833 - accuracy: 0.3833 - val_loss: 1.1365 - val_accuracy: 0.3389\n",
      "Epoch 9/62\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0813 - accuracy: 0.3944 - val_loss: 1.1136 - val_accuracy: 0.3278\n",
      "Epoch 10/62\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.0814 - accuracy: 0.3889 - val_loss: 1.1187 - val_accuracy: 0.3389\n",
      "Epoch 11/62\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0732 - accuracy: 0.4097 - val_loss: 1.1285 - val_accuracy: 0.3278\n",
      "Epoch 12/62\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0643 - accuracy: 0.4167 - val_loss: 1.1435 - val_accuracy: 0.2944\n",
      "Epoch 13/62\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0762 - accuracy: 0.3917 - val_loss: 1.1461 - val_accuracy: 0.3333\n",
      "Epoch 14/62\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0585 - accuracy: 0.4347 - val_loss: 1.1619 - val_accuracy: 0.3778\n",
      "Epoch 15/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0643 - accuracy: 0.4194 - val_loss: 1.1597 - val_accuracy: 0.3556\n",
      "Epoch 16/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0648 - accuracy: 0.4181 - val_loss: 1.1788 - val_accuracy: 0.3389\n",
      "Epoch 17/62\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0561 - accuracy: 0.4111 - val_loss: 1.1541 - val_accuracy: 0.3500\n",
      "Epoch 18/62\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0475 - accuracy: 0.4444 - val_loss: 1.1616 - val_accuracy: 0.3611\n",
      "Epoch 19/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0263 - accuracy: 0.4639 - val_loss: 1.1855 - val_accuracy: 0.3389\n",
      "Epoch 20/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0463 - accuracy: 0.4236 - val_loss: 1.1375 - val_accuracy: 0.3667\n",
      "Epoch 21/62\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0387 - accuracy: 0.4208 - val_loss: 1.1957 - val_accuracy: 0.3444\n",
      "Epoch 22/62\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0196 - accuracy: 0.4444 - val_loss: 1.2603 - val_accuracy: 0.3444\n",
      "Epoch 23/62\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.0454 - accuracy: 0.4444 - val_loss: 1.1941 - val_accuracy: 0.3111\n",
      "Epoch 24/62\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0256 - accuracy: 0.4347 - val_loss: 1.2568 - val_accuracy: 0.3667\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 53.685760498046875, Units2: 93.70620727539062, Dropout Rate: 0.078125, Learning Rate: 0.0071875, Epochs: 26.13616943359375, Batch Size: 56.2030029296875\n",
      "\n",
      "Epoch 1/26\n",
      "13/13 [==============================] - 6s 102ms/step - loss: 1.1018 - accuracy: 0.3583 - val_loss: 1.0989 - val_accuracy: 0.3222\n",
      "Epoch 2/26\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0958 - accuracy: 0.3500 - val_loss: 1.1030 - val_accuracy: 0.3389\n",
      "Epoch 3/26\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0912 - accuracy: 0.3722 - val_loss: 1.1083 - val_accuracy: 0.3833\n",
      "Epoch 4/26\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0919 - accuracy: 0.3806 - val_loss: 1.1106 - val_accuracy: 0.3833\n",
      "Epoch 5/26\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.0873 - accuracy: 0.3597 - val_loss: 1.1057 - val_accuracy: 0.3556\n",
      "Epoch 6/26\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0879 - accuracy: 0.3653 - val_loss: 1.0987 - val_accuracy: 0.4056\n",
      "Epoch 7/26\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0883 - accuracy: 0.3806 - val_loss: 1.0989 - val_accuracy: 0.3778\n",
      "Epoch 8/26\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0843 - accuracy: 0.3847 - val_loss: 1.1140 - val_accuracy: 0.3944\n",
      "Epoch 9/26\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0809 - accuracy: 0.3875 - val_loss: 1.1080 - val_accuracy: 0.3833\n",
      "Epoch 10/26\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0812 - accuracy: 0.4028 - val_loss: 1.1084 - val_accuracy: 0.4000\n",
      "Epoch 11/26\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0755 - accuracy: 0.4208 - val_loss: 1.1085 - val_accuracy: 0.3889\n",
      "Epoch 12/26\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.0726 - accuracy: 0.3875 - val_loss: 1.1211 - val_accuracy: 0.3333\n",
      "Epoch 13/26\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0713 - accuracy: 0.4014 - val_loss: 1.1103 - val_accuracy: 0.3500\n",
      "Epoch 14/26\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0726 - accuracy: 0.4069 - val_loss: 1.1313 - val_accuracy: 0.3333\n",
      "Epoch 15/26\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0668 - accuracy: 0.4181 - val_loss: 1.1243 - val_accuracy: 0.3556\n",
      "Epoch 16/26\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0593 - accuracy: 0.4194 - val_loss: 1.1488 - val_accuracy: 0.3333\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 72.99835205078125, Units2: 89.80194091796875, Dropout Rate: 0.29296875, Learning Rate: 0.045859375, Epochs: 56.01348876953125, Batch Size: 40.52001953125\n",
      "\n",
      "Epoch 1/56\n",
      "18/18 [==============================] - 9s 124ms/step - loss: 1.1280 - accuracy: 0.3250 - val_loss: 1.1113 - val_accuracy: 0.3389\n",
      "Epoch 2/56\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1.1123 - accuracy: 0.3236 - val_loss: 1.1048 - val_accuracy: 0.3000\n",
      "Epoch 3/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.1036 - accuracy: 0.3514 - val_loss: 1.1142 - val_accuracy: 0.3444\n",
      "Epoch 4/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.1072 - accuracy: 0.3403 - val_loss: 1.0960 - val_accuracy: 0.3556\n",
      "Epoch 5/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0977 - accuracy: 0.3222 - val_loss: 1.1076 - val_accuracy: 0.3778\n",
      "Epoch 6/56\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1.0963 - accuracy: 0.3833 - val_loss: 1.0902 - val_accuracy: 0.4167\n",
      "Epoch 7/56\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0918 - accuracy: 0.3597 - val_loss: 1.0916 - val_accuracy: 0.3722\n",
      "Epoch 8/56\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1.0881 - accuracy: 0.3833 - val_loss: 1.1065 - val_accuracy: 0.3667\n",
      "Epoch 9/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0853 - accuracy: 0.3903 - val_loss: 1.1066 - val_accuracy: 0.3278\n",
      "Epoch 10/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0769 - accuracy: 0.4056 - val_loss: 1.1494 - val_accuracy: 0.3611\n",
      "Epoch 11/56\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.0764 - accuracy: 0.4208 - val_loss: 1.0948 - val_accuracy: 0.3611\n",
      "Epoch 12/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0665 - accuracy: 0.4167 - val_loss: 1.1378 - val_accuracy: 0.3500\n",
      "Epoch 13/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0623 - accuracy: 0.4264 - val_loss: 1.1270 - val_accuracy: 0.3667\n",
      "Epoch 14/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0507 - accuracy: 0.4319 - val_loss: 1.1339 - val_accuracy: 0.3778\n",
      "Epoch 15/56\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0552 - accuracy: 0.4250 - val_loss: 1.1037 - val_accuracy: 0.3278\n",
      "Epoch 16/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0534 - accuracy: 0.4014 - val_loss: 1.1355 - val_accuracy: 0.3222\n",
      "Epoch 17/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0275 - accuracy: 0.4500 - val_loss: 1.1175 - val_accuracy: 0.3667\n",
      "Epoch 18/56\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0328 - accuracy: 0.4375 - val_loss: 1.1277 - val_accuracy: 0.3556\n",
      "Epoch 19/56\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0084 - accuracy: 0.4694 - val_loss: 1.1675 - val_accuracy: 0.3778\n",
      "Epoch 20/56\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1.0013 - accuracy: 0.4667 - val_loss: 1.1194 - val_accuracy: 0.3444\n",
      "Epoch 21/56\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9734 - accuracy: 0.4806 - val_loss: 1.1573 - val_accuracy: 0.3833\n",
      "Epoch 22/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9890 - accuracy: 0.4708 - val_loss: 1.1605 - val_accuracy: 0.3667\n",
      "Epoch 23/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9906 - accuracy: 0.4736 - val_loss: 1.1481 - val_accuracy: 0.3333\n",
      "Epoch 24/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9884 - accuracy: 0.4903 - val_loss: 1.2005 - val_accuracy: 0.3778\n",
      "Epoch 25/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9501 - accuracy: 0.4889 - val_loss: 1.2402 - val_accuracy: 0.3444\n",
      "Epoch 26/56\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9607 - accuracy: 0.4806 - val_loss: 1.1349 - val_accuracy: 0.4000\n",
      "Epoch 27/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9625 - accuracy: 0.4889 - val_loss: 1.2573 - val_accuracy: 0.3556\n",
      "Epoch 28/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9746 - accuracy: 0.5083 - val_loss: 1.2605 - val_accuracy: 0.3722\n",
      "Epoch 29/56\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9420 - accuracy: 0.4819 - val_loss: 1.2161 - val_accuracy: 0.3611\n",
      "Epoch 30/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9364 - accuracy: 0.5028 - val_loss: 1.3671 - val_accuracy: 0.3500\n",
      "Epoch 31/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9207 - accuracy: 0.5194 - val_loss: 1.3106 - val_accuracy: 0.3722\n",
      "Epoch 32/56\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.9393 - accuracy: 0.5014 - val_loss: 1.3328 - val_accuracy: 0.3556\n",
      "Epoch 33/56\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.9319 - accuracy: 0.4931 - val_loss: 1.2701 - val_accuracy: 0.3833\n",
      "Epoch 34/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9043 - accuracy: 0.5347 - val_loss: 1.3212 - val_accuracy: 0.3389\n",
      "Epoch 35/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.8967 - accuracy: 0.5250 - val_loss: 1.3287 - val_accuracy: 0.3556\n",
      "Epoch 36/56\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.8623 - accuracy: 0.5542 - val_loss: 1.3193 - val_accuracy: 0.4444\n",
      "Epoch 37/56\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.8872 - accuracy: 0.5528 - val_loss: 1.3747 - val_accuracy: 0.3444\n",
      "Epoch 38/56\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8806 - accuracy: 0.5236 - val_loss: 1.3200 - val_accuracy: 0.3667\n",
      "Epoch 39/56\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8740 - accuracy: 0.5208 - val_loss: 1.3615 - val_accuracy: 0.3833\n",
      "Epoch 40/56\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8625 - accuracy: 0.5431 - val_loss: 1.5162 - val_accuracy: 0.3611\n",
      "Epoch 41/56\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.8523 - accuracy: 0.5514 - val_loss: 1.4419 - val_accuracy: 0.3556\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 59.12811279296875, Units2: 73.90609741210938, Dropout Rate: 0.5703125, Learning Rate: 0.02884375, Epochs: 41.717529296875, Batch Size: 53.45367431640625\n",
      "\n",
      "Epoch 1/41\n",
      "14/14 [==============================] - 7s 108ms/step - loss: 1.1082 - accuracy: 0.3583 - val_loss: 1.1028 - val_accuracy: 0.3389\n",
      "Epoch 2/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.1052 - accuracy: 0.3181 - val_loss: 1.1014 - val_accuracy: 0.3611\n",
      "Epoch 3/41\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0965 - accuracy: 0.3583 - val_loss: 1.1010 - val_accuracy: 0.3667\n",
      "Epoch 4/41\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0973 - accuracy: 0.3528 - val_loss: 1.0984 - val_accuracy: 0.3667\n",
      "Epoch 5/41\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0878 - accuracy: 0.3653 - val_loss: 1.0972 - val_accuracy: 0.3556\n",
      "Epoch 6/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0983 - accuracy: 0.3681 - val_loss: 1.0968 - val_accuracy: 0.3833\n",
      "Epoch 7/41\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0934 - accuracy: 0.3458 - val_loss: 1.1103 - val_accuracy: 0.3944\n",
      "Epoch 8/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0763 - accuracy: 0.3917 - val_loss: 1.1082 - val_accuracy: 0.3611\n",
      "Epoch 9/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0957 - accuracy: 0.3625 - val_loss: 1.0955 - val_accuracy: 0.3556\n",
      "Epoch 10/41\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0811 - accuracy: 0.3889 - val_loss: 1.1118 - val_accuracy: 0.3444\n",
      "Epoch 11/41\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0695 - accuracy: 0.4083 - val_loss: 1.1200 - val_accuracy: 0.3556\n",
      "Epoch 12/41\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0811 - accuracy: 0.4042 - val_loss: 1.1299 - val_accuracy: 0.3833\n",
      "Epoch 13/41\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0623 - accuracy: 0.4181 - val_loss: 1.1249 - val_accuracy: 0.3444\n",
      "Epoch 14/41\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0505 - accuracy: 0.4319 - val_loss: 1.1513 - val_accuracy: 0.3111\n",
      "Epoch 15/41\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0678 - accuracy: 0.4097 - val_loss: 1.1158 - val_accuracy: 0.3722\n",
      "Epoch 16/41\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0556 - accuracy: 0.4333 - val_loss: 1.1275 - val_accuracy: 0.3222\n",
      "Epoch 17/41\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0427 - accuracy: 0.4389 - val_loss: 1.1320 - val_accuracy: 0.3444\n",
      "Epoch 18/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0474 - accuracy: 0.4500 - val_loss: 1.1336 - val_accuracy: 0.3389\n",
      "Epoch 19/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0344 - accuracy: 0.4264 - val_loss: 1.1704 - val_accuracy: 0.3611\n",
      "Epoch 20/41\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0473 - accuracy: 0.4083 - val_loss: 1.1461 - val_accuracy: 0.3778\n",
      "Epoch 21/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0456 - accuracy: 0.4056 - val_loss: 1.1306 - val_accuracy: 0.3667\n",
      "Epoch 22/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0329 - accuracy: 0.4278 - val_loss: 1.1445 - val_accuracy: 0.3389\n",
      "Epoch 23/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0214 - accuracy: 0.4583 - val_loss: 1.1710 - val_accuracy: 0.3333\n",
      "Epoch 24/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0210 - accuracy: 0.4417 - val_loss: 1.1783 - val_accuracy: 0.3333\n",
      "Epoch 25/41\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0074 - accuracy: 0.4750 - val_loss: 1.1816 - val_accuracy: 0.3222\n",
      "Epoch 26/41\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.9906 - accuracy: 0.4958 - val_loss: 1.2090 - val_accuracy: 0.3278\n",
      "Epoch 27/41\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9888 - accuracy: 0.4792 - val_loss: 1.1887 - val_accuracy: 0.3333\n",
      "Epoch 28/41\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9814 - accuracy: 0.4861 - val_loss: 1.2174 - val_accuracy: 0.3111\n",
      "Epoch 29/41\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.9639 - accuracy: 0.4806 - val_loss: 1.2418 - val_accuracy: 0.3944\n",
      "Epoch 30/41\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.9775 - accuracy: 0.4944 - val_loss: 1.2189 - val_accuracy: 0.3389\n",
      "Epoch 31/41\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.9762 - accuracy: 0.4917 - val_loss: 1.2389 - val_accuracy: 0.3556\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 62.889556884765625, Units2: 78.21685791015625, Dropout Rate: 0.884765625, Learning Rate: 0.07215625, Epochs: 79.23446655273438, Batch Size: 87.56759643554688\n",
      "\n",
      "Epoch 1/79\n",
      "9/9 [==============================] - 9s 178ms/step - loss: 1.1675 - accuracy: 0.3472 - val_loss: 1.1163 - val_accuracy: 0.3222\n",
      "Epoch 2/79\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1782 - accuracy: 0.3375 - val_loss: 1.1091 - val_accuracy: 0.3722\n",
      "Epoch 3/79\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1492 - accuracy: 0.3361 - val_loss: 1.0972 - val_accuracy: 0.3222\n",
      "Epoch 4/79\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1269 - accuracy: 0.3403 - val_loss: 1.0957 - val_accuracy: 0.3333\n",
      "Epoch 5/79\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.1086 - accuracy: 0.3500 - val_loss: 1.0994 - val_accuracy: 0.3278\n",
      "Epoch 6/79\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.1053 - accuracy: 0.3486 - val_loss: 1.1021 - val_accuracy: 0.3056\n",
      "Epoch 7/79\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1042 - accuracy: 0.3819 - val_loss: 1.1024 - val_accuracy: 0.3778\n",
      "Epoch 8/79\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1094 - accuracy: 0.3403 - val_loss: 1.1024 - val_accuracy: 0.3611\n",
      "Epoch 9/79\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0901 - accuracy: 0.3611 - val_loss: 1.1152 - val_accuracy: 0.3222\n",
      "Epoch 10/79\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1021 - accuracy: 0.3708 - val_loss: 1.1026 - val_accuracy: 0.3056\n",
      "Epoch 11/79\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.1071 - accuracy: 0.3542 - val_loss: 1.0985 - val_accuracy: 0.3778\n",
      "Epoch 12/79\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1122 - accuracy: 0.3361 - val_loss: 1.0996 - val_accuracy: 0.3389\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 57.28515625, Units2: 55.655059814453125, Dropout Rate: 0.271484375, Learning Rate: 0.047406250000000004, Epochs: 55.045318603515625, Batch Size: 39.59991455078125\n",
      "\n",
      "Epoch 1/55\n",
      "19/19 [==============================] - 7s 80ms/step - loss: 1.1099 - accuracy: 0.3431 - val_loss: 1.1302 - val_accuracy: 0.3278\n",
      "Epoch 2/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.1165 - accuracy: 0.3444 - val_loss: 1.1057 - val_accuracy: 0.3389\n",
      "Epoch 3/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0972 - accuracy: 0.3472 - val_loss: 1.0949 - val_accuracy: 0.3611\n",
      "Epoch 4/55\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 1.0948 - accuracy: 0.3569 - val_loss: 1.0923 - val_accuracy: 0.3444\n",
      "Epoch 5/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.0932 - accuracy: 0.3764 - val_loss: 1.1311 - val_accuracy: 0.3111\n",
      "Epoch 6/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0939 - accuracy: 0.3625 - val_loss: 1.1517 - val_accuracy: 0.3444\n",
      "Epoch 7/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0879 - accuracy: 0.3847 - val_loss: 1.1163 - val_accuracy: 0.3667\n",
      "Epoch 8/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.1039 - accuracy: 0.3458 - val_loss: 1.0950 - val_accuracy: 0.3833\n",
      "Epoch 9/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0924 - accuracy: 0.3556 - val_loss: 1.1024 - val_accuracy: 0.3833\n",
      "Epoch 10/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0875 - accuracy: 0.4069 - val_loss: 1.0869 - val_accuracy: 0.3778\n",
      "Epoch 11/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0794 - accuracy: 0.4056 - val_loss: 1.1276 - val_accuracy: 0.3889\n",
      "Epoch 12/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0754 - accuracy: 0.4069 - val_loss: 1.1154 - val_accuracy: 0.4111\n",
      "Epoch 13/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.0699 - accuracy: 0.4167 - val_loss: 1.1153 - val_accuracy: 0.3833\n",
      "Epoch 14/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0619 - accuracy: 0.4167 - val_loss: 1.1525 - val_accuracy: 0.3389\n",
      "Epoch 15/55\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0544 - accuracy: 0.4361 - val_loss: 1.1184 - val_accuracy: 0.3333\n",
      "Epoch 16/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0518 - accuracy: 0.4319 - val_loss: 1.1216 - val_accuracy: 0.3389\n",
      "Epoch 17/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.0520 - accuracy: 0.4222 - val_loss: 1.1349 - val_accuracy: 0.3889\n",
      "Epoch 18/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0363 - accuracy: 0.4403 - val_loss: 1.1628 - val_accuracy: 0.3611\n",
      "Epoch 19/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0326 - accuracy: 0.4472 - val_loss: 1.1905 - val_accuracy: 0.3111\n",
      "Epoch 20/55\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0383 - accuracy: 0.4500 - val_loss: 1.1717 - val_accuracy: 0.3556\n",
      "Epoch 21/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0301 - accuracy: 0.4250 - val_loss: 1.1672 - val_accuracy: 0.3333\n",
      "Epoch 22/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.0268 - accuracy: 0.4403 - val_loss: 1.2119 - val_accuracy: 0.3778\n",
      "Epoch 23/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0310 - accuracy: 0.4431 - val_loss: 1.1557 - val_accuracy: 0.3500\n",
      "Epoch 24/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.9914 - accuracy: 0.4681 - val_loss: 1.2405 - val_accuracy: 0.3556\n",
      "Epoch 25/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0010 - accuracy: 0.4583 - val_loss: 1.1136 - val_accuracy: 0.3722\n",
      "Epoch 26/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0149 - accuracy: 0.4667 - val_loss: 1.1818 - val_accuracy: 0.3389\n",
      "Epoch 27/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.9753 - accuracy: 0.4764 - val_loss: 1.1934 - val_accuracy: 0.3333\n",
      "Epoch 28/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.9762 - accuracy: 0.4861 - val_loss: 1.2412 - val_accuracy: 0.3556\n",
      "Epoch 29/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.9503 - accuracy: 0.5028 - val_loss: 1.2766 - val_accuracy: 0.3444\n",
      "Epoch 30/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.9373 - accuracy: 0.5194 - val_loss: 1.2914 - val_accuracy: 0.3722\n",
      "Epoch 31/55\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.9470 - accuracy: 0.5153 - val_loss: 1.2549 - val_accuracy: 0.3500\n",
      "Epoch 32/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.9224 - accuracy: 0.5042 - val_loss: 1.3235 - val_accuracy: 0.2778\n",
      "Epoch 33/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.9157 - accuracy: 0.5014 - val_loss: 1.2803 - val_accuracy: 0.3667\n",
      "Epoch 34/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.8969 - accuracy: 0.5528 - val_loss: 1.3466 - val_accuracy: 0.3278\n",
      "Epoch 35/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.8829 - accuracy: 0.5319 - val_loss: 1.2920 - val_accuracy: 0.3444\n",
      "Epoch 36/55\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.9051 - accuracy: 0.5208 - val_loss: 1.3317 - val_accuracy: 0.3111\n",
      "Epoch 37/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.8926 - accuracy: 0.5250 - val_loss: 1.3798 - val_accuracy: 0.3278\n",
      "Epoch 38/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.8782 - accuracy: 0.5444 - val_loss: 1.3588 - val_accuracy: 0.3222\n",
      "Epoch 39/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.8368 - accuracy: 0.5667 - val_loss: 1.4688 - val_accuracy: 0.3500\n",
      "Epoch 40/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.8523 - accuracy: 0.5361 - val_loss: 1.4345 - val_accuracy: 0.3389\n",
      "Epoch 41/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.8939 - accuracy: 0.5417 - val_loss: 1.4461 - val_accuracy: 0.3500\n",
      "Epoch 42/55\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.8705 - accuracy: 0.5472 - val_loss: 1.3367 - val_accuracy: 0.3722\n",
      "Epoch 43/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.8291 - accuracy: 0.5639 - val_loss: 1.4603 - val_accuracy: 0.3667\n",
      "Epoch 44/55\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.8215 - accuracy: 0.5667 - val_loss: 1.4985 - val_accuracy: 0.3611\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 10.7415771484375, Units2: 67.1893310546875, Dropout Rate: 0.712890625, Learning Rate: 0.042765625, Epochs: 79.03533935546875, Batch Size: 56.8017578125\n",
      "\n",
      "Epoch 1/79\n",
      "13/13 [==============================] - 7s 117ms/step - loss: 1.1048 - accuracy: 0.3236 - val_loss: 1.1106 - val_accuracy: 0.3167\n",
      "Epoch 2/79\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.1069 - accuracy: 0.3264 - val_loss: 1.1057 - val_accuracy: 0.3444\n",
      "Epoch 3/79\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.1074 - accuracy: 0.3667 - val_loss: 1.1235 - val_accuracy: 0.3722\n",
      "Epoch 4/79\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.1113 - accuracy: 0.3389 - val_loss: 1.1054 - val_accuracy: 0.3556\n",
      "Epoch 5/79\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0933 - accuracy: 0.3625 - val_loss: 1.1051 - val_accuracy: 0.3389\n",
      "Epoch 6/79\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0884 - accuracy: 0.3847 - val_loss: 1.1064 - val_accuracy: 0.3778\n",
      "Epoch 7/79\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0995 - accuracy: 0.3542 - val_loss: 1.1125 - val_accuracy: 0.3444\n",
      "Epoch 8/79\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0839 - accuracy: 0.3972 - val_loss: 1.1239 - val_accuracy: 0.3333\n",
      "Epoch 9/79\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.1010 - accuracy: 0.3597 - val_loss: 1.1298 - val_accuracy: 0.3278\n",
      "Epoch 10/79\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0752 - accuracy: 0.3875 - val_loss: 1.1295 - val_accuracy: 0.3167\n",
      "Epoch 11/79\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0736 - accuracy: 0.3861 - val_loss: 1.1197 - val_accuracy: 0.3611\n",
      "Epoch 12/79\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0769 - accuracy: 0.3889 - val_loss: 1.1661 - val_accuracy: 0.3611\n",
      "Epoch 13/79\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0740 - accuracy: 0.3958 - val_loss: 1.1211 - val_accuracy: 0.3500\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 34.61761474609375, Units2: 71.93817138671875, Dropout Rate: 0.451171875, Learning Rate: 0.045859375, Epochs: 41.853485107421875, Batch Size: 72.589111328125\n",
      "\n",
      "Epoch 1/41\n",
      "10/10 [==============================] - 6s 148ms/step - loss: 1.1058 - accuracy: 0.3431 - val_loss: 1.1022 - val_accuracy: 0.3444\n",
      "Epoch 2/41\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1055 - accuracy: 0.3625 - val_loss: 1.1003 - val_accuracy: 0.4056\n",
      "Epoch 3/41\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1064 - accuracy: 0.3556 - val_loss: 1.1001 - val_accuracy: 0.3778\n",
      "Epoch 4/41\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0926 - accuracy: 0.3417 - val_loss: 1.1224 - val_accuracy: 0.3222\n",
      "Epoch 5/41\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0886 - accuracy: 0.3944 - val_loss: 1.1122 - val_accuracy: 0.3611\n",
      "Epoch 6/41\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0878 - accuracy: 0.3819 - val_loss: 1.1251 - val_accuracy: 0.3611\n",
      "Epoch 7/41\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0896 - accuracy: 0.3708 - val_loss: 1.1246 - val_accuracy: 0.3333\n",
      "Epoch 8/41\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0698 - accuracy: 0.3958 - val_loss: 1.1350 - val_accuracy: 0.3667\n",
      "Epoch 9/41\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0671 - accuracy: 0.4167 - val_loss: 1.1275 - val_accuracy: 0.3444\n",
      "Epoch 10/41\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0601 - accuracy: 0.4361 - val_loss: 1.1300 - val_accuracy: 0.3500\n",
      "Epoch 11/41\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0588 - accuracy: 0.4347 - val_loss: 1.1318 - val_accuracy: 0.3444\n",
      "Epoch 12/41\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0674 - accuracy: 0.4139 - val_loss: 1.1759 - val_accuracy: 0.3278\n",
      "Epoch 13/41\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0594 - accuracy: 0.4333 - val_loss: 1.1309 - val_accuracy: 0.3667\n",
      "Epoch 14/41\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0666 - accuracy: 0.4208 - val_loss: 1.1418 - val_accuracy: 0.3611\n",
      "Epoch 15/41\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0548 - accuracy: 0.4333 - val_loss: 1.1299 - val_accuracy: 0.3778\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 23.921051025390625, Units2: 99.99862670898438, Dropout Rate: 0.109375, Learning Rate: 0.021109375000000003, Epochs: 28.07525634765625, Batch Size: 88.95462036132812\n",
      "\n",
      "Epoch 1/28\n",
      "9/9 [==============================] - 8s 198ms/step - loss: 1.1003 - accuracy: 0.3194 - val_loss: 1.1062 - val_accuracy: 0.3389\n",
      "Epoch 2/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1049 - accuracy: 0.3708 - val_loss: 1.1067 - val_accuracy: 0.3500\n",
      "Epoch 3/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0943 - accuracy: 0.3736 - val_loss: 1.0946 - val_accuracy: 0.3889\n",
      "Epoch 4/28\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0935 - accuracy: 0.3500 - val_loss: 1.0956 - val_accuracy: 0.3500\n",
      "Epoch 5/28\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.0913 - accuracy: 0.3694 - val_loss: 1.1007 - val_accuracy: 0.3611\n",
      "Epoch 6/28\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 1.0936 - accuracy: 0.3875 - val_loss: 1.0984 - val_accuracy: 0.3889\n",
      "Epoch 7/28\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.0846 - accuracy: 0.3847 - val_loss: 1.1076 - val_accuracy: 0.3667\n",
      "Epoch 8/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0846 - accuracy: 0.3931 - val_loss: 1.1118 - val_accuracy: 0.3500\n",
      "Epoch 9/28\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.0803 - accuracy: 0.4042 - val_loss: 1.1092 - val_accuracy: 0.3944\n",
      "Epoch 10/28\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0812 - accuracy: 0.4000 - val_loss: 1.1003 - val_accuracy: 0.3667\n",
      "Epoch 11/28\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0771 - accuracy: 0.4000 - val_loss: 1.1341 - val_accuracy: 0.3278\n",
      "Epoch 12/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0713 - accuracy: 0.4069 - val_loss: 1.1107 - val_accuracy: 0.3278\n",
      "Epoch 13/28\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.0727 - accuracy: 0.4139 - val_loss: 1.1012 - val_accuracy: 0.3611\n",
      "Epoch 14/28\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 1.0631 - accuracy: 0.4194 - val_loss: 1.1348 - val_accuracy: 0.3500\n",
      "Epoch 15/28\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.0626 - accuracy: 0.4375 - val_loss: 1.1261 - val_accuracy: 0.3278\n",
      "Epoch 16/28\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0537 - accuracy: 0.4236 - val_loss: 1.1055 - val_accuracy: 0.3167\n",
      "Epoch 17/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0533 - accuracy: 0.4486 - val_loss: 1.1175 - val_accuracy: 0.3500\n",
      "Epoch 18/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0484 - accuracy: 0.4250 - val_loss: 1.1136 - val_accuracy: 0.3722\n",
      "Epoch 19/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0332 - accuracy: 0.4431 - val_loss: 1.1579 - val_accuracy: 0.3556\n",
      "Epoch 20/28\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0432 - accuracy: 0.4361 - val_loss: 1.1433 - val_accuracy: 0.3333\n",
      "Epoch 21/28\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0346 - accuracy: 0.4569 - val_loss: 1.1199 - val_accuracy: 0.3833\n",
      "Epoch 22/28\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.0220 - accuracy: 0.4583 - val_loss: 1.1315 - val_accuracy: 0.3333\n",
      "Epoch 23/28\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0170 - accuracy: 0.4667 - val_loss: 1.1414 - val_accuracy: 0.3444\n",
      "Epoch 24/28\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.0196 - accuracy: 0.4653 - val_loss: 1.1347 - val_accuracy: 0.3611\n",
      "Epoch 25/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0121 - accuracy: 0.4542 - val_loss: 1.1230 - val_accuracy: 0.3778\n",
      "Epoch 26/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0037 - accuracy: 0.4778 - val_loss: 1.1425 - val_accuracy: 0.3333\n",
      "Epoch 27/28\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.9895 - accuracy: 0.4750 - val_loss: 1.1155 - val_accuracy: 0.3556\n",
      "Epoch 28/28\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9866 - accuracy: 0.4806 - val_loss: 1.1703 - val_accuracy: 0.3444\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 64.7393798828125, Units2: 36.6033935546875, Dropout Rate: 0.259765625, Learning Rate: 0.010281250000000002, Epochs: 65.72952270507812, Batch Size: 30.315093994140625\n",
      "\n",
      "Epoch 1/65\n",
      "24/24 [==============================] - 6s 65ms/step - loss: 1.1015 - accuracy: 0.3264 - val_loss: 1.1023 - val_accuracy: 0.3500\n",
      "Epoch 2/65\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0964 - accuracy: 0.3639 - val_loss: 1.1007 - val_accuracy: 0.3778\n",
      "Epoch 3/65\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0933 - accuracy: 0.3792 - val_loss: 1.1030 - val_accuracy: 0.3556\n",
      "Epoch 4/65\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.0923 - accuracy: 0.3750 - val_loss: 1.0991 - val_accuracy: 0.3944\n",
      "Epoch 5/65\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0932 - accuracy: 0.3597 - val_loss: 1.1011 - val_accuracy: 0.3944\n",
      "Epoch 6/65\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0907 - accuracy: 0.3958 - val_loss: 1.1082 - val_accuracy: 0.3833\n",
      "Epoch 7/65\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0844 - accuracy: 0.4014 - val_loss: 1.1019 - val_accuracy: 0.3833\n",
      "Epoch 8/65\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0767 - accuracy: 0.4028 - val_loss: 1.1057 - val_accuracy: 0.4000\n",
      "Epoch 9/65\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0706 - accuracy: 0.4306 - val_loss: 1.1147 - val_accuracy: 0.3667\n",
      "Epoch 10/65\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0750 - accuracy: 0.4056 - val_loss: 1.1095 - val_accuracy: 0.3667\n",
      "Epoch 11/65\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0735 - accuracy: 0.4042 - val_loss: 1.1254 - val_accuracy: 0.3278\n",
      "Epoch 12/65\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0639 - accuracy: 0.4194 - val_loss: 1.1078 - val_accuracy: 0.3722\n",
      "Epoch 13/65\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0630 - accuracy: 0.4181 - val_loss: 1.1322 - val_accuracy: 0.3556\n",
      "Epoch 14/65\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0683 - accuracy: 0.4153 - val_loss: 1.1098 - val_accuracy: 0.3722\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 29.974517822265625, Units2: 60.741729736328125, Dropout Rate: 0.646484375, Learning Rate: 0.008734374999999999, Epochs: 97.77114868164062, Batch Size: 74.1217041015625\n",
      "\n",
      "Epoch 1/97\n",
      "10/10 [==============================] - 6s 165ms/step - loss: 1.1012 - accuracy: 0.3111 - val_loss: 1.0978 - val_accuracy: 0.3667\n",
      "Epoch 2/97\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0964 - accuracy: 0.3486 - val_loss: 1.0999 - val_accuracy: 0.3333\n",
      "Epoch 3/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0922 - accuracy: 0.3847 - val_loss: 1.1056 - val_accuracy: 0.3278\n",
      "Epoch 4/97\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0926 - accuracy: 0.3750 - val_loss: 1.1087 - val_accuracy: 0.3333\n",
      "Epoch 5/97\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0950 - accuracy: 0.3597 - val_loss: 1.1027 - val_accuracy: 0.3778\n",
      "Epoch 6/97\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0919 - accuracy: 0.3875 - val_loss: 1.1039 - val_accuracy: 0.3389\n",
      "Epoch 7/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0890 - accuracy: 0.3736 - val_loss: 1.1053 - val_accuracy: 0.3667\n",
      "Epoch 8/97\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0872 - accuracy: 0.3778 - val_loss: 1.1056 - val_accuracy: 0.3500\n",
      "Epoch 9/97\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0889 - accuracy: 0.3778 - val_loss: 1.1099 - val_accuracy: 0.3889\n",
      "Epoch 10/97\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0874 - accuracy: 0.3931 - val_loss: 1.1078 - val_accuracy: 0.3722\n",
      "Epoch 11/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0828 - accuracy: 0.3861 - val_loss: 1.1023 - val_accuracy: 0.3556\n",
      "Epoch 12/97\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1.0827 - accuracy: 0.3778 - val_loss: 1.1058 - val_accuracy: 0.3556\n",
      "Epoch 13/97\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0806 - accuracy: 0.3722 - val_loss: 1.1043 - val_accuracy: 0.3667\n",
      "Epoch 14/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0871 - accuracy: 0.3944 - val_loss: 1.1101 - val_accuracy: 0.3556\n",
      "Epoch 15/97\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0757 - accuracy: 0.4042 - val_loss: 1.1172 - val_accuracy: 0.3722\n",
      "Epoch 16/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0754 - accuracy: 0.4097 - val_loss: 1.1153 - val_accuracy: 0.3722\n",
      "Epoch 17/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0764 - accuracy: 0.4042 - val_loss: 1.1098 - val_accuracy: 0.3500\n",
      "Epoch 18/97\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0798 - accuracy: 0.3889 - val_loss: 1.1131 - val_accuracy: 0.3500\n",
      "Epoch 19/97\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0785 - accuracy: 0.3944 - val_loss: 1.1147 - val_accuracy: 0.3389\n",
      "Epoch 20/97\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0682 - accuracy: 0.4125 - val_loss: 1.1128 - val_accuracy: 0.3556\n",
      "Epoch 21/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0730 - accuracy: 0.3889 - val_loss: 1.1189 - val_accuracy: 0.3278\n",
      "Epoch 22/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0672 - accuracy: 0.4292 - val_loss: 1.1235 - val_accuracy: 0.3278\n",
      "Epoch 23/97\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0688 - accuracy: 0.4097 - val_loss: 1.1199 - val_accuracy: 0.3556\n",
      "Epoch 24/97\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0703 - accuracy: 0.4111 - val_loss: 1.1189 - val_accuracy: 0.3389\n",
      "Epoch 25/97\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0628 - accuracy: 0.4125 - val_loss: 1.1220 - val_accuracy: 0.3500\n",
      "Epoch 26/97\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0643 - accuracy: 0.4069 - val_loss: 1.1258 - val_accuracy: 0.3556\n",
      "Epoch 27/97\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0552 - accuracy: 0.4278 - val_loss: 1.1335 - val_accuracy: 0.3444\n",
      "\n",
      "\n",
      "New generation training start. Parameters:\n",
      "Units1: 81.41799926757812, Units2: 76.52084350585938, Dropout Rate: 0.099609375, Learning Rate: 0.09071875, Epochs: 17.123260498046875, Batch Size: 10.907745361328125\n",
      "\n",
      "Epoch 1/17\n",
      "72/72 [==============================] - 7s 26ms/step - loss: 1.1579 - accuracy: 0.3653 - val_loss: 1.1069 - val_accuracy: 0.3444\n",
      "Epoch 2/17\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 1.1093 - accuracy: 0.3347 - val_loss: 1.1053 - val_accuracy: 0.3222\n",
      "Epoch 3/17\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1221 - accuracy: 0.3431 - val_loss: 1.1337 - val_accuracy: 0.3389\n",
      "Epoch 4/17\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.1297 - accuracy: 0.3361 - val_loss: 1.1187 - val_accuracy: 0.3667\n",
      "Epoch 5/17\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.1097 - accuracy: 0.3403 - val_loss: 1.1137 - val_accuracy: 0.3222\n",
      "Epoch 6/17\n",
      "24/72 [=========>....................] - ETA: 0s - loss: 1.1196 - accuracy: 0.3375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_accuracy\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Run the Genetic Algorithm\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\engine.py:45\u001b[0m, in \u001b[0;36mdo_profile.<locals>._do_profile.<locals>.profiled_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m     ps\u001b[38;5;241m.\u001b[39mdump_stats(filename)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\engine.py:156\u001b[0m, in \u001b[0;36mGAEngine.run\u001b[1;34m(self, ng)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo fitness function in GA engine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_statvars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Setup analysis objects.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalysis:\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\engine.py:223\u001b[0m, in \u001b[0;36mGAEngine._update_statvars\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03mPrivate helper function to update statistic variables in GA engine, like\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mmaximum, minimum and mean values.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Wrt original fitness.\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mori_fitness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fitness)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fmean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori_fitness)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\components\\population.py:212\u001b[0m, in \u001b[0;36mPopulation.max\u001b[1;34m(self, fitness)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m, fitness):\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Get the maximum fitness value in population.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    :param fitness: Fitness function to calculate fitness value\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    :rtype: float\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_fits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\components\\population.py:29\u001b[0m, in \u001b[0;36mMemoized.__call__\u001b[1;34m(self, fitness)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m fitness\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Update and memoize result.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Recover flag.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\u001b[38;5;241m.\u001b[39m_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\components\\population.py:244\u001b[0m, in \u001b[0;36mPopulation.all_fits\u001b[1;34m(self, fitness)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;129m@Memoized\u001b[39m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_fits\u001b[39m(\u001b[38;5;28mself\u001b[39m, fitness):\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Get all fitness values in population.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m    :param fitness: Fitness function to calculate fitness value\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    :type fitness: function\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindividuals\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\components\\population.py:244\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;129m@Memoized\u001b[39m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_fits\u001b[39m(\u001b[38;5;28mself\u001b[39m, fitness):\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Get all fitness values in population.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m    :param fitness: Fitness function to calculate fitness value\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    :type fitness: function\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m indv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividuals]\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\gaft\\engine.py:268\u001b[0m, in \u001b[0;36mGAEngine.fitness_register.<locals>._fn_with_fitness_check\u001b[1;34m(indv)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindv\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms class must be subclass of IndividualBase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# Check fitness.\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m fitness \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m is_invalid \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mtype\u001b[39m(fitness) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (math\u001b[38;5;241m.\u001b[39misnan(fitness))\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_invalid:\n",
      "Cell \u001b[1;32mIn[15], line 42\u001b[0m, in \u001b[0;36mfitness\u001b[1;34m(indv)\u001b[0m\n\u001b[0;32m     39\u001b[0m units1, units2, dropout_rate, learning_rate, epochs, batch_size \u001b[38;5;241m=\u001b[39m indv\u001b[38;5;241m.\u001b[39msolution\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Create and train LSTM model\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_and_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_accuracy\n",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m, in \u001b[0;36mcreate_and_train_model\u001b[1;34m(units1, units2, dropout_rate, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Return the validation accuracy as the fitness\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mD:\\python\\python3115\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "def create_and_train_model(units1, units2, dropout_rate, learning_rate, epochs, batch_size):\n",
    "    print(\"\\n\\nNew generation training start. Parameters:\")\n",
    "    print(f\"Units1: {units1}, Units2: {units2}, Dropout Rate: {dropout_rate}, Learning Rate: {learning_rate}, Epochs: {epochs}, Batch Size: {batch_size}\\n\")\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(units1), input_shape=(1, X_train.shape[1]), return_sequences=True))\n",
    "    model.add(LSTM(units=int(units2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=len(df['DataCenterID'].unique()), activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train_lstm, y_train, epochs=int(epochs), batch_size=int(batch_size), validation_data=(X_val_lstm, y_val), callbacks=[early_stopping])\n",
    "\n",
    "    # Return the validation accuracy as the fitness\n",
    "    return history.history['accuracy'][-1]\n",
    "\n",
    "# Define individual\n",
    "indv_template = BinaryIndividual(ranges=[(10, 100), (10, 100), (0.0, 1.0), (0.001, 0.1), (10, 100), (10, 100)])\n",
    "\n",
    "# Create population\n",
    "population = Population(indv_template=indv_template, size=50).init()\n",
    "\n",
    "# Define Genetic Algorithm operators\n",
    "selection = RouletteWheelSelection()\n",
    "crossover = UniformCrossover(pc=0.8, pe=0.5)\n",
    "mutation = FlipBitMutation(pm=0.1)\n",
    "\n",
    "# Create Genetic Algorithm engine\n",
    "engine = GAEngine(population=population, selection=selection, crossover=crossover, mutation=mutation)\n",
    "\n",
    "# Define and register fitness function\n",
    "@engine.fitness_register\n",
    "def fitness(indv):\n",
    "    # Decode GA individual to LSTM parameters\n",
    "    units1, units2, dropout_rate, learning_rate, epochs, batch_size = indv.solution\n",
    "\n",
    "    # Create and train LSTM model\n",
    "    val_accuracy = create_and_train_model(units1, units2, dropout_rate, learning_rate, epochs, batch_size)\n",
    "    \n",
    "    return val_accuracy\n",
    "\n",
    "# Run the Genetic Algorithm\n",
    "engine.run(ng=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068fff7-be5b-41a2-b8a8-59e581f2a530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": ".venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
